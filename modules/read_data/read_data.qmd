---
# Module title
title: Read data

# Module-specific parameters (that are not already in the profile yaml)
params:
  # Name of the module. Must be the same as name of qmd file.
  module: "read_data"
  
  # Path to a csv or Excel file containing a table with single-cell datasets. For Excel files, a sheet can be specified by appending ':<sheet_number>'.
  # The table must contain the following columns:
  # - sample (required): Name of the sample. A sample can have multiple single-cell datasets.
  # - technology (required): Single-cell technology used. Can be: "smartseq2" - Smartseq2, "smartseq3" - Smartseq3, "10x" - 10x, "10x_visium" - 10x Visium, 
  #                          "10x_xenium" - 10x Xenium, "parse" - Parse Biosciences, "scale" - ScaleBio.
  # - assays (required): Assay(s) of single-cell data to read. Currently supported are: RNA (Gene Expression), ADT (Antibody Protein Capture) and 
  #                     ATAC (Chromatin Accessibility), CUSTOM (Custom). Multiple assays can be specified comma-separated.
  # - path (required): Path to single-cell dataset. Can be: csv file (Smartseq2/3), mtx matrix market directory (10x, 10x Visium, 10x Xenium, Parse Biosciences,
  #                    ScaleBio), hdf5 file (10x, 10x Visium, 10x Xenium), h5ad file (Parse Biosciences).
  # - metrics_file (required): Path to a file containing a metrics summary table. For Smartseq2/3, this can be any table. For 10x, 10x Visium or 10x Xenium, this 
  #                            must be a "metrics_summary.csv" file produced by the Cellranger pipelines. For Parse Biosciences, this must be a "analysis_summary.csv"
  #                            file produced by the splitpipe pipeline. For ScaleBio, this must be a "*.reportStatistics.csv" file produced by the scalerna pipeline.
  # - barcode_metadata_file (optional): Path to a file containing a table of additional barcode metadata. Can be: a csv, Excel or an R table saved as rds file. 
  #                                     For Excel files, a sheet can be specified by appending ':<sheet_number>'. First column must contain the barcode. Table
  #                                     does not need to contain all barcodes.
  # - feature_metadata_file (optional): Path to a file containing a table of additional feature metadata. Can be: a csv, Excel or an R table saved as rds file. 
  #                                     For Excel files, a sheet can be specified by appending ':<sheet_number>'. First column must contain the feature id. Table
  #                                     does not need to contain all features.
  # - rename_features_ensembl (optional): By default, ids are used to name features (first column). For gene features, specify an Ensembl version to fetch the gene names (and more annotation). If used together with 
  #                                       rename_features_metadata, then rename_features_metadata must be set '1' for all assays that should be renamed with rename_features_ensembl.
  # - rename_features_metadata (optional): By default, ids are used to name features (first column). This column controls how to rename the features using metadata. Can be the name or index of a feature 
  #                                        metadata column. If multiple assays are read, this option can be specified either once or for all assays. If used together with 
  #                                        rename_features_ensembl, then rename_features_metadata must be set '1' for all assays that should be renamed with rename_features_ensembl.
  # - barcode_suffix (optional): Suffix to add to the barcodes. Suggestion is to use '-1', '-2', etc. If not set, no suffixes are added.
  datasets_file: "datasets/pbmc_datasets.xlsx"
  
  # For large datasets: Do not keep counts in memory but store on disk in matrix directories. Computations will access only the relevant parts of the data. TThis will create a a 'counts' directory within the module directory with one matrix directory per sample and assay.
  on_disk_counts: true
  
  # For large datasets: Overwrite existing matrix directories. The counts files will still be read though.
  on_disk_counts_overwrite: true
  
# Module execution
execute:
  # Should this module be re-rendered?
  # - auto: only when code changes
  # - true/false: always/never
  # Does not apply in interactive mode or when explicitly rendering this document via in rstudio
  freeze: false
---

```{r}
#| label: setup

# If running code interactively in rstudio, set profile here
# When rendering with quarto, profile is already set and should not be overwritten
if (nchar(Sys.getenv("QUARTO_PROFILE")) == 0) {Sys.setenv("QUARTO_PROFILE" = "default")}

# Source general configurations
source("R/general_configuration.R")

# Source required R functions
source("R/functions_util.R")
source("R/functions_io.R")

# Load libraries
library(magrittr)

# Get module name and directory (needed to access files within the module directory)
module_name = param("module")
module_dir = file.path("modules", module_name)
```

```{r}
#| label: preparation

v = 
ensembl_mart = GetBiomaRt(species="homo_sapiens", ensembl_version = 98)
annot_ensembl = biomaRt::getBM(mart=ensembl_mart, attributes=c("ensembl_gene_id", "external_gene_name", "chromosome_name", "start_position", "end_position", "gene_biotype", "description"), useCache=FALSE)

"", "start_position", "end_position", "percentage_gene_gc_content", "gene_biotype", "strand", "description

  annot_main: !r c(ensembl="", symbol="external_gene_name", entrez="entrezgene_accession")
  mart_attributes: !r c(c(ensembl="ensembl_gene_id", symbol="external_gene_name", entrez="entrezgene_accession"), 

```

```{r}
#| label: datasets_table

# Read table with datasets
datasets_file = param("datasets_file")


datasets = ReadDatasetsTable(datasets_file)


 annot_mart = suppressWarnings(GetBiomaRt(biomart="ensembl", 
                                           dataset=param$mart_dataset, 
                                           mirror=param$biomart_mirror, 
                                           version=param$annot_version))
  annot_ensembl = biomaRt::getBM(mart=annot_mart, attributes=param$mart_attributes, useCache=FALSE)
  write.table(annot_ensembl, file=param$file_annot, sep="\t", col.names=TRUE, row.names=FALSE, append=FALSE)

```


```{r}
# Read counts for datasets
counts_lst = list()

for (i in 1:nrow(datasets)) {
  i = 1
  
  # Set defaults
  sample = datasets$sample[i]
  path = datasets$path[i]
  technology = datasets$technology[i]
  assays = strsplit(datasets$assays[i], split=",") %>% unlist() %>% trimws()
  
  barcode_metadata_file = datasets$barcode_metadata_file[i]
  if (is.na(barcode_metadata_file)) barcode_metadata_file = NULL
  
  feature_metadata_file = datasets$feature_metadata_file[i]
  if (is.na(feature_metadata_file)) feature_metadata_file = NULL
  
  rename_barcodes = NULL
  rename_features = 2
  
  barcode_suffix = paste("-", i)
  
  # Save counts in matrix directory ?
  if (param("on_disk_counts") ){
    on_disk_path = file.path(module_dir, "counts", sample)
  } else {
    on_disk_path = NULL
  }
  on_disk_overwrite = param("on_disk_counts_overwrite")
  
  
  # Read counts for dataset
  counts_lst[[sample]] = ReadCounts(path=path,
                                    technology=technology,
                                    assay=assays,
                                    barcode_metadata_file=barcode_metadata_file,
                                    feature_metadata_file=feature_metadata_file,
                                    rename_barcodes=NULL,
                                    rename_features=2,
                                    barcode_suffix=barcode_suffix,
                                    on_disk_path=on_disk_path,
                                    on_disk_overwrite=on_disk_overwrite)
}

# 
a = "RNA"

purrr::map(counts_lst, names) %>% unlist() %>% table()

purrr::map(counts_lst, names)

n = "RNA"
has_assay = purrr::map(counts_lst, pluck_exists, n) %>% purrr::flatten_lgl()
has_assay = c(TRUE, FALSE)
assay_counts_lst = purrr::map(counts_lst[has_assay], pluck, n)

assay_barcode_metadata = purrr::map(names(assay_counts_lst), function(n) {
  metadata = attr(assay_counts_lst[[n]], "barcode_metadata")
  metadata$orig.ident = n
  metadata$technology = attr(assay_counts_lst[[n]], "technology")
  return(metadata)
}) %>% dplyr::bind_rows()

merged.object <- CreateSeuratObject(counts=assay_counts_lst, meta.data=assay_barcode_metadata, assay="RNA", names.delim=NULL, names.field=NULL)

n = "ADT"
has_assay = purrr::map(counts_lst, pluck_exists, n) %>% purrr::flatten_lgl()
assay_counts_lst = purrr::map(counts_lst[has_assay], pluck, n)

assay_barcode_metadata = purrr::map(names(assay_counts_lst), function(n) {
  metadata = attr(assay_counts_lst[[n]], "barcode_metadata")
  metadata$orig.ident = n
  metadata$technology = attr(assay_counts_lst[[n]], "technology")
  return(metadata)
}) %>% dplyr::bind_rows()

other_assay <- CreateAssay5Object(counts = assay_counts_lst)

merged.object[["ADT"]] = other_assay


param()
```



Blah Blah [see @Xie_2014]
