---
date: "`r format(Sys.time(), '%B, %Y')`"
geometry: "margin=2cm"
params:
  # Author
  author: !r Sys.info()[["user"]]

  # Project ID
  project_id: pbmc
   
  # Path to input data
  path_data: !r data.frame(name=c("pbmc_10x","pbmc_smartseq2"), 
                           type=c("10x","smartseq2"), 
                           path=c("test_datasets/10x_SmartSeq2_pbmc_GSE132044/counts/10x/", "test_datasets/10x_SmartSeq2_pbmc_GSE132044/counts/smartseq2/counts_table.tsv.gz"), 
                           stats=c(NA, NA))

  # Data type ("RNA", "Spatial")
  assay_raw: "RNA"
  
  # Downsample data to at most n cells per sample AFTER filtering (mainly for tests)
  #   NULL to deactivate
  downsample_cells_n: NULL
  
  # Downsample all samples equally according to the smalles sample
  #   TRUE/FALSE
  #   Overwritten by downsample_cells_n
  downsample_cells_equally: TRUE

  # Path to output directory
  path_out: test_datasets/10x_SmartSeq2_pbmc_GSE132044/results/

  # Marker genes based on literature, translated to Ensembl IDs
  #   xlsx file, one list per column, first row as header and Ensembl IDs below
  #   NULL if no known marker genes should be plotted
  file_known_markers: test_datasets/10x_SmartSeq2_pbmc_GSE132044/known_markers.xlsx
   
  # Annotation via biomaRt
  mart_dataset: hsapiens_gene_ensembl
  annot_version: 98
  annot_main: !r c(ensembl="ensembl_gene_id", symbol="external_gene_name", entrez="entrezgene_accession")
  mart_attributes: !r c(c(ensembl="ensembl_gene_id", symbol="external_gene_name", entrez="entrezgene_accession"), 
                        c("chromosome_name", "start_position", "end_position", "percentage_gene_gc_content", "gene_biotype", "strand", "description"))
  biomart_mirror: NULL

  # Prefix for mitochondrial genes 
  mt: "^MT-"

  #####################
  # Filter parameters #
  #####################
  # Filter for cells
  cell_filter: !r list(nFeature_RNA=c(NA, NA), percent_mt=c(NA, NA))

  # Filter for features
  feature_filter: !r list(min_counts=1, min_cells=3) # feature has to be found by at least one count in one cell

  # Samples to drop
  # Cells from these samples will be dropped after initial QC
  # Example: samples_to_drop = c("pbmc_smartseq2_NC", "pbmc_smartseq2_RNA"), 
  #   where "pbmc_smartseq2" is the name of the dataset, and "NC" and "RNA" are the names of the subsamples
  samples_to_drop: NULL

  # Drop samples with too few cells
  samples_min_cells: 10
   
  ############################
  # Normalisation parameters #
  ############################
  # Which normalisation should be used for analysis? ("RNA", "SCT")
  norm: RNA

  # Whether or not to remove cell cycle effects
  cc_remove: !r FALSE

  # Should all cell cycle effects be removed, or only the difference between profilerating cells (G2M and S phase)?
  # Read https://satijalab.org/seurat/v3.1/cell_cycle_vignette.html, for an explanation
  cc_remove_all: !r FALSE
   
  # Whether or not to re-score cell cycle effects after data
  #   from different samples have been merged/integrated
  cc_rescore_after_merge: !r TRUE

  # Additional (unwanted) variables that will be regressed out for visualisation and clustering
  vars_to_regress: NULL

  # When there are multiple datasets, how to combine them:
  #   - method:
  #     - "single": Default when there is only one dataset after filtering, no integration is needed
  #     - "merge": Merge (in other words, concatenate) data when no integration is needed, 
  #                e.g. when samples were multiplexed on the same chip.
  #     - "integrate": Anchors are computed for all pairs of datasets. This will give all datasets the same weight
  #                   during dataset integration but can be computationally intensive
  #
  # Additional options for the "integrate" method:
  #
  #   - dimensions: Number of dimensions to consider for integration
  #   - reference: Use one or more datasets as reference and compute anchors for all other datasets. 
  #                Separate multiple datasets by comma. This is computationally faster but less accurate.
  #   - use_reciprocal_pca: Compute anchors in PCA space. Even more computationally faster but again less accurate 
  #                         Recommended for big datasets.
  #   - k_filter: How many neighbors to use when filtering anchors (default: min(200, minimum number of cells in a sample))
  #   - k_weight: Number of neighbors to consider when weighting anchors (default: min(100, minimum number of cells in a sample))
  #   - k_anchor: How many neighbors to use when picking anchors (default: min(5, minimum number of cells in a sample))
  #   - k_score: How many neighbors to use when scoring anchors (default: min(30, minimum number of cells in a sample))
  integrate_samples: !r list(method="integrate", dimensions=30, reference=NULL, use_reciprocal_pca=FALSE)

  # TO DISCUSS from Seurat vignette:
  # The results show that rpca-based integration is more conservative, and in this case, do not perfectly align a subset of cells (which are naive and memory T cells) across experiments. You can increase the strength of alignment by increasing the k.anchor parameter, which is set to 5 by default. Increasing this parameter to 20 will assist in aligning these populations.
   
  # The number of PCs to use; adjust this parameter based on the Elbowplot 
  pc_n: 10
  
  # k nearest neighbors to find clusters
  # k nearest neighbors to construct the UMAP
  # Scanpy uses 15 for both by default
  # Seurat uses 20 for cluster_k, and 30 for umap_k by default
  cluster_k: 20
  umap_k: 30

  # Cluster resolutions to compute; lower values will lead to fewer clusters of cells; can be multiple values;
  # Empty vector if not needed
  cluster_resolution_test: !r c(0.3, 0.7)
  
  # Cluster resolution to use for analysis
  cluster_resolution: 0.5
  
  #######################################################
  # Marker genes and genes with differential expression #
  #######################################################
  # Thresholds to define marker genes
  marker_padj: 0.05
  marker_log2FC: !r log2(2)
  marker_pct: 0.25
   
  # Additional (unwanted) variables to account for in statistical tests
  latent_vars: NULL
      
  # Contrasts to find differentially expressed genes (R data.frame or Excel file)
  # Required columns:
  # condition_column: Categorial column in the cell metadata; specify "orig.ident" for sample and "seurat_clusters" for cluster
  # condition_group1: Condition levels in group 1, multiple levels concatenated by the plus character
  #                     Empty string = all levels not in group2 (cannot be used if group2 is empty)
  # condition_group2: Condition levels in group 2, multiple levels concatenated by the plus character
  #                     Empty string = all levels not in group1 (cannot be used if group1 is empty)
  #
  # Optional columns:
  # subset_column: Categorial column in the cell metadata to subset before testing (default: NA)
  #                  Specify "orig.ident" for sample and "seurat_clusters" for cluster 
  # subset_group: Further subset levels (default: NA)
  #                 For the individual analysis of multiple levels separate by semicolons
  #                 For the joint analysis of multiple levels concatenate by the plus character 
  #                 For the individual analysis of all levels empty string ""
  # assay: Seurat assay to test on; can also be a Seurat dimensionality reduction (default: "RNA")
  # slot: In case assay is a Seurat assay object, which slot to use (default: "data")
  # padj: Maximum adjusted p-value (default: 0.05)
  # log2FC: Minimum absolute log2 fold change (default: 0)
  # min_pct: Minimum percentage of cells expressing a gene to test (default: 0.1)
  # test: Type of test; "wilcox", "bimod", "roc", "t", "negbinom", "poisson", "LR", "MAST", "DESeq2"; (default: "wilcox")
  # downsample_cells_n: Downsample each group to at most n cells to speed up tests (default: NA)
  # latent_vars: Additional variables to account for; multiple variables need to be concatenated by semicolons; will overwrite the default by param$latent_vars (default: none).
  deg_contrasts: !r data.frame(condition_column=c("orig.ident", "orig.ident", "Phase"),
                               condition_group1=c("pbmc_10x", "pbmc_10x", "G1"),
                               condition_group2=c("pbmc_smartseq2_sample1", "pbmc_smartseq2_sample1", "G2M"),
                               subset_column=c(NA, "seurat_clusters", "seurat_clusters"),
                               subset_group=c(NA, "", "1;2"),
                               downsample_cells_n=c(NA, 50, 30))

  # Enrichr site ("Enrichr", "FlyEnrichr", "WormEnrichr", "YeastEnrichr", "FishEnrichr")
  enrichr_site: "Enrichr"
  
  # P-value threshold for functional enrichment tests
  enrichr_padj: 0.05
   
  # Enrichr databases of interest
  enrichr_dbs: !r c("GO_Molecular_Function_2018", "GO_Biological_Process_2018", "GO_Cellular_Component_2018", "Azimuth_Cell_Types_2021", "CellMarker_Augmented_2021", "Descartes_Cell_Types_and_Tissue_2021")
  
  ######################
  # General parameters #
  ######################
  # Main colour to use for plots
  col: "palevioletred"

  # Colour palette used for samples
  col_palette_samples: "ggsci::pal_jama"
   
  # Colour palette used for cluster
  col_palette_clusters: "ggsci::pal_igv"
   
  # Path to git repository
  path_to_git: "."
   
  # Debugging mode: 
  # 'default_debugging' for default, 'terminal_debugger' for debugging without X11, 'print_traceback' for non-interactive sessions 
  debugging_mode: "default_debugging"
  
  # Number of cores to use
  cores: 4
  
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: "hide"
    highlight: "tango"
    theme: "paper"
bibliography: "`r file.path(params$path_out, 'references.bib')`"
title: "Single-cell RNA-seq data analysis of project `r params$project_id`"
author: "`r params$author`"
---

```{r setup, warning=FALSE, message=FALSE}
# R Options
options(stringsAsFactors=FALSE,
        citation_format="pandoc", 
        dplyr.summarise.inform=FALSE, 
        knitr.table.format="html",
        kableExtra_view_html=TRUE,
        future.globals.maxSize=+Inf,
        mc.cores=params$cores, 
        future.fork.enable=TRUE, future.plan="multicore",
        future.rng.onMisuse="ignore")

# Python3 needed for clustering, umap, other python packages
# Path to binary will be automatically found
# Set manually if it does not work
reticulate_python3_path = unname(Sys.which("python3"))
Sys.setenv(RETICULATE_PYTHON=reticulate_python3_path)

# Required libraries
library(Seurat) # main
library(ggplot2) # plots
library(patchwork) # combination of plots
library(magrittr) # %>% operator
library(reticulate) # required for "leiden" clustering
library(enrichR) # functional enrichment
library(future) # multicore support for Seurat

# Other libraries we use
# Knit: knitr
# Data handling: dplyr, tidyr, purrr, stringr, Matrix, sctransform, glmGamPoi (optional for speed but only available for R 4.0)
# Tables: kableExtra, DT
# Plots: ggsci
# IO: openxlsx, readr, R.utils
# Annotation: biomaRt
# DEG: mast, limma (for a more efficient implementation of the Wilcoxon Rank Sum Test according to Seurat)
# Functional enrichment: enrichR
# Other: sessioninfo, cerebroApp, sceasy, ROpenSci/bibtex, knitcitations

# Knitr default options
knitr::opts_chunk$set(echo=TRUE,                     # output code
                      cache=FALSE,                   # do not cache results
                      message=TRUE,                  # show messages
                      warning=TRUE,                  # show warnings
                      tidy=FALSE,                    # do not auto-tidy-up code
                      fig.width=10,                  # default fig width in inches
                      class.source="fold-hide",      # by default collapse code blocks
                      dev=c("png", "pdf"),           # create figures in png and pdf; the first device (png) will be used for HTML output
                      dev.args=list(png=list(type="cairo"),  # png: use cairo - works on cluster, supports anti-aliasing (more smooth)
                                    pdf=list(bg="white")),     # pdf: use cairo - works on cluster, supports anti-aliasing (more smooth)
                      dpi=96,                        # figure resolution
                      fig.retina=2                   # retina multiplier
)

# If the DOI publication servers cannot be reached, there will be no citations, knitcitations will not write a references.bib file and pandoc will stop. This makes sure that there is always at least one citation.
invisible(knitcitations::citep(citation("knitr")))
```

```{r css, results="asis"}
cat(paste0('<link rel="stylesheet" href="', params$path_to_git, '/css/style.css">'))
```

```{r preparation_and_initial_checks}
# Copy input parameters to internal parameter list
param = params
if (is.null(param$samples_to_drop )) param$samples_to_drop = c()
if (is.null(param$vars_to_regress)) param$vars_to_regress = c()
if (is.null(param$latent_vars)) param$latent_vars = c()

# Git directory and files to source must be done first, then all helper functions can be sourced
git_files_to_source = c("functions_io.R",
                        "functions_plotting.R",
                        "functions_analysis.R",
                        "functions_degs.R",
                        "functions_util.R")
git_files_to_source = file.path(param$path_to_git, "R", git_files_to_source)
file_exists = purrr::map_lgl(git_files_to_source, file.exists)
if (any(!file_exists)) stop(paste("The following files could not be found:", paste(git_files_to_source[!file_exists], collapse=", "), ". Please check the git directory at '", param$path_to_git, "'.!"))
invisible(purrr::map(git_files_to_source, source))

# Debugging mode: 
switch (param$debugging_mode, 
        default_debugging=on_error_default_debugging(), 
        terminal_debugger=on_error_start_terminal_debugger(),
        print_traceback=on_error_just_print_traceback(),
        on_error_default_debugging())

# Set output hooks
knitr::knit_hooks$set(message=format_message, warning=format_warning)

# Create output directories
if (!file.exists(param$path_out)) dir.create(param$path_out, recursive=TRUE, showWarnings=FALSE)
dir.create(file.path(param$path_out, "figures"), recursive=TRUE, showWarnings=FALSE)
dir.create(file.path(param$path_out, "marker_degs"), recursive=TRUE, showWarnings=FALSE)
dir.create(file.path(param$path_out, "annotation"), recursive=TRUE, showWarnings=FALSE)
dir.create(file.path(param$path_out, "data"), recursive=TRUE, showWarnings=FALSE)
dir.create(file.path(param$path_out, "export"), recursive=TRUE, showWarnings=FALSE)

# Path for figures in png and pdf format (trailing "/" is needed)
knitr::opts_chunk$set(fig.path=paste0(file.path(param$path_out, "figures"), "/"))

# Path for annotation
param$file_annot = file.path(param$path_out, "annotation", paste0(param$mart_dataset, ".v", param$annot_version, ".annot.txt"))

# Path for cell cycle genes file
param$file_cc_genes = file.path(param$path_out, "annotation", "cell_cycle_markers.xlsx")

# Do checks
error_messages = c()

# Check parameters and parse entries (e.g. numbers) so that they are valid
param = check_parameters_scrnaseq(param)
error_messages = c(error_messages, param[["error_messages"]])
# Check installed packages
error_messages = c(error_messages, check_installed_packages_scrnaseq())
# Check python
error_messages = c(error_messages, check_python())
# Check pandoc
error_messages = c(error_messages, check_pandoc())
# Check enrichR
error_messages = c(error_messages, check_enrichr(param$enrichr_dbs, param$enrichr_site))
# Check ensembl
error_messages = c(error_messages, check_ensembl(biomart="ensembl", 
                                                 dataset=param$mart_dataset, 
                                                 mirror=param$biomart_mirror, 
                                                 version=param$annot_version,
                                                 attributes=param$mart_attributes,
                                                 file_annot=param$file_annot,
                                                 file_cc_markers=param$file_cc_genes))

# Stop here if there are errors
if (length(error_messages)) stop(paste(c("", paste("*", error_messages)), collapse="\n"))
```

# Read data
The workflow can be run for pre-processed 10x data, as well as for pre-processed SmartSeq-2 or other data that are represented by a simple table with transcript counts per gene and cell. 

## Read and print general metrics
Prior to this workflow, raw sequencing reads were mapped to the reference transcriptome. The resulting mapping statistics are printed below for a first estimation of sample quality. 

<details>
  <summary>Pre-processing of 10x data with Cell Ranger</summary>

We use the 10x Genomics Cell Ranger software to map 10x sequencing reads. The result is a count matrix that contains the number of unique transcripts per gene (rows) and cell (columns). To save storage space, the matrix is converted into a condensed format and described by the following 3 files:   
<ul>
<li>	“features.tsv.gz”: Tabular file with gene annotation (Ensembl gene ID and the gene symbol) to identify genes </li>
<li>	“barcodes.tsv.gz”: File with cell barcodes to identify cells </li>
<li> “matrix.mtx.gz”: A condensed version of the count matrix </li>
</ul>
</details>

<details>
  <summary>Pre-processing of SmartSeq-2 data</summary>

Sequencing reads from SmartSeq-2 (and other) experiments can be mapped with any suitable mapping software as long as a count matrix is generated that contains the number of mapped reads per gene (rows) and cell (columns). The first row of the count matrix should contain cell barcodes or names, the first column of the matrix should contain Ensembl gene IDs. 
</details>

```{r general_metrics, message=TRUE}
# Are metrics provided?
if (!all(is.na(param$path_data$stats))) { 

  # Loop through all samples and read metrics
  mapping_stats_list = list()
  for (i in 1:nrow(param$path_data)) {  
    if (!is.na(param$path_data$stats[i])) { 
      mapping_stats_list[[param$path_data$name[i]]] = Read10XMetrics(param$path_data$stats[i])
    } 
  }
  
  # Join all mapping stats tables
  mapping_stats = mapping_stats_list %>% purrr::reduce(dplyr::full_join, by="metric")
  rownames(mapping_stats) = mapping_stats[["metric"]]
  mapping_stats = mapping_stats %>% dplyr::select(-metric)
  colnames(mapping_stats) = names(mapping_stats_list)
 
  # Print table to HTML 
  knitr::kable(mapping_stats, align="l", caption="General metrics") %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover")) %>%
  kableExtra::scroll_box(width="100%", fixed_thead=TRUE)
 
} else { 
  message("Mapping statistics cannot be shown. No valid file provided.")
}
```

## Read gene annotation
We read gene annotation from Ensembl and write the resulting table to file. We generate several dictionaries to translate between Ensembl IDs, gene symbols, Entrez Ids, and Seurat gene names. 

```{r read_ensembl_annotation}
# Read annotation from csv or from Ensembl and a tab separated txt will be created
if (file.exists(param$file_annot)) {
  annot_ensembl = read.delim(param$file_annot)
} else {
  annot_mart = suppressWarnings(GetBiomaRt(biomart="ensembl", 
                                           dataset=param$mart_dataset, 
                                           mirror=param$biomart_mirror, 
                                           version=param$annot_version))
  annot_ensembl = biomaRt::getBM(mart=annot_mart, attributes=param$mart_attributes, useCache=FALSE)
  write.table(annot_ensembl, file=param$file_annot, sep="\t", col.names=TRUE, row.names=FALSE, append=FALSE)
  message("Gene annotation file was created at: ", param$file_annot)
  # Note: depending on the attributes, there might be more than one row per gene
}

# Double-check if we got all required annotation, in case annotation file was read
check_annot_main = all(param$annot_main %in% colnames(annot_ensembl))
if (!check_annot_main) {
  stop("The annotation table misses at least one of the following columns: ", paste(param$annot_main, collapse=", "))
}

# Create translation tables
ensembl = param$annot_main["ensembl"]
symbol = param$annot_main["symbol"]
entrez = param$annot_main["entrez"]

# Ensembl id to gene symbol (new)
ensembl_to_symbol = unique(annot_ensembl[, c(ensembl, symbol)])
ensembl_to_symbol[, symbol] = ifelse(nchar(ensembl_to_symbol[, symbol]) == 0, NA, ensembl_to_symbol[, symbol])
ensembl_to_symbol = setNames(ensembl_to_symbol[, symbol], ensembl_to_symbol[, ensembl])

# Ensembl id to seurat-compatible unique rowname (new)
ensembl_to_seurat_rowname = unique(annot_ensembl[, c(ensembl, symbol)])
ensembl_to_seurat_rowname[, symbol] = ifelse(nchar(ensembl_to_seurat_rowname[, symbol]) == 0, ensembl_to_seurat_rowname[, ensembl], ensembl_to_seurat_rowname[, symbol])
ensembl_to_seurat_rowname[, symbol] = make.unique(gsub(pattern="_", replacement="-", x=ensembl_to_seurat_rowname[, symbol], fixed=TRUE))
ensembl_to_seurat_rowname = setNames(ensembl_to_seurat_rowname[, symbol], ensembl_to_seurat_rowname[, ensembl])

# Seurat-compatible unique rowname to ensembl id
seurat_rowname_to_ensembl = setNames(names(ensembl_to_seurat_rowname), ensembl_to_seurat_rowname)

# Ensembl to Entrez
ensembl_to_entrez = unique(annot_ensembl[, c(ensembl, entrez)])
ensembl_to_entrez[, entrez] = ifelse(nchar(ensembl_to_entrez[, entrez]) == 0, NA, ensembl_to_entrez[, entrez])
ensembl_to_entrez = split(ensembl_to_entrez[, entrez], ensembl_to_entrez[, ensembl])

# Seurat-compatible unique rowname to Entrez
seurat_rowname_to_ensembl_match = match(seurat_rowname_to_ensembl, names(ensembl_to_entrez))
names(seurat_rowname_to_ensembl_match) = names(seurat_rowname_to_ensembl)
seurat_rowname_to_entrez = purrr::map(seurat_rowname_to_ensembl_match, function(i) {unname(ensembl_to_entrez[[i]])})

# Entrez IDs is duplicating Ensembl IDs in annot_ensembl
# Therefore, we remove Entrez IDs from the annotation table, after generating all required translation tables
# Set rownames of annotation table to Ensembl identifiers
annot_ensembl = annot_ensembl[, -match(entrez, colnames(annot_ensembl))] %>% unique() %>% as.data.frame()
rownames(annot_ensembl) = annot_ensembl[, ensembl]
```

```{r read_cc_genes}
# Use biomart to translate human cell cycle genes to the species of interest and save them in a file
if (file.exists(param$file_cc_genes)) {
  # Load from file
  genes_s = openxlsx::read.xlsx(param$file_cc_genes, sheet=1)
  genes_g2m = openxlsx::read.xlsx(param$file_cc_genes, sheet=2)
  
} else { 
  # Obtain from Ensembl
  # Note: both mart objects must point to the same mirror for biomarT::getLDS to work
  mart_human = suppressWarnings(GetBiomaRt(biomart="ensembl", 
                                           dataset="hsapiens_gene_ensembl", 
                                           mirror=param$biomart_mirror, 
                                           version=param$annot_version))
  mart_myspecies = suppressWarnings(GetBiomaRt(biomart="ensembl", 
                                               dataset=param$mart_dataset, 
                                               mirror=GetBiomaRtMirror(mart_human), 
                                               version=param$annot_version)) 
  
  # S phase marker
  genes_s = biomaRt::getLDS(attributes=c("ensembl_gene_id", "external_gene_name"), 
                          filters="external_gene_name", 
                          values=Seurat::cc.genes.updated.2019$s.genes, 
                          mart=mart_human, 
                          attributesL=c("ensembl_gene_id", "external_gene_name"), 
                          martL=mart_myspecies, 
                          uniqueRows=TRUE)
  colnames(genes_s) = c("Human_ensembl_id", "Human_gene_name", "Species_ensembl_id", "Species_gene_name")
  genes_s = genes_s %>% dplyr::arrange(Human_gene_name)
  
  # G2/M marker
  genes_g2m = biomaRt::getLDS(attributes=c("ensembl_gene_id", "external_gene_name"), 
                            filters="external_gene_name", 
                            values=Seurat::cc.genes.updated.2019$g2m.genes, 
                            mart=mart_human, 
                            attributesL=c("ensembl_gene_id", "external_gene_name"), 
                            martL=mart_myspecies, 
                            uniqueRows=TRUE)
  colnames(genes_g2m) = c("Human_ensembl_id", "Human_gene_name", "Species_ensembl_id", "Species_gene_name")
  genes_g2m = genes_g2m %>% dplyr::arrange(Human_gene_name)
  
  # Write to file
  openxlsx::write.xlsx(list(S_phase=genes_s,G2M_phase=genes_g2m), file=param$file_cc_genes)
}

# Convert Ensembl ID to Seurat-compatible unique rowname
genes_s = data.frame(Human_gene_name=genes_s$Human_gene_name, Species_gene_name=unname(ensembl_to_seurat_rowname[genes_s$Species_ensembl_id]))
genes_g2m = data.frame(Human_gene_name=genes_g2m$Human_gene_name, Species_gene_name=unname(ensembl_to_seurat_rowname[genes_g2m$Species_ensembl_id]))
```

## Read scRNA-seq data
We next read the single-cell RNA-seq data into a Seurat object. 
<details>
  <summary>What is Seurat and which information is contained in a Seurat object?</summary>

Seurat is an R-package that is used for the analysis of single-cell RNA-seq data. We read pre-processed data as described above, and convert it to a count matrix in R. In the case of 10x data, the count matrix contains the number of unique RNA molecules (UMIs) per gene and cell. In the case of SmartSeq-2 data, the count matrix contains the number of reads per gene and cell.

In addition to the count matrix, the workflow stores additional information in the Seurat object, including but not limited to the normalized data, dimensionality reduction and cluster results.
</details>

```{r read_datasets}
# List of Seurat objects
sc = list()

datasets = param$path_data
for (i in seq(nrow(datasets))) {
  name = datasets[i, "name"]
  type = datasets[i, "type"]
  path = datasets[i, "path"]
  suffix = datasets[i, "suffix"]
  
  # Read 10X or smartseq2
  if (type == "10x") {
    # Read 10X sparse matrix into a Seurat object
    sc = c(sc, ReadSparseMatrix(path, project=name, row_name_column=1, convert_row_names=ensembl_to_seurat_rowname, cellnames_suffix=suffix))
    
  } else if (type == "smartseq2") {
    # Read counts table into a Seurat object
    sc = c(sc, ReadCountsTable(path, project=name, row_name_column=1, convert_row_names=ensembl_to_seurat_rowname, parse_plate_information=TRUE, return_samples_as_datasets=TRUE, cellnames_suffix=suffix))
  } 
}

# Make sure that sample names are unique. If not, just prefix with the dataset name. Also set orig.ident to this name.
sample_names = names(sc)
duplicated_sample_names_idx = which(sample_names %in% sample_names[duplicated(sample_names)])
for (i in duplicated_sample_names_idx) {
  sample_names[i] = paste(head(sc[[i]][["orig.dataset", drop=TRUE]], 1), sample_names[i], sep=".")
  sc[[i]][["orig.ident"]] = sample_names[i]
}

# Set up colors for samples and add them to the sc objects
sample_names = purrr::flatten_chr(purrr::map(sc, function(s) {
  nms = unique(as.character(s[[]][["orig.ident"]]))
  return(nms) 
}))
param$col_samples = GenerateColours(num_colours=length(sample_names), names=sample_names, palette=param$col_palette_samples, alphas=1)
sc = purrr::map(sc, ScAddLists, lists=list(orig.ident=param$col_samples), lists_slot="colour_lists")

sc
```

The following first table shows available metadata (columns) of the first 5 cells (rows). These metadata provide additional information about the cells in the dataset, such as the sample a cell belongs to ("orig.ident"), the number of mapped reads (“nCounts_RNA”),  or the above mentioned number of unique genes detected ("`r paste0("nFeature_", param$assay_raw)`"). 
The second table shows available metadata (columns) of the first 5 genes (rows). 

```{r metadata}
# Combine cell metadata of the Seurat objects into one big metadata
sc_cell_metadata = suppressWarnings(purrr::map_dfr(sc, function(s) return(s[[]])) %>% as.data.frame())

# Print cell metadata
knitr::kable(head(sc_cell_metadata), align="l", caption="Cell metadata, top 5 rows") %>%
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))  %>% 
  kableExtra::scroll_box(width="100%")

# Print gene metadata
knitr::kable(head(sc[[1]][[param$assay_raw]][[]], 5), align="l", caption="Feature metadata, top 5 rows (only first dataset shown)") %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))  %>% 
  kableExtra::scroll_box(width="100%")
```

# Pre-processing
The steps below represent a standard pre-processing workflow for single-cell RNA-seq data, including quality control, the respective filtering of cells and genes, data normalization and scaling, and the detection of highly variable genes.

<details>
  <summary>Why is pre-processing so important?</summary>

Cells may have been damaged during sample preparation and might be only partially captured in the sequencing. In addition, free-floating mRNA from damaged cells can be encapsulated, adding to the background noise. The low-quality cells and free-floating mRNA interfere with downstream analyses. Therefore, cells and genes are filtered based on defined quality metrics. Data normalization eliminates cell-specific biases such as the absolute number of reads per cell, allowing us to systematically compare cells afterwards. Subsequent scaling corrects for the fact that genes have different lengths, allowing us to compare genes afterwards. Lastly, highly variable genes are determined, reducing computational overhead and noise from genes that are not interesting. 
</details>

## Quality control 
We start the analysis by removing unwanted cells from the dataset(s). Three commonly used QC metrics include the number of unique genes detected in each cell ("`r paste0("nFeature_", param$assay_raw)`"), the total number of molecules detected in each cell ("`r paste0("nCount_", param$assay_raw)`"), and the percentage of counts that map to the mitochrondrial genome ("percent_mt"). If ERCC spike-in controls were used, the percentage of counts mapping to them is also shown ("percent_ercc").

<details>
  <summary>Which cells can be considered to be of low quality?</summary>

On the one hand, low-quality cells such as dying, degraded and damaged cells, and empty droplets will often have very few genes ("nFeature_RNA") and low total counts ("nCount_RNA"). On the other hand, cell doublets may show an aberrantly high number of genes. Since the total number of reads detected within a cell typically strongly correlates with the number of unique genes, we can focus on the number of unique genes for filtering. In addition, damaged cells often exhibit high mitochondrial ("percent_mt") or spike-in ("percent_ercc") content. As mitochondria have their own membranes, their RNA is often the last to degrade in damaged cells and can thus be found in high numbers. However, it is important to keep in mind that different cell types and cells isolated from various species may differ in their number of expressed genes and metabolism. For example, stem cells may express a higher number of unique genes, and metabolically active cells may express a higher number of mitochondrial genes. 
</details>

<details>
  <summary>Impact of low-quality cells on downstream analyses</summary>

First of all, low-quality cells of different cell types might cluster together due to similarities in their damage-induced gene expression profiles. This leads to artificial intermediate states or trajectories between subpopulations that would otherwise be distinct. Second, low-quality cells might mask relevant gene expression changes. The main differences captured by the first principal components will likely be based on cell quality rather than the underlying biology, reducing the power of dimensionality reduction. Likewise, highly variable genes might just be genes that differ between low- and high-quality cells. Lastly and equally important, the low number of total counts in low-quality cells might lead to artificial upregulation of genes due to wrong scaling effects during the normalisation process. 
</details>

```{r qc_criteria_create}
# If filters were specified globally (i.e. not by sample), this chunk will copy them for each sample such that downstream filtering can work by sample
param$cell_filter = purrr::map(list_names(sc), function(s) {
  if (s %in% names(param$cell_filter)) {
    return(param$cell_filter[[s]])
  } else {
    return(param$cell_filter)
  }
})

param$feature_filter = purrr::map(list_names(sc), function(s) {
  if (s %in% names(param$feature_filter)) {
    return(param$feature_filter[[s]])
  } else {
    return(param$feature_filter)
  }
})
```

```{r qc_calculate_cells}
# Calculate percentage of counts in mitochondrial genes for each Seurat object
sc = purrr::map(sc, function(s) {
  mt_features = grep(pattern=param$mt, rownames(s), value=TRUE)
  return(Seurat::PercentageFeatureSet(s, features=mt_features, col.name="percent_mt", assay=param$assay_raw))
})

# Calculate percentage of counts in ribosomal genes for each Seurat object
sc = purrr::map(sc, function(s) {
  ribo_features = grep(pattern="^RP[SL]", rownames(s), value=TRUE, ignore.case=TRUE)
  return(Seurat::PercentageFeatureSet(s, features=ribo_features, col.name="percent_ribo", assay=param$assay_raw))
})

# Calculate percentage of counts in ERCC for each Seurat object (if assay is available)
sc = purrr::map(sc, function(s) {
  if ("ERCC" %in% Seurat::Assays(s)) s$percent_ercc = s$nCount_ERCC/(s$nCount_ERCC + s$nCount_RNA)*100
  return(s)
  })

# Combine (again) cell metadata of the Seurat objects into one big metadata, this time including mt and ercc 
sc_cell_metadata = suppressWarnings(purrr::map_dfr(sc, function(s){ return(s[[]]) }) %>% as.data.frame())
```

```{r qc_calculate_features}
# Only RNA assay at the moment
# counts_median uses sapply on the counts matrix, which converts the sparse matrix into a normal matrix
#   This might have to be adapted in future (Sparse Matrix Apply Function)
sc = purrr::map(list_names(sc), function(n) {
  # Calculate percentage of counts per gene in a cell
  counts_rna = Seurat::GetAssayData(sc[[n]], slot="counts", assay=param$assay_raw)
  total_counts = sc[[n]][[paste0("nCount_", param$assay_raw), drop=TRUE]]
  counts_rna_perc = Matrix::t(Matrix::t(counts_rna)/total_counts)*100

  # Calculate feature filters
  num_cells_expr = Matrix::rowSums(counts_rna >= 1)
  num_cells_expr_threshold = Matrix::rowSums(counts_rna >= param$feature_filter[[n]][["min_counts"]])
  
  # Calculate median of counts_rna_perc per gene 
  counts_median = apply(counts_rna_perc, 1, median)
  
  # Add all QC measures as metadata
  sc[[n]][[param$assay_raw]] = Seurat::AddMetaData(sc[[n]][[param$assay_raw]], data.frame(num_cells_expr, num_cells_expr_threshold, counts_median))
  return(sc[[n]])
})
```

```{r qc_plot_cells, fig.height=10}
# QC metrics to plot for cells
cell_qc_features = c(paste0(c("nFeature_", "nCount_"), param$assay_raw), "percent_mt")
if ("percent_ercc" %in% colnames(sc_cell_metadata)) cell_qc_features = c(cell_qc_features, "percent_ercc")
cell_qc_features = values_to_names(cell_qc_features)

# Get filter thresholds per QC metrics
cell_qc_thresholds = purrr::map(cell_qc_features, function(m) {
  tresh = purrr::map_dfr(names(param$cell_filter), function(n) {
    if (m %in% names(param$cell_filter[[n]])) {
      t = data.frame(orig.ident=n, min=param$cell_filter[[n]][[m]][1], max=param$cell_filter[[n]][[m]][2]) %>% 
        tidyr::pivot_longer(cols=2:3, names_to=c("threshold")) %>%
        dplyr::filter(!is.na(value))
      t$threshold = factor(t$threshold, levels=c("min", "max"))
      return(t)
    }
  })
})

# Now create plot per QC metric
p_list = list()
for (m in cell_qc_features) {
  p_list[[m]]= ggplot(sc_cell_metadata[, c("orig.ident", m)], aes_string(x="orig.ident", y=m, fill="orig.ident", group="orig.ident")) +
    geom_violin(scale="width")

  # Adds points for samples with less than three cells since geom_violin does not work here
  p_list[[m]] = p_list[[m]] + 
    geom_point(data=sc_cell_metadata[, c("orig.ident", m)] %>% dplyr::filter(orig.ident %in% names(which(table(sc_cell_metadata$orig.ident) < 3))), aes_string(x="orig.ident", y=m, fill="orig.ident"), shape=21, size=2)
  
  # Now add style
  p_list[[m]] = p_list[[m]] + 
    AddStyle(title=m, legend_position="none", fill=param$col_samples, xlab="") + 
    theme(axis.text.x=element_text(angle=45, hjust=1))
  
  # Add filter threshold as segments to plot; min threshold lines are dashed and max threshold lines are twodashed
  if (nrow(cell_qc_thresholds[[m]]) > 0) {
    p_list[[m]] = p_list[[m]] + geom_segment(data=cell_qc_thresholds[[m]], 
                                             aes(x=as.integer(as.factor(orig.ident))-0.5, 
                                                 xend=as.integer(as.factor(orig.ident))+0.5, 
                                                 y=value, yend=value, lty=threshold), colour="firebrick") +
      scale_linetype_manual(values=setNames(c("dashed", "F1"), c("max", "min")))
  }
}
p = patchwork::wrap_plots(p_list, ncol=2) + patchwork::plot_annotation("Distribution of feature values") 
p
```

```{r qc_plot_correlation}
# Correlate QC metrics for cells
p_list = list()
sc_cell_metadata_plot_order = sample(1:nrow(sc_cell_metadata))

# nFeature vs nCount
m = paste0(c("nCount_", "nFeature_"), param$assay_raw)
p_list[[1]] = ggplot(sc_cell_metadata[sc_cell_metadata_plot_order, , drop=FALSE], aes_string(x=m[1], y=m[2], colour="orig.ident")) +
  geom_point() + 
  scale_linetype_manual(values=setNames(c("dashed", "F1"), c("max", "min"))) +
  AddStyle(col=param$col_samples)
if (nrow(cell_qc_thresholds[[m[1]]]) > 0) {
  p_list[[1]] = p_list[[1]] + geom_vline(data=cell_qc_thresholds[[m[1]]], aes(xintercept=value, lty=threshold), colour="firebrick")
    
}
if (nrow(cell_qc_thresholds[[m[2]]]) > 0) {
  p_list[[1]] = p_list[[1]] + geom_hline(data=cell_qc_thresholds[[m[2]]], aes(yintercept=value, lty=threshold), colour="firebrick")
}
  

# nFeature vs percent_mt
m = c("percent_mt", paste0(c("nFeature_"), param$assay_raw))
p_list[[2]] = ggplot(sc_cell_metadata[sc_cell_metadata_plot_order, , drop=FALSE], aes_string(x=m[1], y=m[2], colour="orig.ident")) +
  geom_point() +
  scale_linetype_manual(values=setNames(c("dashed", "F1"), c("max", "min"))) +
  AddStyle(col=param$col_samples)
if (nrow(cell_qc_thresholds[[m[1]]]) > 0) {
  p_list[[2]] = p_list[[2]] + geom_vline(data=cell_qc_thresholds[[m[1]]], aes(xintercept=value, lty=threshold), colour="firebrick")
}
if (nrow(cell_qc_thresholds[[m[2]]]) > 0) {
  p_list[[2]] = p_list[[2]] + geom_hline(data=cell_qc_thresholds[[m[2]]], aes(yintercept=value, lty=threshold), colour="firebrick")
}

# nFeature vs percent_ercc (if available)
if ("percent_ercc" %in% names(cell_qc_features)) {
  m = c("percent_ercc", paste0(c("nFeature_"), param$assay_raw))
  p_list[[3]] = ggplot(sc_cell_metadata[sc_cell_metadata_plot_order, , drop=FALSE], aes_string(x=m[1], y=m[2], colour="orig.ident")) +
    geom_point() + 
    scale_linetype_manual(values=setNames(c("dashed", "F1"), c("max", "min"))) + 
    AddStyle(col=param$col_samples)
  if (nrow(cell_qc_thresholds[[m[1]]]) > 0) {
    p_list[[3]] = p_list[[3]] + geom_vline(data=cell_qc_thresholds[[m[1]]], aes(xintercept=value, lty=threshold), colour="firebrick")
  }
  if (nrow(cell_qc_thresholds[[m[2]]]) > 0) {
    p_list[[3]] = p_list[[3]] + geom_hline(data=cell_qc_thresholds[[m[2]]], aes(yintercept=value, lty=threshold), colour="firebrick")
  }
}

# Combine plots
p = patchwork::wrap_plots(p_list, ncol=length(p_list)) + patchwork::plot_annotation("Features plotted against each other")
if (length(p_list) == 1) {
  p = p & theme(legend.position="bottom")
} else {
  p = p + patchwork::plot_layout(guides="collect") & theme(legend.position="bottom")
}
p
```

## Genes with highest expression
We next investigate whether there are individual genes that are represented by an unusually high number of counts. For each cell, we first calculate the percentage of counts per gene. Subsequently, for each gene, we calculate the median value of these percentages in all cells. Genes with the highest median percentage of counts are plotted below. 

```{r plot_highest_expression}
# Plot only samples that we intend to keep 
sc_names = names(sc)[!(names(sc) %in% param$samples_to_drop)]
genes_highestExpr = lapply(sc_names, function(i) {
  top_ten_exp = sc[[i]][[param$assay_raw]][["counts_median"]] %>% dplyr::arrange(dplyr::desc(counts_median)) %>% head(n=10)
  return(rownames(top_ten_exp))
  }) %>%
  unlist() %>%
  unique()

genes_highestExpr_counts = purrr::map_dfc(sc[sc_names], .f=function(s) s[[param$assay_raw]][["counts_median"]][genes_highestExpr, ]) 
genes_highestExpr_counts$gene = genes_highestExpr
genes_highestExpr_counts = genes_highestExpr_counts %>% tidyr::pivot_longer(cols=all_of(sc_names))
genes_highestExpr_counts$name = factor(genes_highestExpr_counts$name, levels=sc_names)

col =  GenerateColours(num_colours=length(genes_highestExpr), names=genes_highestExpr, palette="ggsci::pal_simpsons")
p = ggplot(genes_highestExpr_counts, aes(x=name, y=value, col=gene, group=gene)) + 
  geom_point() + 
  AddStyle(title="Top 10 highest expressed genes per sample, added into one list", 
           xlab="Sample", ylab="Median % of raw counts\n per gene in a cell", 
           legend_position="bottom", 
           col=col)
if (length(unique(genes_highestExpr_counts$name))>1) p = p + geom_line()
p
```

## Filtering
Cells and genes are filtered based on the following thresholds: 

```{r filter_print_cutoffs}
cell_filter_lst = param$cell_filter %>% unlist(recursive=FALSE)
is_numeric_filter = purrr::map_lgl(cell_filter_lst, function(f) return(is.numeric(f) & length(f)==2))

# numeric cell filters
if (length(cell_filter_lst[is_numeric_filter]) > 0) {
  purrr::invoke(rbind, cell_filter_lst[is_numeric_filter]) %>%
    knitr::kable(align="l", caption="Numeric filters applied to cells", col.names=c("Min", "Max")) %>% 
    kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))
}

# categorial cell filters
if (length(cell_filter_lst[!is_numeric_filter]) > 0) {
purrr::invoke(rbind, cell_filter_lst[!is_numeric_filter] %>% purrr::map(paste, collapse=",")) %>%
  knitr::kable(align="l", caption="Categorial filters applied to cells", col.names=c("Values")) %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))
}
  
# gene filters
feature_filter_lst = param$feature_filter %>% unlist(recursive=FALSE)
if (length(feature_filter_lst) > 0) {
  purrr::invoke(rbind, feature_filter_lst) %>% 
    knitr::kable(align="l", caption="Filters applied to genes", col.names=c("Value")) %>%
    kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))
}
```

The number of excluded cells and features is as follows: 

```{r filter_cells}
# Iterate over datasets and filters
# Record a cell if it does not pass the filter
# Also record a cell if it belongs to a sample that should be dropped
sc_cells_to_exclude  = purrr::map(list_names(sc), function(n) { 
  filter_result = purrr::map(list_names(param$cell_filter[[n]]), function(f) {
    filter = param$cell_filter[[n]][[f]]
    if (is.numeric(filter)) {
      if (is.na(filter[1])) filter[1] = -Inf # Minimum
      if (is.na(filter[2])) filter[2] = Inf  # Maximum 
      idx_exclude = sc[[n]][[f, drop=TRUE]] < filter[1] | sc[[n]][[f, drop=TRUE]] > filter[2]
      return(names(which(idx_exclude)))
    } else if (is.character(filter)) { 
      idx_exclude = !sc[[n]][[f, drop=TRUE]] %in% filter
      return(Cells(sc[[n]])[idx_exclude])
    }
  })

  # Samples to drop
  if (n %in% param$samples_to_drop) {
    filter_result[["samples_to_drop"]] = colnames(sc[[n]])
  } else {
    filter_result[["samples_to_drop"]] = as.character(c())
  }
  
  # Minimum number of cells for a sample to keep
  if (ncol(sc[[n]]) < param$samples_min_cells) {
    filter_result[["samples_min_cells"]] = colnames(sc[[n]])
  } else {
    filter_result[["samples_min_cells"]] = as.character(c())
  }
  
  return(filter_result)
})

# Summarise
sc_cells_to_exclude_summary = purrr::map_dfr(sc_cells_to_exclude, function(s) {
  return(as.data.frame(purrr::map(s, length))) 
  })
rownames(sc_cells_to_exclude_summary) = names(sc_cells_to_exclude)

sc_cells_to_exclude_summary$Original = purrr::map_int(sc, ncol)
sc_cells_to_exclude_summary$Excluded = purrr::map_int(sc_cells_to_exclude, function(s) { return(purrr::flatten(s) %>% unique() %>% length())})
sc_cells_to_exclude_summary$PercKept = round((sc_cells_to_exclude_summary$Original - sc_cells_to_exclude_summary$Excluded) / sc_cells_to_exclude_summary$Original * 100, 2)
knitr::kable(sc_cells_to_exclude_summary, 
             align="l", 
             caption="Summary of excluded cells") %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))

# Add filter column to sc_cell_metadata for post-filtering QC
sc_cell_metadata$IS_FILTERED = rownames(sc_cell_metadata) %in% unlist(sc_cells_to_exclude)

# Now filter, drop the respective colours and adjust integration method
sc = purrr::map(list_names(sc), function(n) {
  cells_to_keep = Cells(sc[[n]])
  cells_to_keep = cells_to_keep[!cells_to_keep %in% purrr::flatten_chr(sc_cells_to_exclude[[n]])]
  if (length(cells_to_keep)==0) return(NULL)
  else return(subset(sc[[n]], cells=cells_to_keep))
}) %>% purrr::discard(is.null)

if (length(sc)==1) param$integrate_samples[["method"]] = "single"
```

```{r filter_features}
# Only RNA assay at the moment

# Iterate over samples and record a feature if it does not pass the filter
sc_features_to_exclude = purrr::map(list_names(sc), function(n) {
  
  # Make sure the sample contains more cells than the minimum threshold
  if (length(Cells(sc[[n]])) < param$feature_filter[[n]][["min_cells"]]) return(list())
  
  # Return gene names that do not pass the minimum threshold 
  else return(names(which(sc[[n]][[param$assay_raw]][["num_cells_expr_threshold", drop=TRUE]] < param$feature_filter[[n]][["min_cells"]])))
})

# Which genes are to be filtered for all samples?
# Note: Make sure that no other sample is called "AllSamples"
sc_features_to_exclude$AllSamples = Reduce(f=intersect, x=sc_features_to_exclude)

# Summarise
sc_features_to_exclude_summary = purrr::map_dfr(names(sc), function(n){
  df = data.frame(Original=nrow(sc[[n]]), 
                  FailThreshold=length(sc_features_to_exclude[[n]]))
  df$PercFailThreshold = round(df$FailThreshold / df$Original * 100, 2)
  df$Kept = length(setdiff(rownames(sc[[n]]), sc_features_to_exclude[["AllSamples"]]))
  df$PercKept = round(df$Kept / df$Original * 100, 2)
  return(df)
})
rownames(sc_features_to_exclude_summary) = names(sc)
knitr::kable(sc_features_to_exclude_summary, align="l", caption="Summary of excluded genes") %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))

# Now filter those genes that are to be filtered for all samples 
sc = purrr::map(list_names(sc), function(n) {
  assay_names = Seurat::Assays(sc[[n]])
  features_to_keep = purrr::map(values_to_names(assay_names), function(a) {
    features = rownames(sc[[n]][[a]])
    keep = features[!features %in% sc_features_to_exclude$AllSamples]
    return(keep)
  })
  return(subset(sc[[n]], features=purrr::flatten_chr(features_to_keep)))
})
```

After filtering, the size of the Seurat object is: 

```{r filter_size_after}
sc
```

## Quality control post filtering
The updated QC plots are: 

```{r qc_plot_cells_afterFiltering, fig.height=10}
# Now create plot per QC metric after filtering
p_list = list()
for (m in cell_qc_features) {
  p_list[[m]] = ggplot(sc_cell_metadata[, c("orig.ident", m, "IS_FILTERED")] %>% dplyr::filter(!IS_FILTERED), aes_string(x="orig.ident", y=m, fill="orig.ident", group="orig.ident")) +
    geom_violin(scale="width")

  # Adds points for samples with less than three cells since geom_violin does not work here
  p_list[[m]] = p_list[[m]] + 
    geom_point(data=sc_cell_metadata[, c("orig.ident", m, "IS_FILTERED")] %>% dplyr::filter(!IS_FILTERED, orig.ident %in% names(which(table(sc_cell_metadata$orig.ident) < 3))), aes_string(x="orig.ident", y=m, fill="orig.ident"), shape=21, size=2)
  
  # Now add style
  p_list[[m]] = p_list[[m]] + 
    AddStyle(title=m, legend_position="none", fill=param$col_samples, xlab="") + 
    theme(axis.text.x=element_text(angle=45, hjust=1))
  
  # Add filter threshold as segments to plot; min threshold lines are dashed and max threshold lines are twodashed
  if (nrow(cell_qc_thresholds[[m]]) > 0) {
    sample_names = sc_cell_metadata[, c("orig.ident", m, "IS_FILTERED")] %>% dplyr::filter(!IS_FILTERED) %>% dplyr::pull(orig.ident) %>% unique()
    p_list[[m]] = p_list[[m]] + geom_segment(data=cell_qc_thresholds[[m]] %>% dplyr::filter(orig.ident %in% sample_names), 
                                             aes(x=as.integer(as.factor(orig.ident))-0.5, 
                                                 xend=as.integer(as.factor(orig.ident))+0.5, 
                                                 y=value, yend=value, lty=threshold), colour="firebrick") +
      scale_linetype_manual(values=setNames(c("dashed", "F1"), c("max", "min")))
  }
}
p = patchwork::wrap_plots(p_list, ncol=2) + patchwork::plot_annotation("Distribution of feature values") 
p
```

```{r qc_plot_correlation_afterFiltering}
# Correlate QC metrics for cells
p_list = list()
sc_cell_metadata_plot_order = sample(1:nrow(sc_cell_metadata))

# nFeature vs nCount
m = paste0(c("nCount_", "nFeature_"), param$assay_raw)
p_list[[1]] = ggplot(sc_cell_metadata[sc_cell_metadata_plot_order, , drop=FALSE], aes_string(x=m[1], y=m[2], colour="orig.ident", alpha="IS_FILTERED")) +
  geom_point() + 
  scale_linetype_manual(values=setNames(c("dashed", "F1"), c("max", "min"))) +
  scale_alpha_manual(values=setNames(c(1, 0.1), c(FALSE, TRUE))) +
  AddStyle(col=param$col_samples) +
  guides(alpha = "none")
if (nrow(cell_qc_thresholds[[m[1]]]) > 0) {
  p_list[[1]] = p_list[[1]] + geom_vline(data=cell_qc_thresholds[[m[1]]], aes(xintercept=value, lty=threshold), colour="firebrick")
}
if (nrow(cell_qc_thresholds[[m[2]]]) > 0) {
  p_list[[1]] = p_list[[1]] + geom_hline(data=cell_qc_thresholds[[m[2]]], aes(yintercept=value, lty=threshold), colour="firebrick")
}
  
# nFeature vs percent_mt
m = c("percent_mt", paste0(c("nFeature_"), param$assay_raw))
p_list[[2]] = ggplot(sc_cell_metadata[sc_cell_metadata_plot_order, , drop=FALSE], aes_string(x=m[1], y=m[2], colour="orig.ident", alpha="IS_FILTERED")) +
  geom_point() +
  scale_linetype_manual(values=setNames(c("dashed", "F1"), c("max", "min"))) +
  scale_alpha_manual(values=setNames(c(1, 0.1), c(FALSE, TRUE))) +
  AddStyle(col=param$col_samples) +
  guides(alpha = "none")
if (nrow(cell_qc_thresholds[[m[1]]]) > 0) {
  p_list[[2]] = p_list[[2]] + geom_vline(data=cell_qc_thresholds[[m[1]]], aes(xintercept=value, lty=threshold), colour="firebrick")
}
if (nrow(cell_qc_thresholds[[m[2]]]) > 0) {
  p_list[[2]] = p_list[[2]] + geom_hline(data=cell_qc_thresholds[[m[2]]], aes(yintercept=value, lty=threshold), colour="firebrick")
}

# nFeature vs percent_ercc
if ("percent_ercc" %in% names(cell_qc_features)) {
  m = c("percent_ercc", paste0(c("nFeature_"), param$assay_raw))
  p_list[[3]] = ggplot(sc_cell_metadata[sc_cell_metadata_plot_order, , drop=FALSE], aes_string(x=m[1], y=m[2], colour="orig.ident", alpha="IS_FILTERED")) +
    geom_point() + 
    scale_linetype_manual(values=setNames(c("dashed", "F1"), c("max", "min"))) +
    scale_alpha_manual(values=setNames(c(1, 0.1), c(FALSE, TRUE))) +
    AddStyle(col=param$col_samples) +
    guides(alpha = "none")
  if (nrow(cell_qc_thresholds[[m[1]]]) > 0) {
    p_list[[3]] = p_list[[3]] + geom_vline(data=cell_qc_thresholds[[m[1]]], aes(xintercept=value, lty=threshold), colour="firebrick")
  }
  if (nrow(cell_qc_thresholds[[m[2]]]) > 0) {
    p_list[[3]] = p_list[[3]] + geom_hline(data=cell_qc_thresholds[[m[2]]], aes(yintercept=value, lty=threshold), colour="firebrick")
  }
}

# Combine plots
p = patchwork::wrap_plots(p_list, ncol=length(p_list)) + patchwork::plot_annotation("Features plotted against each other")
if (length(p_list)==1) {
  p = p & theme(legend.position="bottom")
} else {
  p = p + patchwork::plot_layout(guides="collect") & theme(legend.position="bottom")
}
p
```
```{r downsampling}
# If requested, determine number of cells for downsampling
if (is.null(param$downsample_cells_n) & param$downsample_cells_equally) {
  n = purrr::map_int(sc, ncol) %>% min()  
} else if (!is.null(param$downsample_cells_n)) {
  n = param$downsample_cells_n
}

# Actual downsampling
if (!is.null(param$downsample_cells_n) | param$downsample_cells_equally) {
  sc = purrr::map(sc, function(s) {
    cells = ScSampleCells(sc=s, n=n, seed=1)
    return(subset(s, cells=cells))
  })
  
  # Adjust combined metadata accordingly
  sc_cell_metadata = sc_cell_metadata[unlist(purrr::map(sc, Cells)), ]
  
  message("Your data has been downsampled.")
  print(sc)
}
```

```{r cleanup_metadata}
# Remove filtered cells from metadata
sc_cell_metadata = sc_cell_metadata %>% dplyr::filter(IS_FILTERED==FALSE)

# Update levels but make sure level order stays the same
idx.factors = sapply(sc_cell_metadata, is.factor) %>% which()
for (n in colnames(sc_cell_metadata[idx.factors])) {
  levels_old = sc_cell_metadata %>% dplyr::pull(n) %>% levels()
  levels_new = sc_cell_metadata %>% dplyr::pull(n) %>% as.character() %>% unique()
  sc_cell_metadata[[n]] = factor(sc_cell_metadata[[n]], levels=levels_old[levels_old %in% levels_new])
}

# Update actual colors as well, as they will appear in the plots otherwise
param$col_samples = param$col_samples[names(param$col_samples) %in% names(sc)]
```

## Normalisation
In this section, we subsequently run a series of Seurat functions for each provided sample:  

| 1. We start by running a __standard log normalisation__, where counts for each cell are divided by the total counts for that cell and multiplied by 10,000. This is then natural-log transformed.   
   
<details>
  <summary>What do we need normalisation for?</summary>

The number of raw sequencing reads per cell is influenced by technical differences in the capture, reverse transcription and sequencing of RNA molecules, particularly due to the difficulty of achieving consistent library preparation with minimal starting material. Thus, comparing gene expression between cells may reveal differences that are solely due to sampling effects. After low-quality cells were removed in the previous step, the primary goal of normalization is to remove technical sampling effects while preserving the true biological signal.

Count depth scaling is the simplest and most commonly used normalization strategy. The underlying idea is that each cell initially contained an equal number of mRNA molecules, and differences arise due to sampling effects. For each cell, the number of reads per gene is divided by a cell-specific “size factor”, which is proportional to the total count depth of the cell. The resulting normalized data add up to 1 per cell, and is then typically multiplied by a factor of 10 (10,000 in this workflow).

Finally, normalized data are log-transformed for three important reasons. First, distances between log-transformed expression data represent log fold changes. Log-transformation emphasizes contributions from genes with strong relative differences, for example a gene that is expressed at an average count of 50 in cell type A and 10 in cell type B rather than a gene that is expressed at an average count of 1100 in A and 1000 in B. Second, log-transformation mitigates the relation between mean and variance in the data. Lastly, log-transformation reduces that skewness of the data as many downstream analyses require the data to be normally distributed. 
</details>   
   
| 2. We assign __cell cycle scores__ to each cell based on its normalised expression of G2/M and S phase markers. These scores are visualised in a separate section further below. If specified in the above parameter section, cell cycle effects are removed during scaling (step 3). Cell cycle effects removed for this report: `r param$cc_remove`; _all_ cell cycle effects removed for this report: `r param$cc_remove_all`.   
   
<details>
  <summary>How does removal of cell cycle effects affect the data?</summary>

Note that removing all signal associated to cell cycle can negatively impact downstream analysis. For example, in differentiating processes, stem cells are quiescent and differentiated cells are proliferating (or vice versa), and removing all cell cycle effects can blur the distinction between these cells. An alternative approach is to remove the difference between G2M and S phase scores. This way, signals separating non-cycling and cycling cells will be maintained, while differences amongst proliferating cells will be removed. For a more detailed explanation, see the cell cycle vignette for Seurat `r Cite("https://satijalab.org/seurat/v3.1/cell_cycle_vignette.html")`.
</details>   
   
| 3. Dependent on the normalisation of your choice, we either   

| a. Run standard functions to select __variable genes__, and __scale__ normalised gene counts. For downstream analysis it is beneficial to focus on genes that exhibit high cell-to-cell variation, that is they are highly expressed in some cells and lowly in others. To be able to compare normalised gene counts between genes, gene counts are further scaled to have zero mean and unit variance (z-score). 
   
<details>
  <summary>What do we need scaling for?</summary>

After normalization, gene expression data can be compared between cells. However, expression of individual genes still cannot be compared. This is because genes have different lengths and, depending on the experimental set up, longer genes can be represented by a higher number of reads. To account for this effect, normalized data are further scaled using a z-transformation, resulting in the average expression of 0 and the variance of 1 for each gene across all cells. Note that additional unwanted sources of variations can be regressed out during the scaling process, such as cell cycle effects or the percentage of mitochondrial reads. 
</details>   
   
| b. Run __SCTransform__, a new and more sophisticated normalisation method that replaces the previous functions (__normalisation, variable genes and scaling__). 
   
<details>
  <summary>What is __SCTransform__ special about?</summary>

The standard log-transformation applied in step 1 assumes that count depth influences all genes equally. However, it has been shown that the use of a single size factor will introduce different effects on highly and lowly expressed genes (`r Cite("10.1186/s13059-019-1874-1")`). __SCTransform__ is a new statistical approach for the modelling, normalization and variance stabilization of single-cell RNA-seq data, and is an alternative to steps 1 and 3a described above. Note that __SCTransform__ has been developed for UMI count data and can therefore safely be applied to 10x but not SmartSeq-2 data. As for the scaling in step 3a, additional unwanted sources of variations can be regressed out during __SCTransform__. 
</details>   
   
Normalisation method used for this report: `r param$norm`; with additional sources of variance regressed out: `r param$vars_to_regress`.  

While raw data is typically used for statistical tests such as finding marker genes, normalised data is mainly used for visualising gene expression values. Scaled data include variable genes only, potentially without cell cycle effects, and are mainly used to determine the structure of the dataset(s) with Principal Component Analysis, and indirectly to cluster and visualise cells in 2D space. 

```{r part1_normalisation}
# Normalise data the original way
#   This is required to score cell cycle (https://github.com/satijalab/seurat/issues/1679)
sc = purrr::map(sc, Seurat::NormalizeData, normalization.method="LogNormalize", scale.factor=10000, verbose=FALSE)
```

```{r part2_cc_scores}
# Determine cell cycle effect per sample 
sc = purrr::map(list_names(sc), function(n) {
  sc[[n]] = CCScoring(sc=sc[[n]], genes_s=genes_s[,2], genes_g2m=genes_g2m[,2], name=n)
  if (any(is.na(sc[[n]][["S.Score"]])) | any(is.na(sc[[n]][["G2M.Score"]]))) {
    param$cc_remove=FALSE
    param$cc_remove_all=FALSE
    param$cc_rescore_after_merge=FALSE
  }
  return(sc[[n]])
})

# If cell cycle effects should be removed, we first score cells 
# The effect is then removed in the following chunk 
if (param$cc_remove) {
# Add to vars that need to regressed out during normalisation
  if (param$cc_remove_all) {
    # Remove all signal associated to cell cycle
    param$vars_to_regress = unique(c(param$vars_to_regress, "S.Score", "G2M.Score"))
    param$latent_vars = unique(c(param$latent_vars, "S.Score", "G2M.Score"))
  } else {
    # Don't remove the difference between cycling and non-cycling cells 
    param$vars_to_regress = unique(c(param$vars_to_regress, "CC.Difference"))
    param$latent_vars = unique(c(param$latent_vars, "CC.Difference"))
  }  
}
```

```{r part3_normalisation, results="hide", warning=FALSE}
if (param$norm == "RNA") { 
  # Find variable features from normalised data (unaffected by scaling)
  sc = purrr::map(sc, Seurat::FindVariableFeatures, selection.method="vst", nfeatures=3000, verbose=FALSE)
  
  # Scale 
  # Note: For a single dataset where no integration/merging is needed, all features can already be scaled here. 
  #   Otherwise, scaling of all features will be done after integration/merging.
  if (param$integrate_samples[["method"]]=="single") {
    sc[[1]] = Seurat::ScaleData(sc[[1]], 
                      features=rownames(sc[[1]][["RNA"]]),
                      vars.to.regress=param$vars_to_regress, 
                      verbose=FALSE) 
  }
} else if (param$norm == "SCT") {
  # Run SCTransform
  #
  # This is a new normalisation method that replaces previous Seurat functions "NormalizeData", "FindVariableFeatures", and "ScaleData". 
  # vignette: https://satijalab.org/seurat/v3.0/sctransform_vignette.html
  # paper: https://www.biorxiv.org/content/10.1101/576827v2
  # Normalised data end up here: sc@assays$SCT@data
  # Note: For a single dataset where no integration is needed, all features can already be scaled here. 
  #   Otherwise, it is enough to scale only the variable features.
  # Note: It is not guaranteed that all genes are successfully normalised with SCTransform. 
  #   Consequently, some genes might be missing from the SCT assay. 
  #   See: https://github.com/ChristophH/sctransform/issues/27
  # Note: The performance of SCTransform can be improved by using "glmGamPoi" instead of "poisson" as method for initial parameter estimation.
  sc = purrr::map(list_names(sc), function(n) { 
    SCTransform(sc[[n]], 
                assay=param$assay_raw,
                vars.to.regress=param$vars_to_regress, 
                min_cells=param$feature_filter[[n]][["min_cells"]], 
                verbose=FALSE, 
                return.only.var.genes=!(param$integrate_samples[["method"]]=="single"),
                method=ifelse(packages_installed("glmGamPoi"), "glmGamPoi", "poisson")) 
  })
}
```

Experience shows that 1,000-2,000 genes with the highest cell-to-cell variation are often sufficient to describe the global structure of a single-cell dataset. For example, cell type-specific genes typically highly vary between cells. Housekeeping genes, on the other hand, are similarly expressed across cells and can be disregarded to differentiate between cells. Highly variable genes are typically the genes with a cell type specific expression profile, and are often the genes of interest in single-cell experiments. Housekeeping genes, with similar levels of expression across all cells, or genes with minor expression differences, might add random noise and mask relevant changes during downstream dimensionality reduction and clustering. We therefore aim to select a sensible set of variable genes that includes interesting biological signal and excludes noise. Here, the top 3,000 variable genes are selected and used for downstream analysis. 

<details>
  <summary>How are variable genes selected?</summary>

To determine variable genes, we need to separate biological variability from technical variability. Technical variability arises especially for lowly expressed genes, where high variability corresponds to small absolute changes that we are not interested in. Here, we use the variance-stabilizing transformation (vst) method implemented in Seurat (`r Cite("10.1186/s13059-019-1874-1")`). This method first models the technical variability as a relationship between mean gene expression and variance using local polynomial regression. The model is then used to calculate the expected variance based on the observed mean gene expression. The difference between the observed and expected variance is called residual variance and likely reflects biological variability.
</details>

```{r plot_variable_features_heights}
fig_height_vf = 5 * ceiling(length(names(sc))/2)
```

```{r plot_variable_features, warning=FALSE, fig.height=fig_height_vf}
p_list = purrr::map(list_names(sc), function(n) {
  top10 = head(Seurat::VariableFeatures(sc[[n]], assay=ifelse(param$norm=="SCT", param$norm, param$assay_raw)), 10)
  p = Seurat::VariableFeaturePlot(sc[[n]], 
                                  assay=ifelse(param$norm=="SCT", param$norm, param$assay_raw), 
                                  selection.method=ifelse(param$norm=="RNA", "vst", "sct"), 
                                  col=c("grey", param$col)) + 
    AddStyle(title=n) + 
    theme(legend.position=c(0.2, 0.8), legend.background=element_rect(fill=alpha("white", 0.0)))
  p = LabelPoints(plot=p, points=top10, repel=TRUE, xnudge=0, ynudge=0)
  return(p)
})

p = patchwork::wrap_plots(p_list, ncol=2) + patchwork::plot_annotation("Variable genes")
p
```

## Combining multiple samples

```{r multi_dataset_integration_single, eval=(param$integrate_samples[["method"]]=="single"), include=(param$integrate_samples[["method"]]=="single")}
# Called when there is only a single sample and no integration needed
# Default assay is set automatically
if (param$integrate_samples[["method"]]=="single") {
  sc = sc[[1]]
  message("Your dataset contains 1 sample only. No merging/integrating required.")
}
```

```{r multi_dataset_integration_preparation, eval=(param$integrate_samples[["method"]]!="single"), include=(param$integrate_samples[["method"]]!="single"), results="asis"}
if (param$integrate_samples[["method"]]!="single") {
  
  # When merging, feature meta-data is removed by Seurat entirely; save separately for each assay except for SCT and add again afterwards
  # Note: not sure whether this is still needed - discuss
  assay_names = setdiff(unique(purrr::flatten_chr(purrr::map(list_names(sc), function(n) { Seurat::Assays(sc[[n]]) } ))), "SCT")

  # Loop through all assays and accumulate meta data
  sc_feature_metadata = purrr::map(values_to_names(assay_names), function(a) {
    # "feature_id", "feature_name", "feature_type" are accumulated for all assays and stored just once
    # This step is skipped for assays that do not contain all three types of feature information
    contains_neccessary_columns = purrr::map_lgl(list_names(sc), function(n) { 
      all(c("feature_id", "feature_name", "feature_type") %in% colnames(sc[[n]][[a]][[]])) 
      })

    if (all(contains_neccessary_columns)) {
      feature_id_name_type = purrr::map(sc, function(s) return(s[[a]][[c("feature_id", "feature_name", "feature_type")]]) )
      feature_id_name_type = purrr::reduce(feature_id_name_type, function(df_x, df_y) {
        new_rows = which(!rownames(df_y) %in% rownames(df_x))
        if (length(new_rows) > 0) return(rbind(df_x, df_y[new_rows, ]))
        else return(df_x)
      })
      feature_id_name_type$row_names = rownames(feature_id_name_type)
    } else {
      feature_id_name_type = NULL
    }
    
    # For all other meta-data, we prefix column names with the dataset
    other_feature_data = purrr::map(list_names(sc), function(n) {
      df = sc[[n]][[a]][[]]
      if (contains_neccessary_columns[[n]]) df = df %>% dplyr::select(-dplyr::one_of(c("feature_id", "feature_name", "feature_type"), c()))
      if (ncol(df) > 0) colnames(df) = paste(n, colnames(df), sep=".")
      df$row_names = rownames(df)
      return(df)
    })
    
    # Now join everything by row_names by full outer join
    if (!is.null(feature_id_name_type)) {
      feature_data = purrr::reduce(c(list(feature_id_name_type=feature_id_name_type), other_feature_data), dplyr::full_join, by="row_names")
    } else {
      feature_data = purrr::reduce(other_feature_data, dplyr::full_join, by="row_names")
    }
    rownames(feature_data) = feature_data$row_names
    feature_data$row_names = NULL
    
    return(feature_data)
  })
  
  # When merging, cell meta-data are merged but factors are not kept
  sc_cell_metadata = suppressWarnings(purrr::map_dfr(sc, function(s){ s[[]] }) %>% as.data.frame())
  sc_cell_metadata_factor_levels = purrr::map(which(sapply(sc_cell_metadata, is.factor)), function(n) {
    return(levels(sc_cell_metadata[, n, drop=TRUE]))
  })
}
```

```{r multi_dataset_integration_merge, eval=(param$integrate_samples[["method"]]=="merge"), include=(param$integrate_samples[["method"]]=="merge")}
# Data for different samples can be merged if no integration is needed, 
#   for example, when samples were multiplexed on the same chip
if (param$integrate_samples[["method"]]=="merge") {
  sc = merge(x=sc[[1]], y=sc[2:length(sc)], project=param$project_id)

  # Re-score cell cycle effects after merge
  if (param$cc_rescore_after_merge) {
    sc = CCScoring(sc=sc, genes_s=genes_s[,2], genes_g2m=genes_g2m[,2])
    if (any(is.na(sc[["S.Score"]])) | any(is.na(sc[["G2M.Score"]]))) {
      param$cc_remove=FALSE
      param$cc_remove_all=FALSE
      param$cc_rescore_after_merge=FALSE
      param$vars_to_regress = setdiff(param$vars_to_regress, c("S.Score", "G2M.Score", "CC.Difference"))
      param$latent_vars = setdiff(param$latent_vars, c("S.Score", "G2M.Score", "CC.Difference"))
    }
  }
  
  # (Re-)Run normalisation, variable features and scaling
  if (param$norm == "RNA") {
    # Find variable features in RNA assay
    sc = Seurat::FindVariableFeatures(sc, selection.method="vst", nfeatures=3000, verbose=FALSE)
   
    # Scale RNA assay
    # Note: Removing cell cycle effects in scaled data can be very slow
    sc = Seurat::ScaleData(sc, features=rownames(sc[[param$assay_raw]]), vars.to.regress=param$vars_to_regress, verbose=FALSE, assay=param$assay_raw)
  
  } else if (param$norm == "SCT") {
    # Rerun SCTransform
    min_cells_overall = max(purrr::map_int(param$feature_filter, function(f) as.integer(f[["min_cells"]])))
    sc = suppressWarnings(SCTransform(sc, 
                                      assay=param$assay_raw,
                                      vars.to.regress=param$vars_to_regress, 
                                      min_cells=min_cells_overall, 
                                      verbose=FALSE, 
                                      return.only.var.genes=FALSE,
                                      method=ifelse(packages_installed("glmGamPoi"), "glmGamPoi", "poisson")))
  }
  
  # Add feature metadata
  for (a in Seurat::Assays(sc)) {
    if (a %in% names(sc_feature_metadata)) {
      sc[[a]] = Seurat::AddMetaData(sc[[a]], sc_feature_metadata[[a]][rownames(sc[[a]]),, drop=FALSE])
    }
  }

  # Fix cell metadata factors
  for (f in names(sc_cell_metadata_factor_levels)) {
    sc[[f]] = factor(sc[[f, drop=TRUE]], levels=sc_cell_metadata_factor_levels[[f]])
  }
  
  # Add sample/dataset colours again to misc slot
  sc = ScAddLists(sc, lists=list(orig.ident=param$col_samples), lists_slot="colour_lists")
  
  message("Data values for all samples have been merged. This means that data values have been concatenated, not integrated.")
  print(sc)
}
```

```{r multi_dataset_integration_integrate, eval=(param$integrate_samples[["method"]]=="integrate"), include=(param$integrate_samples[["method"]]=="integrate"), warning=FALSE}
# Standard method for integrating multiple samples. Best performance but computationally intensive.
if (param$integrate_samples[["method"]]=="integrate") {
  if (!"use_reciprocal_pca" %in% names(param$integrate_samples)) param$integrate_samples[["use_reciprocal_pca"]] = FALSE

  # Run integration
  sc = RunIntegration(sc, 
                      assay=param$norm,
                      ndims=param$integrate_samples[["dimensions"]], 
                      verbose=FALSE, 
                      reference=param$integrate_samples[["reference"]], 
                      use_reciprocal_pca=param$integrate_samples[["use_reciprocal_pca"]], 
                      k_filter=param$integrate_samples[["k.filter"]], 
                      k_weight=param$integrate_samples[["k.weight"]], 
                      k_anchor=param$integrate_samples[["k.anchor"]],
                      k_score=param$integrate_samples[["k.score"]])

  # Re-score cell cycle effects after integration
  if (param$cc_rescore_after_merge) {
    sc = CCScoring(sc=sc, genes_s=genes_s[,2], genes_g2m=genes_g2m[,2])
    if (any(is.na(sc[["S.Score"]])) | any(is.na(sc[["G2M.Score"]])))  {
      param$cc_remove=FALSE
      param$cc_remove_all=FALSE
      param$cc_rescore_after_merge=FALSE
      param$vars_to_regress = setdiff(param$vars_to_regress, c("S.Score", "G2M.Score", "CC.Difference"))
      param$latent_vars = setdiff(param$latent_vars, c("S.Score", "G2M.Score", "CC.Difference"))
    }
  }
  
  # (Re-)Run scaling
  if (param$norm == "RNA") {
    # According to Seurat, we need to scale data again for "RNAintegrated", and "RNA"
    DefaultAssay(sc) = "RNAintegrated"
    sc = Seurat::ScaleData(sc, 
                                features=rownames(sc[["RNAintegrated"]]), 
                                vars.to.regress=param$vars_to_regress, 
                                assay="RNAintegrated",
                                verbose=FALSE)
      
    DefaultAssay(sc) = "RNA"
    sc = Seurat::ScaleData(sc, 
                                features=rownames(sc[["RNA"]]), 
                                vars.to.regress=param$vars_to_regress, 
                                assay="RNA",
                                verbose=FALSE)
  } else if (param$norm == "SCT") {
    # We need to re-run SCTransform for the "SCT" assay again, to normalise on the complete dataset
    DefaultAssay(sc) = "SCT"
    min_cells_overall = max(purrr::map_int(param$feature_filter, function(f) as.integer(f[["min_cells"]])))
    sc = SCTransform(sc, 
                     assay=param$assay_raw, 
                     vars.to.regress=param$vars_to_regress, 
                     min_cells=min_cells_overall,
                     verbose=FALSE,
                     return.only.var.genes=FALSE,
                     method=ifelse(packages_installed("glmGamPoi"), "glmGamPoi", "poisson"))
  }
  
  # Add feature metadata
  for (a in Seurat::Assays(sc)) {
    if (a %in% names(sc_feature_metadata)) {
      sc[[a]] = Seurat::AddMetaData(sc[[a]], sc_feature_metadata[[a]][rownames(sc[[a]]),, drop=FALSE])
    }
  }
  
  # Fix cell metadata factors
  for (f in names(sc_cell_metadata_factor_levels)) {
    sc[[f]] = factor(sc[[f, drop=TRUE]], levels=sc_cell_metadata_factor_levels[[f]])
  }
  
  # Add sample colours again to misc slot
  sc = ScAddLists(sc, lists=list(orig.ident=param$col_samples), lists_slot="colour_lists")

  # Set default assay (will be the integrated version)
  DefaultAssay(sc) = paste0(param$norm, "integrated")  
  
  message("Data values for all samples have been integrated.")
  print(sc)
  
  # Add sample as latent_vars for marker detection
  param$latent_vars = c(param$latent_vars, "orig.ident")
}
```

## Relative log expression {.tabset}

```{r plot_RLE_prep}
n_cells_rle_plot = 100

# Sample at most 100 cells per dataset and save their identity
cells_subset = sc[["orig.ident"]] %>% tibble::rownames_to_column() %>% 
  dplyr::group_by(orig.ident) %>% 
  dplyr::sample_n(size=min(n_cells_rle_plot, length(orig.ident))) %>% 
  dplyr::select(rowname, orig.ident)
  
```

To better understand the efficiency of the applied normalisation procedures, we plot the relative log expression of genes in at most `r n_cells_rle_plot` randomly selected cells per sample before and after normalisation. This type of plot reveals unwanted variation in your data. The concept is taken from `r Cite("10.1371/journal.pone.0191629")`. In brief, we remove variation between genes, leaving only variation between samples. If expression levels of most genes are similar in all cell types, sample heterogeneity is a sign of unwanted variation.

For each gene, we calculate its median expression across all cells, and then calculate the deviation from this median for each cell. For each cell, we plot the median expression (black), the interquartile range (<span style="color:lightgrey;font-weight:bold">lightgrey</span>), whiskers defined as 1.5 times the interquartile range (<span style="color:darkgrey;font-weight:bold">darkgrey</span>), and outliers (`r paste0('<span style="color:', param$col_samples, ';font-weight:bold">', param$col_samples, '</span>', collapse=', ')`)

### Raw counts

```{r plot_RLE_raw}
# Plot raw data
p = PlotRLE(as.matrix(log2(GetAssayData(subset(sc, cells=cells_subset$rowname), assay=param$assay_raw, slot="counts") + 1)), 
            id=cells_subset$orig.ident, 
            col=param$col_samples) + 
  labs(title="log2(raw counts + 1)")
p
```

### Normalised data
Dependent on the context, this tab refers to different data:   

* Single sample: `r param$norm` normalisation of the single sample   
* Multiple samples that were merged: Combined `r param$norm` normalisation post merging of all samples   
* Multiple samples that were integrated: Separate `r param$norm` normalisation prior to integration of all samples   

```{r plot_RLE_norm}
# Plot normalised data
p = PlotRLE(as.matrix(GetAssayData(subset(sc, cells=cells_subset$rowname), assay=ifelse(param$norm=="SCT", param$norm, param$assay_raw), slot="data")), 
            id=cells_subset$orig.ident, 
            col=param$col_samples) + 
  labs(title="Normalised data")
p
```

### Integrated data

```{r plot_RLE_integrated}
if (! param$integrate_samples[["method"]] %in% c("single", "merge")) {
  # Plot integrated data
  p = PlotRLE(as.matrix(GetAssayData(subset(sc, cells=cells_subset$rowname), assay=paste0(param$norm, "integrated"), slot="data")), 
              id=cells_subset$orig.ident, 
              col=param$col_samples) + 
    labs(title="Integrated data")
  p
} else {
  message("No integrated data available.")
}
```
  
## Dimensionality reduction
A single-cell dataset of 20,000 genes and 5,000 cells has 20,000 dimensions. At this point of the analysis, we have already reduced the dimensionality of the dataset to 3,000 variable genes. The biological manifold however can be described by far fewer dimensions than the number of (variable) genes, since expression profiles of different genes are correlated if they are involved in the same biological process. Dimension reduction methods aim to find these dimensions. There are two general purposes for dimension reduction methods: to __summarize__ a dataset, and to __visualize__ a dataset. 

We use Principal Component Analysis (PCA) to __summarize__ a dataset, overcoming noise and reducing the data to its essential components. Later, we use Uniform Manifold Approximation and Projection (UMAP) to __visualize__ the dataset, placing similar cells together in 2D space, see below. 

<details>
  <summary>PCA in a nutshell</summary>

Principal Component Analysis is a way to summarize a dataset and to reduce noise by averaging similar gene expression profiles. The information for correlated genes is compressed into single dimensions called principal components (PCs) and the analysis identifies those dimensions that capture the largest amount of variation. This process gives a more precise representation of the patterns inherent to complex and large datasets.

In a PCA, the first PC captures the greatest variance across the whole dataset. The next PC captures the greatest remaining amount of variance, and so on. This way, the top PCs are likely to represent the biological signal where multiple genes are affected by the same biological processes in a coordinated way. In contrast, random technical or biological noise that affects each gene independently are contained in later PCs. Downstream analyses can be restricted to the top PCs to focus on the most relevant biological signal and to reduce noise and unnecessary computational overhead. 
</details>

To decide how many PCs to include in downstream analyses, we visualise the cells and genes that define the PCA.

```{r run_pca}
# Run PCA for default normalisation
sc = Seurat::RunPCA(sc, features=Seurat::VariableFeatures(object=sc), verbose=FALSE, npcs=min(50, ncol(sc)))
```

```{r pca_loadings}
p_list = Seurat::VizDimLoadings(sc, dims=1:2, reduction="pca", col=param$col, combine=FALSE, balanced=TRUE)
for (i in seq(p_list)) p_list[[i]] = p_list[[i]] + AddStyle()
p =  patchwork::wrap_plots(p_list, ncol=2) + patchwork::plot_annotation("Top gene loadings of the first two PCs") 
p
```

```{r pca_dims}
p = Seurat::DimPlot(sc, reduction="pca", cols=param$col_samples) + 
  AddStyle(title="Cells arranged by the first two PCs", legend_position="bottom")
p
```

```{r pca_heatmaps, fig.height=20}
p_list = Seurat::DimHeatmap(sc, dims=1:min(20, ncol(sc)), cells=min(500, ncol(sc)), balanced=TRUE, fast=FALSE, combine=FALSE)
p_list = purrr::map(seq(p_list), function(i) {
  p_list[[i]] = p_list[[i]] + 
    ggtitle(paste("PC", i)) + 
    theme(legend.position="none", axis.text.y=element_text(size=8))
  return(p_list[[i]])
  })
p = patchwork::wrap_plots(p_list, ncol=3) + patchwork::plot_annotation("Top gene loadings of the first PCs")
p
```

## Dimensionality of the dataset
We next need to decide how many PCs we want to use for our analyses. PCs include biological signal as well as noise, and we need to determine the number of PCs with which we include as much biological signal as possible and as little noise as possible. The following "Elbow plot" is designed to help us make an informed decision. It shows PCs ranked based on the percentage of variance they explain.

<details>
  <summary>How do we determine the number of PCs for downstream analysis?</summary>

The top PC captures the greatest variance across cells and each subsequent PC represents decreasing levels of variance. By visual inspection of the Elbow plot, we try to find the point at which we can explain most of the variance across cells. Commonly, the top 10 PCs are chosen. It may be helpful to repeat downstream analyses with a different number of PCs, although the results often do not differ dramatically. Note that it is recommended to rather choose too many than too few PCs. 
</details>

```{r dimensionality}
# More approximate technique used to reduce computation time
p = Seurat::ElbowPlot(sc, ndims=min(20, ncol(sc))) + 
  geom_vline(xintercept=param$pc_n + .5, col="firebrick", lty=2) + 
  AddStyle(title="Elbow plot") 
p

# Cannot have more PCs than number of cells
param$pc_n = min(param$pc_n, ncol(sc))
```

For the current dataset, `r param$pc_n` PCs were chosen.

# Clustering
Seurat's clustering method first constructs a graph structure, where nodes are cells and edges are drawn between cells with similar gene expression patterns. Technically speaking, Seurat first constructs a K-nearest neighbor (KNN) graph based on Euclidean distance in PCA space, and refines edge weights between cells based on the shared overlap in their local neighborhoods (Jaccard similarity). To partition the graph into highly interconnected parts, cells are iteratively grouped together using the Leiden algorithm `r Cite("10.1038/s41598-019-41695-z", "citep")`. 

<details>
  <summary>Further explanation on clustering</summary>

At this point, we would like to define subpopulations of cells with similar gene expression profiles using unsupervised clustering. Clusters ultimately serve as approximations for biological objects like cell types or cell states.

During the first step of clustering, a K-nearest neighbor (KNN) graph is constructed. In simplified terms this means that cells are connected to their K nearest neighbors based on cell-to-cell expression similarity using the PCs chosen in the previous step. The higher the similarity is, the higher the edge weight becomes. During the second step, the graph is partitioned into highly interconnected communities, whereby each community represents a cluster of cells with similar expression profiles. The separation of the graph into clusters is dependent on the chosen resolution. For scRNA-seq datasets of around 3000 cells, it is recommended to use a resolution value between 0.4 and 1.2. This value can be set even higher for larger datasets. Note that the choice of PCs and cluster resolution is an arbitrary one. Therefore, it is highly recommended to evaluate clusters and re-run the workflow with adapted parameters if needed. 
</details>

To get a first idea about how different cluster resolution values influence the clustering, we run and visualize the clustering multiple times, see below. For this report, you chose the resolution value `r param$cluster_resolution` as the final value for further analyses. 

```{r clustering}
cluster_resolutions = sort(unique(c(param$cluster_resolution, param$cluster_resolution_test)))

# Construct phylogenetic tree relating the "average" cell from each sample
if (length(levels(sc$orig.ident)) > 1) {
  sc = suppressWarnings(Seurat::BuildClusterTree(sc, features=rownames(sc), verbose=FALSE))
  Seurat::Misc(sc, "trees") = list(orig.ident = Seurat::Tool(sc, "Seurat::BuildClusterTree"))
}

# The number of clusters can be optimized by tuning "resolution" -> based on feedback from the client whether or not clusters make sense
# Choose the number of PCs to use for clustering
sc = Seurat::FindNeighbors(sc, dims=1:param$pc_n, verbose=FALSE, k.param=param$cluster_k)

# Seurat vignette suggests resolution parameter between 0.4-1.2 for datasets of about 3k cells
# But we can run multiple resolutions if requested
sc = Seurat::FindClusters(sc, resolution=cluster_resolutions, algorithm=4, verbose=FALSE, method="igraph")

# Construct phylogenetic tree relating the "average" cell from each cluster for each clustering
# Also add colour lists for each clustering
for(r in cluster_resolutions) {
  n = paste0(DefaultAssay(sc), "_snn_res.", r)
  
  # Tree
  if (length(levels(sc[[n, drop=TRUE]])) > 1) {
    Seurat::Idents(sc) = n
    sc = suppressWarnings(Seurat::BuildClusterTree(sc, dims=1:param$pc_n, verbose=FALSE))
    l = list(Seurat::Tool(sc, "Seurat::BuildClusterTree"))
    names(l) = n
    suppressWarnings({Seurat::Misc(sc, "trees") = c(Seurat::Misc(sc, "trees"), l)})
  }
  
  col = GenerateColours(num_colours=length(levels(sc[[n, drop=TRUE]])), names=levels(sc[[n, drop=TRUE]]), 
                                     palette=param$col_palette_clusters, alphas=1)
  # Colours
  l = list(col)
  names(l) = n
  sc = ScAddLists(sc, lists=l, lists_slot="colour_lists")
}

# Set default clustering
n = paste0(DefaultAssay(sc), "_snn_res.", param$cluster_resolution)
sc$seurat_clusters = sc[[n, drop=TRUE]]
Seurat::Idents(sc) = sc$seurat_clusters
if (length(levels(sc$seurat_clusters)) > 1) {
  suppressWarnings({Seurat::Misc(sc, "trees") = c(Seurat::Misc(sc, "trees"), list(seurat_clusters = Seurat::Misc(sc, "trees")[[n]]))})
}

# Set up colors for default clustering
sc = ScAddLists(sc, lists=list(seurat_clusters=Misc(sc, "colour_lists")[[n]]), lists_slot="colour_lists")
param$col_clusters = Misc(sc, "colour_lists")[["seurat_clusters"]]

# Define height of test clusters
height_per_row = 3
nr_cols = 3
nr_rows = ceiling(length(cluster_resolutions)/nr_cols)
fig_height_test_clusters = nr_rows * height_per_row
```

```{r run_umap_test, fig.height=fig_height_test_clusters}
# Default UMAP
sc = suppressWarnings(Seurat::RunUMAP(sc, dims=1:param$pc_n, verbose=FALSE, umap.method="uwot", n.neighbors=param$umap_k))

# If there are any test resolutions other than the default, go ahead
if (length(cluster_resolutions) > 1) {
  p_list = list()
  for(r in cluster_resolutions) {
    r = as.character(r)
    n = paste0(DefaultAssay(sc), "_snn_res.", r)
    
    cluster_cells = table(sc[[n, drop=TRUE]])
    cluster_labels = paste0(names(cluster_cells)," (", cluster_cells,")")
    
    p_list[[r]] = Seurat::DimPlot(sc, reduction="umap", group.by=n, pt.size=param$pt_size, label=TRUE) + 
      scale_color_manual(values=Seurat::Misc(sc, "colour_lists")[[n]], labels=cluster_labels) +
      AddStyle(title=r, legend_position="none") +
      FontSize(x.text = 10, y.text = 10, x.title = 13, y.title = 13, main = 15)
  }
  
  p = patchwork::wrap_plots(p_list, ncol=nr_cols) + patchwork::plot_annotation(title="UMAP, cells coloured by cluster identity for different resolution values")
  print(p)
}
```

# Visualisation with UMAP {.tabset}
We use a UMAP to visualise and explore a dataset. The goal is to place similar cells together in 2D space, and learn about the biology underlying the data. Cells are color-coded according to the graph-based clustering, and clusters typcially co-localise on the UMAP.

Take care not to mis-read a UMAP:

* Parameters influence the plot (we use defaults here)
* Cluster sizes relative to each other mean nothing, since the method has a local notion of distance
* Distances between clusters might not mean anything
* You may need more than one plot

For a nice read to intuitively understand UMAP, see `r Cite("https://pair-code.github.io/understanding-umap/")`.

## Coloured by cluster

```{r umap_by_cluster}
# Note that you can set `label = TRUE` or use the LabelClusters function to help label individual clusters
cluster_cells = table(sc@active.ident)
cluster_labels = paste0(levels(sc@active.ident)," (", cluster_cells[levels(sc@active.ident)],")")
p = Seurat::DimPlot(sc, reduction="umap", group.by="seurat_clusters") + 
  scale_color_manual(values=param$col_clusters, labels=cluster_labels) +
  AddStyle(title="UMAP, cells coloured by cluster identity", legend_position="bottom", legend_title="Clusters")
p = LabelClusters(p, id="seurat_clusters", box=TRUE, fill="white")
p
```

## Coloured by cluster (per sample)

```{r umap_by_cluster_separately}
# Plot all samples separately
# Repel will be deactivated if there are more than six samples; otherwise the plot may crash
p = Seurat::DimPlot(sc, reduction="umap", group.by="seurat_clusters", pt.size=param$pt_size, split.by = "orig.ident", ncol = 2) +
  scale_color_manual(values=param$col_clusters, labels=cluster_labels) +
  AddStyle(title="UMAP, cells coloured by cluster identity", legend_position="bottom", legend_title="Clusters")
p = LabelClusters(p, id="seurat_clusters", box=TRUE, fill="white", repel=ifelse(length(unique(sc$orig.ident)) <= 5, TRUE, FALSE))
p
```

## Coloured by sample

```{r umap_by_sample}
sample_cells = table(sc$orig.ident)
sample_labels = paste0(levels(sc$orig.ident)," (", sample_cells[levels(sc$orig.ident)],")")
# Note: This is a hack to colour by sample but label by Cluster
p = Seurat::DimPlot(sc, reduction="umap", group.by="orig.ident") +
  scale_color_manual(values=param$col_samples, labels=sample_labels) +
  AddStyle(title="UMAP, cells coloured by sample of origin", legend_position="bottom")
p$data$seurat_clusters = sc[["seurat_clusters"]][rownames(p$data), ]
p = LabelClusters(p, id="seurat_clusters", box=TRUE, segment.color="black", fill="white")
p
```

## Coloured by sample (per sample)

```{r umap_by_sample_separately}
# Plot all samples separately
# Repel will be deactivated if there are more than six samples; otherwise the plot may crash
p = Seurat::DimPlot(sc, reduction="umap", group.by="orig.ident", pt.size=param$pt_size, split.by = "orig.ident", ncol = 2) +
  scale_color_manual(values=param$col_samples, labels=sample_labels) +
  AddStyle(title="UMAP, cells coloured by sample of origin", legend_position="bottom")
p$data$seurat_clusters = sc[["seurat_clusters"]][rownames(p$data), ]
p = LabelClusters(p, id="seurat_clusters", box=TRUE, segment.color="black", fill="white", repel=ifelse(length(unique(sc$orig.ident)) <= 5, TRUE, FALSE))
p
``` 

<!--
# Subclustering {.tabset}

Based on your request, we further split clusters. 

```{r subclustering_prepare, eval=FALSE}
# Save original clustering
sc$seurat_clusters_original = sc$seurat_clusters
```

## Cluster 10

```{r subclustering_10, eval=FALSE}
# Run subclustering
sc = Seurat::FindSubCluster(object=sc,
                            cluster="10",
                            graph.name=paste(Seurat::DefaultAssay(sc), "snn", sep="_"),
                            subcluster.name="subcluster",
                            resolution=0.1,
                            algorithm=4)

# Plot
p = Seurat::DimPlot(sc, reduction="umap", group.by="subcluster", label=TRUE) + 
  AddStyle(title="UMAP, cells coloured by cluster identity", legend_position="bottom", legend_title="Clusters")
p

p = VlnPlot(sc, features=c("Cd4", "Cd8a"), group.by="subcluster", pt.size=0) 
p
```

```{r subclustering_10_save, eval=FALSE}
# If subclustering is okay confirm
sc$seurat_clusters = sc$subcluster
sc$subcluster = NULL
Idents(sc) = "seurat_clusters"
```
-->

# Distribution of cells in clusters

```{r cells_per_cluster}
# Count cells per cluster per sample 
cell_samples = sc[[]] %>% dplyr::pull(orig.ident) %>% levels()
cell_clusters = sc[[]] %>% dplyr::pull(seurat_clusters) %>% levels()

tbl = dplyr::count(sc[[c("orig.ident", "seurat_clusters")]], orig.ident, seurat_clusters) %>% tidyr::pivot_wider(names_from="seurat_clusters", names_prefix="Cl_", values_from=n, values_fill=0) %>% as.data.frame()
rownames(tbl) = paste0(tbl[,"orig.ident"],"_n")
tbl[,"orig.ident"] = NULL

# Add percentages
tbl_perc = round(t(tbl) / colSums(tbl) * 100, 2) %>% t()
rownames(tbl_perc) = gsub(rownames(tbl_perc), pattern="_n$", replacement="_perc", perl=TRUE)
tbl = rbind(tbl, tbl_perc)

# Add enrichment
if (length(cell_samples) > 1 & length(cell_clusters) > 1) tbl = rbind(tbl, CellsFisher(sc))

# Sort
tbl = tbl[order(rownames(tbl)),, drop=FALSE]

# Plot percentages
tbl_bar = tbl[paste0(cell_samples, "_perc"), , drop=FALSE] %>% 
  tibble::rownames_to_column(var="Sample") %>%
  tidyr::pivot_longer(tidyr::starts_with("Cl"), names_to="Cluster", values_to="Percentage")
tbl_bar$Cluster = tbl_bar$Cluster %>% gsub(pattern="^Cl_", replacement="", perl=TRUE) %>% factor(levels=sc$seurat_clusters %>% levels())
tbl_bar$Sample = tbl_bar$Sample %>% gsub(pattern="_perc$", replacement="", perl=TRUE) %>% as.factor()
tbl_bar$Percentage = as.numeric(tbl_bar$Percentage)
p = ggplot(tbl_bar, aes(x=Cluster, y=Percentage, fill=Sample)) + 
  geom_bar(stat="identity" ) +
  AddStyle(title="Percentage cells of samples in clusters",
           fill=param$col_samples,
           legend_title="Sample",
           legend_position="bottom")
p
```

The following table shows the number of cells per sample and cluster:   

* n: Number of cells per sample and cluster   
* perc: Percentage of cells per sample and cluster compared to all other cells of that cluster   

In case the dataset contains 2 or more samples, we also calculate whether or not the number of cells of a sample in a cluster is significantly higher or lower than expected:      

* oddsRatio: Odds ratio calculated for cluster c1 and sample s1 as (# cells s1 in c1 / # cells not s1 in c1) / (# cells s1 not in c1 / # cells not s1 not in c1)    
* p: P-value calculated with a Fisher test to test whether "n" is higher or lower than expected  

```{r cells_per_cluster_table}
# Print table
knitr::kable(tbl, align="l", caption="Number of cells per sample and cluster") %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover")) %>% 
  kableExtra::scroll_box(width="100%", fixed_thead=TRUE)
```

```{r reset_default_assay}
# Reset default assay, so we won't plot integrated data
# Note: We need integrated data for UMAP, clusters
DefaultAssay(sc) = ifelse(param$norm=="SCT", param$norm, param$assay_raw)
```

# Cell Cycle Effect {.tabset}
How much do gene expression profiles in the dataset reflect the cell cycle phases the single cells were in? After initial normalisation, we determined the effects of cell cycle heterogeneity by calculating a score for each cell based on its expression of G2M and S phase markers. Scoring is based on the strategy described in `r Cite("10.1126/science.aad0501")`, and human gene symbols are translated to gene symbols of the species of interest using biomaRt. This section of the report visualises the above calculated cell cycle scores. 

```{r cellCycleEffect}
# Set up colours for cell cycle effect and add to sc object
col =  GenerateColours(num_colours=length(levels(sc$Phase)), names=levels(sc$Phase), palette="ggsci::pal_npg", alphas=1)
sc = ScAddLists(sc, lists=list(Phase=col), lists_slot="colour_lists")

# Get a feeling for how many cells are affected
p1 = ggplot(sc[[]], aes(x=S.Score, y=G2M.Score, colour=Phase)) + 
  geom_point() + 
  scale_x_continuous("G1/S score") + 
  scale_y_continuous("G2/M score") + 
  AddStyle(col=Misc(sc, "colour_lists")[["Phase"]])

p2 = ggplot(sc@meta.data %>% 
              dplyr::group_by(seurat_clusters, Phase) %>% 
              dplyr::summarise(num_cells=length(Phase)), 
            aes(x=seurat_clusters, y=num_cells, fill=Phase)) + 
  geom_bar(stat="identity", position="fill") + 
  scale_x_discrete("Seurat clusters") + 
  scale_y_continuous("Fraction of cells") + 
  AddStyle(fill=Misc(sc, "colour_lists")[["Phase"]]) + 
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1)) 

p3 = ggplot(sc[[]] %>% 
              dplyr::group_by(orig.ident, Phase) %>% 
              dplyr::summarise(num_cells=length(Phase)), 
            aes(x=orig.ident, y=num_cells, fill=Phase)) + 
  geom_bar(stat="identity", position="fill") + 
  scale_y_continuous("Fraction of cells") +
  AddStyle(fill=Misc(sc, "colour_lists")[["Phase"]]) + 
  theme(axis.text.x = element_text(angle=30, hjust=1, vjust=1)) + xlab("")

p = p1 + p2 + p3 & theme(legend.position="bottom")
p = p + patchwork::plot_annotation(title="Cell cycle phases") + plot_layout(guides="collect")
p
```

## UMAP coloured by cell cycle phases

```{r cellCycleEffect_umap_phases}
if (any(!is.na(sc$Phase))) {
  # UMAP with phases superimposed
  # Note: This is a hack to colour by phase but label by Cluster
  p = Seurat::DimPlot(sc, group.by="Phase", pt.size=1, cols=Misc(sc, "colour_lists")[["Phase"]]) + 
    AddStyle(title="UMAP, cells coloured by cell cycle phases", legend_title="Phase")
  p$data$seurat_clusters = sc[["seurat_clusters"]][rownames(p$data), ]
  p = LabelClusters(p, id="seurat_clusters", box=TRUE, fill="white")
  p
}
```

## UMAP coloured by S phase

```{r cellCycleEffect_umap_s}
if (any(!is.na(sc$Phase))) {
  p = Seurat::FeaturePlot(sc, features="S.Score", pt.size=1, min.cutoff="q1", max.cutoff="q99", cols=c("lightgrey", param$col)) +
    AddStyle(title="UMAP, cells coloured by S phase")
  p = LabelClusters(p, id="ident", box=TRUE, fill="white")
  p
}
```

## UMAP coloured by G2/M phase

```{r cellCycleEffect_umap_g2m}
if (any(!is.na(sc$Phase))) {
  p = Seurat::FeaturePlot(sc, features="G2M.Score", pt.size=1, min.cutoff="q1", max.cutoff="q99", cols=c("lightgrey", param$col)) + 
    AddStyle(title="UMAP, cells coloured by G2M phase")
  p = LabelClusters(p, id="ident", box=TRUE, fill="white")
  p
}
```

## UMAP coloured by the difference between S and G2/M phase

```{r cellCycleEffect_umap_ccdiff}
if (any(!is.na(sc$Phase))) {
  p = Seurat::FeaturePlot(sc, features="CC.Difference", pt.size=1, min.cutoff="q1", max.cutoff="q99", cols=c("lightgrey", param$col)) +
    AddStyle(title="UMAP, cells coloured by CC.Difference")
  p = LabelClusters(p, id="ident", box=TRUE, fill="white")
  p
}
```

# Cluster QC  {.tabset}
Do cells in individual clusters have particularly high counts, detected genes or mitochondrial content?

## Number of counts 

```{r clusterQC_nCount_featurePlot}
qc_feature = paste0("nCount_", param$assay_raw)
p1 = suppressMessages(Seurat::FeaturePlot(sc, features=qc_feature) + 
  AddStyle(title="Feature plot") + 
  scale_colour_gradient(low="lightgrey", high=param$col, trans="log10"))
p1 = LabelClusters(p1, id="ident", box=FALSE)


p2 = ggplot(sc[[]], aes_string(x="seurat_clusters", y=qc_feature, fill="seurat_clusters", group="seurat_clusters")) + 
  geom_violin(scale="width") + 
  AddStyle(title="Violin plot (log10 scale)", fill=param$col_clusters,
           xlab="Cluster", legend_position="none") + 
  scale_y_log10()

p = p1 | p2 
p = p + patchwork::plot_annotation(title=paste0("Summed raw counts (", qc_feature, ", log10 scale)"))
p

m = paste0(c("nCount_", "nFeature_"), param$assay_raw)
p = ggplot(sc[[c(m, "seurat_clusters")]], aes_string(x=m[1], y=m[2], colour="seurat_clusters")) + 
  geom_point() + 
  AddStyle(col=param$col_clusters) +
  facet_wrap(~seurat_clusters) +
  theme(legend.position = "none")
p
```

## Number of features

```{r clusterQC_nFeature_featurePlot}
qc_feature = paste0("nFeature_", param$assay_raw)
p1 = suppressMessages(Seurat::FeaturePlot(sc, features=qc_feature) + 
  AddStyle(title="Feature plot") + 
  scale_colour_gradient(low="lightgrey", high=param$col, trans="log10"))
p1 = LabelClusters(p1, id="ident", box=FALSE)

p2 = ggplot(sc[[]], aes_string(x="seurat_clusters", y=qc_feature, fill="seurat_clusters", group="seurat_clusters")) + 
  geom_violin(scale="width") + 
  AddStyle(title="Violin plot", fill=param$col_clusters,
           xlab="Cluster", legend_position="none") + 
  scale_y_log10()

p = p1 | p2 
p = p + patchwork::plot_annotation(title=paste0("Number of features with raw count > 0 (", qc_feature, ", log10 scale)"))
p

m = paste0(c("nFeature_", "nFeature_"), param$assay_raw)
p = ggplot(sc[[c(m, "seurat_clusters")]], aes_string(x=m[1], y=m[2], colour="seurat_clusters")) + 
  geom_point() + 
  AddStyle(col=param$col_clusters) +
  facet_wrap(~seurat_clusters) +
  theme(legend.position = "none")
p
```

## Percent mitochondrial reads

```{r clusterQC_mt_featurePlot}
p1 = Seurat::FeaturePlot(sc, features="percent_mt", cols=c("lightgrey", param$col)) + 
  AddStyle(title="Feature plot")
p1 = LabelClusters(p1, id="ident", box=FALSE)

p2 = ggplot(sc[[]], aes(x=seurat_clusters, y=percent_mt, fill=seurat_clusters, group=seurat_clusters)) + 
  geom_violin(scale="width") + 
  AddStyle(title="Violin plot", fill=param$col_clusters,
           xlab="Cluster", legend_position="none")
p = p1 | p2 
p = p + patchwork::plot_annotation(title="Percent of mitochondrial features (percent_mt)")
p

m = c("percent_mt", paste0("nFeature_", param$assay_raw))
p = ggplot(sc[[c(m, "seurat_clusters")]], aes_string(x=m[1], y=m[2], colour="seurat_clusters")) + 
  geom_point() + 
  AddStyle(col=param$col_clusters) +
  facet_wrap(~seurat_clusters) +
  theme(legend.position = "none")
p
```

## Percent ribosomal reads

```{r clusterQC_ribo_featurePlot}
p1 = Seurat::FeaturePlot(sc, features="percent_ribo", cols=c("lightgrey", param$col)) +
  AddStyle(title="Feature plot")
p1 = LabelClusters(p1, id="ident", box=FALSE)

p2 = ggplot(sc[[]], aes(x=seurat_clusters, y=percent_ribo, fill=seurat_clusters, group=seurat_clusters)) +
  geom_violin(scale="width") +
  AddStyle(title="Violin plot", fill=param$col_clusters,
           xlab="Cluster", legend_position="none")
p = p1 | p2
p = p + patchwork::plot_annotation(title="Percent of ribosomal features (percent_ribo)")
p

m = c("percent_ribo", paste0("nFeature_", param$assay_raw))
p = ggplot(sc[[c(m, "seurat_clusters")]], aes_string(x=m[1], y=m[2], colour="seurat_clusters")) + 
  geom_point() + 
  AddStyle(col=param$col_clusters) +
  facet_wrap(~seurat_clusters) +
  theme(legend.position = "none")
p

```

## Percent ERCC

```{r clusterQC_ercc_featurePlot}
if ("percent_ercc" %in% colnames(sc[[]])) {
  p1 = Seurat::FeaturePlot(sc, features="percent_ercc", cols=c("lightgrey", param$col)) +
    AddStyle(title="Feature plot")
  p1 = LabelClusters(p1, id="ident", box=FALSE)
  
  p2 = ggplot(sc[[]], aes(x=seurat_clusters, y=percent_ercc, fill=seurat_clusters, group=seurat_clusters)) +
    geom_violin(scale="width") +
    AddStyle(title="Violin plot", fill=param$col_clusters,
             xlab="Cluster", legend_position="none")
  p = p1 | p2
  p = p + patchwork::plot_annotation(title="Percent of ERCC features (percent_ercc)")
  print(p)
  
  # Plot percent_ercc vs nFeature by cluster
  m = c("percent_ercc", paste0("nFeature_", param$assay_raw))
  p = ggplot(sc[[c(m, "seurat_clusters")]], aes_string(x=m[1], y=m[2], colour="seurat_clusters")) + 
    geom_point() + 
    AddStyle(col=param$col_clusters) +
    facet_wrap(~seurat_clusters) +
    theme(legend.position = "none")
  print(p)
} else {
  message("No ERCC controls found.")
}
```

# Known marker genes {.tabset}
Do cells in individual clusters express provided known marker genes? 

```{r knownMarkers_read}
known_markers_list=c()

# Overwrite empty list of known markers 
if (!is.null(param$file_known_markers)) {
  # Read known marker genes and map to rownames
  known_markers = openxlsx::read.xlsx(param$file_known_markers)
  known_markers_list = lapply(colnames(known_markers), function(x) {
    y = ensembl_to_seurat_rowname[known_markers[,x]] %>% 
      na.exclude() %>% unique() %>% sort()
    m = !y %in% rownames(sc)
    if (any(m)){
      Warning(paste0("The following genes of marker list '", x, "' cannot be found in the data: ", first_n_elements_to_string(y[m], n=10)))
    }
    return(y[!m])
  })
  
  # Remove empty lists
  names(known_markers_list) = colnames(known_markers)
  is_empty = purrr::map_int(known_markers_list, .f=length) == 0 
  known_markers_list = known_markers_list[!is_empty]
  
  # Add lists to sc object
  sc = ScAddLists(sc, lists=setNames(known_markers_list, paste0("known_marker_", names(known_markers_list))), lists_slot="gene_lists")
}  

# Set plot options
if(length(known_markers_list) > 0) { 
  known_markers_n = length(known_markers_list) 
  known_markers_vect = unlist(known_markers_list) %>% unique() %>% sort()
  idx_dotplot = sapply(seq(known_markers_list), function(x) length(known_markers_list[[x]]) <= 50)
  idx_avgplot = sapply(seq(known_markers_list), function(x) length(known_markers_list[[x]]) >= 10)
} else { 
  known_markers_n=0
  idx_dotplot = idx_avgplot = FALSE
  known_markers_vect = c()
}
```

```{r known_markers_fig_heights}
# The height of feature and violin plots is independent of the number of clusters
# The height of dotplots is dependent on the number of clusters
height_per_row = 3
height_per_row_variable = max(2, 0.3 * length(levels(sc$seurat_clusters)))

# The total heights of average feature plots and dotplots depend on the number of lists provided
fig_height_knownMarkers_avgplot = max(height_per_row, height_per_row * sum(idx_avgplot))
fig_height_knownMarkers_dotplot = max(height_per_row_variable, height_per_row_variable * sum(idx_dotplot)) %>% min(100)

# The total height of individual feature plots depends on the total number of known markers
nr_rows = ceiling(length(known_markers_vect)/2)
fig_height_knownMarkers_vect = max(height_per_row, height_per_row * nr_rows)
```

You provided `r length(known_markers_list)` list(s) of known marker genes. In the following tabs, you find: 

* Dot plots for all gene lists containing at most 50 genes   
* Average feature plots for all gene lists containing at least 10 genes   
* Individual feature plots for all genes if there are no more than 100 genes in total  

## Dot plot(s) 
A dot plot visualises how gene expression changes across different clusters. The size of a dot encodes the percentage of cells in a cluster that expresses the gene, while the color encodes the scaled average expression across all cells within the cluster. Per gene (column), we group cells based on cluster identity (rows), calculate average expression per cluster, subtract the mean of average expression values and divide by the standard deviation. The resulting scores describe how high or low a gene is expressed in a cluster compared to all other clusters. 

```{r knownMarkers_dotplot, fig.height=fig_height_knownMarkers_dotplot}
if ((known_markers_n > 0) & any(idx_dotplot)) {
  known_markers_dotplot = known_markers_list[idx_dotplot]
  p_list = list()
  for (i in seq(known_markers_dotplot)) {
    g = known_markers_dotplot[[i]]
    g = g[length(g):1]
    p_list[[i]] = suppressMessages(
      Seurat::DotPlot(sc, features=g) + 
        scale_colour_gradient2(low="steelblue", mid="lightgrey", high="darkgoldenrod1") +
        AddStyle(title=paste("Known marker genes:", names(known_markers_dotplot)[i]), ylab="Cluster") + 
        theme(axis.text.x=element_text(angle=90, hjust=1, vjust=.5)) +
        lims(size=c(0,100))
      )
  }
  p = patchwork::wrap_plots(p_list, ncol=1)
  p
} else if ((known_markers_n > 0) & !any(idx_dotplot)) {
  message("This tab is used for dot plots for up to 50 genes. All provided lists are longer than this, and hence dot plots are skipped.")
} else {
  message("No known marker genes were provided and hence dot plots are skipped.")
}
```

## Average feature plot(s)
An average feature plot visualises the average gene expression of each gene list on a single-cell level, subtracted by the aggregated expression of control feature sets. The color of the plot encodes the calculated scores, whereat positive scores suggest that genes are expressed more highly than expected. 

```{r knownMarkers_umap, fig.height=fig_height_knownMarkers_avgplot}
if ((known_markers_n > 0) & any(idx_avgplot)) {
  known_markers_avgplot = known_markers_list[idx_avgplot]
  sc = Seurat::AddModuleScore(sc, features=known_markers_avgplot, ctrl=10, name="known_markers")
  idx_replace_names = grep("^known_markers[0-9]+$", colnames(sc@meta.data), perl=TRUE)
  colnames(sc@meta.data)[idx_replace_names] = names(known_markers_avgplot)
  p_list = Seurat::FeaturePlot(sc, features=names(known_markers_avgplot), cols=c("lightgrey", param$col), combine=FALSE, label=TRUE)
  for (i in seq(known_markers_avgplot)) {
    p_list[[i]] = p_list[[i]] + AddStyle(title=paste("Known marker genes:", names(known_markers_avgplot)[i]))
  }
  p = patchwork::wrap_plots(p_list, ncol=1)
  print(p)
} else if ((known_markers_n > 0) & !any(idx_avgplot)) {
  message("This tab is used to plot an average for 10 or more genes. All provided lists are shorter than this, and hence average feature plots are skipped.")
} else {
  message("No known marker genes were provided and hence average feature plots are skipped.")
}
```

## Individual feature plots
An individual feature plot colours single cells on the UMAP according to their normalised gene expression. 

```{r knownMarkers_all, fig.height=fig_height_knownMarkers_vect}
if ((known_markers_n > 0) & length(known_markers_vect) <= 100) {
  p_list = Seurat::FeaturePlot(sc, features=known_markers_vect, cols=c("lightgrey", param$col), combine=FALSE, label=TRUE)
  for (i in seq(p_list)) p_list[[i]] = p_list[[i]] + AddStyle()
  p = patchwork::wrap_plots(p_list, ncol=2)
  print(p)
} else if (length(known_markers_vect) > 100) { 
  message("This tab is used to plot up to 100 known marker genes. Your provided list is longer than this, and hence individual feature plots are skipped.")
} else {
  message("No known marker genes were provided and hence individual feature plots are skipped.")
}
```

# Marker genes
We next identify genes that are differentially expressed in one cluster compared to all other clusters, based on raw `r param$assay_raw` data and the method "MAST". Resulting _p_-values are adjusted using the Bonferroni method. However, note that the _p_-values are likely inflated, since both clusters and marker genes were determined based on the same gene expression data, and there ought to be gene expression differences by design. Nevertheless, _p_-values can be used to sort and prioritize marker genes. We require marker genes to be expressed in at least `r param$marker_pct * 100`% of cells in the respective cluster, with a minimum log2 fold change of `r param$marker_log2FC` and adjusted p-value of at most `r param$marker_padj`. The names of differentially expressed genes per cluster, alongside statistical measures and additional gene annotation are written to file.

<details>
  <summary>What are marker genes?</summary>

As described above, cell clusters approximate cell types and states. But how do we know which cell types these are? To characterize cell clusters, we identify marker genes. Good marker genes are genes that are particularly expressed in one cluster, and existing knowledge of these marker genes can be used to extrapolate biological functions for the cluster. A good clustering of cells typically results in good marker genes. Hence, if you cannot find good marker genes you may need to go back to the start of the workflow and adapt your parameters. Note that we also determine genes that are particularly down-regulated in one cluster, even if these are not marker genes in the classical sense.

Good marker genes are highly and possibly even only expressed in one cluster as compared to all other clusters. However, sometimes marker genes are also expressed in other clusters, or are declared as marker genes in these clusters, for example cell lineage markers that are shared by different cell subtypes. To evaluate marker genes, it is essential to visualize their expression patterns.

In addition to detecting marker genes, it might be informative to detect genes that are differentially expressed between one specific cluster and one or several other clusters. This approach allows a more specific distinction of individual clusters and investigation of more subtle differences, see the section “Differentially expressed genes” below. 
</details>

```{r markers, warning=FALSE}
# Find DEGs for every cluster compared to all remaining cells, report positive (=markers) and negative ones
# min.pct = requires feature to be detected at this minimum percentage in either of the two groups of cells 
# logfc.threshold = requires a feature to be differentially expressed on average by some amount between the two groups
# only.pos = find only positive markers 

# Review recommends using "MAST"; Mathias uses "LR"
# ALWAYS USE: assay="RNA"/"Spatial" or assay="SCT"
# DONT USE: assay=integrated datasets; this data is normalised and contains only 2k genes
# Note: By default, the function uses slot="data". Mast requires log data, so this is the correct way to do it.
#   https://www.bioconductor.org/packages/release/bioc/vignettes/MAST/inst/doc/MAST-interoperability.html
markers = suppressMessages(Seurat::FindAllMarkers(sc, assay=param$assay_raw, test.use="MAST",
                                               only.pos=FALSE, min.pct=param$marker_pct, logfc.threshold=param$marker_log2FC,
                                               latent.vars=param$latent_vars, verbose=FALSE, silent=TRUE))

# If no markers were found, initialise the degs table so that further downstream (export) chunks run
if (ncol(markers)==0) markers = DegsEmptyMarkerResultsTable(levels(sc$seurat_clusters))

# For Seurat versions until 3.2, log fold change is based on the natural log. Convert to log base 2.
if ("avg_logFC" %in% colnames(markers) & !"avg_log2FC" %in% colnames(markers)) {
  lfc_idx = grep("avg_log\\S*FC", colnames(markers))
  markers[,lfc_idx] = marker_deg_results[,lfc_idx] / log(2)
  col_nms = colnames(markers)
  col_nms[2] = "avg_log2FC"
  colnames(markers) = col_nms
}

# Sort markers
markers = markers %>% DegsSort(group=c("cluster"))
  
# Filter markers 
markers_filt = DegsFilter(markers, cut_log2FC=param$marker_log2FC, cut_padj=param$marker_padj)
markers_found = nrow(markers_filt$all)>0

# Add average data to table
markers_out = cbind(markers_filt$all, DegsAvgDataPerIdentity(sc, genes=markers_filt$all$gene, assay=param$assay_raw))

# Split by cluster and write to file
additional_readme = data.frame(Column=c("cluster",
                                        "p_val_adj_score",
                                        "avg_<assay>_<slot>_id<cluster>"), 
                               Description=c("Cluster",
                                             "Score calculated as follows: -log10(p_val_adj)*sign(avg_log2FC)",
                                             "Average expression value for cluster; <assay>: RNA or SCT; <slot>: raw counts or normalised data"))

invisible(DegsWriteToFile(split(markers_out, markers_out$cluster),
                                       annot_ensembl=annot_ensembl,
                                       gene_to_ensembl=seurat_rowname_to_ensembl,
                                       additional_readme=additional_readme,
                                       file=file.path(param$path_out, "marker_degs", "markers_cluster_vs_rest.xlsx")))


# Plot number of differentially expressed genes
p = DegsPlotNumbers(markers_filt$all, 
                      group="cluster", 
                      title=paste0("Number of DEGs, comparing each cluster to the rest\n(FC=", 2^param$marker_log2FC, ", adj. p-value=", param$marker_padj, ")")) 

# Add marker table to seurat object
Seurat::Misc(sc, "markers") = list(condition_column="seurat_clusters", test="MAST", padj=param$marker_padj, 
                                   log2FC=param$marker_log2FC, min_pct=param$marker_pct, assay=param$assay_raw, slot="data",
                                   latent_vars=param$latent_vars,
                                   results=markers_filt$all,
                                   enrichr=EmptyEnrichrDf(overlap_split=TRUE))

# Add marker lists to seurat object
marker_genesets_up = split(markers_filt$up$gene, markers_filt$up$cluster)
names(marker_genesets_up) = paste0("markers_up_cluster", names(marker_genesets_up))
marker_genesets_down = split(markers_filt$down$gene, markers_filt$down$cluster)
names(marker_genesets_down) = paste0("markers_down_cluster", names(marker_genesets_down))
sc = ScAddLists(sc, lists=c(marker_genesets_up, marker_genesets_down), lists_slot="gene_lists")

if (markers_found) {
  p
} else {
  warning("No differentially expressed genes (cluster vs rest) found. The following related code is not executed, no related plots and tables are generated.")
}
```

## Table of top marker genes
We use the term "marker genes" to specifically describe genes that are up-regulated in cells of one cluster compared to the rest.

```{r markers_table, eval=markers_found}
if (markers_found) {
  markers_top = DegsUpDisplayTop(markers_filt$up, n=6)
  
  # Add labels
  markers_top$labels = paste0(markers_top$cluster, ": ", markers_top$gene)

  # Show table
  knitr::kable(markers_top %>% dplyr::select(-labels), align="l", caption="Up to top 5 marker genes per cell cluster") %>% 
    kableExtra::kable_styling(bootstrap_options=c("striped", "hover")) %>% 
    kableExtra::scroll_box(width="100%", height="700px") 
}
```

## Visualisation of top marker genes {.tabset}
The following plots visualise the top marker genes for each cluster, respectively. Clear marker genes indicate good clusters that represent cell types. 

```{r markers_fig_heights}
# Note: We need to run this chunk as it specifies a variable that is used in chunk definitions below
if (markers_found) {

  # The height of feature and violin plots is independent of the number of clusters
  # The height of dotplots is dependent on the number of clusters
  height_per_row = 3
  height_per_row_variable = max(3, 0.3 * length(levels(sc$seurat_clusters)))

  # Feature plots and violin plots: each row contains 3 plots
  #   The plot has 3 columns and 2 rows per cluster, hence the layout works nicely if we find 
  #     at least 6 markers per cluster
  nr_rows_3cols = ceiling(nrow(markers_top)/3)
  fig_height_3cols = height_per_row * nr_rows_3cols
  
  # Dotplots: each row contains 2 plots
  nr_rows_dp_2cols = ceiling(length(levels(sc$seurat_clusters))/2)
  fig_height_dp_2cols = height_per_row_variable * nr_rows_dp_2cols %>% min(100)
  
} else {
  fig_height_3cols = fig_height_dp_2cols = 7 
}
```

### Feature plots

```{r markers_plot_umap, eval=markers_found, fig.height=fig_height_3cols}
if (markers_found) {
  # Plot each marker one by one, and then combine them all at the end
  p_list = list()
  for (i in 1:nrow(markers_top)) { 
    p_list[[i]] = Seurat::FeaturePlot(sc, features=markers_top$gene[i], 
                                      cols=c("lightgrey", param$col_clusters[markers_top$cluster[i]]),  
                                      combine=TRUE, label=TRUE) + 
      AddStyle(title=markers_top$labels[i], 
               xlab="", ylab="", 
               legend_position="bottom")
  }
  
  # Combine all plots
  p = patchwork::wrap_plots(p_list, ncol=3) + 
    patchwork::plot_annotation(title="UMAP, cells coloured by normalised gene expression data, top marker genes per cluster")
  p
}
```

### Violin plots (normalised)

```{r markers_plot_violin_raw, eval=markers_found, fig.height=fig_height_3cols}
if (markers_found) {
  # Plot violin plots per marker gene, and combine it all at the end
  # This layout works out nicely if there are 4 marker genes per cluster
  p_list = list()
  for(i in 1:nrow(markers_top)) { 
    p_list[[i]] = Seurat::VlnPlot(sc, features=markers_top$gene[i], assay=param$assay_raw, pt.size=0, cols=param$col_clusters) + 
      AddStyle(title=markers_top$labels[i], xlab="") + 
      theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1)) 
  }
  p = patchwork::wrap_plots(p_list, ncol=3) + 
    patchwork::plot_annotation(title="Violin plot of for normalised gene expression data, top marker genes per cluster") & theme(legend.position="none")
  p
}
```

### Dot plot (scaled)

```{r markers_plot_dot_scaled, eval=markers_found, fig.height=fig_height_dp_2cols}
if (markers_found) {
  # Visualises how feature expression changes across different clusters
  # Plot dotplots per cluster, and combine it all at the end
  p_list = lapply(markers_top$cluster %>% sort() %>% unique(), function(cl) {
    genes = markers_top %>% dplyr::filter(cluster==cl) %>% dplyr::pull(gene)
    p = suppressMessages(Seurat::DotPlot(sc, features=genes) + 
                           scale_colour_gradient2(low="steelblue", mid="lightgrey", high="darkgoldenrod1") +
                           AddStyle(title=paste0("Top marker genes for cluster ", cl, " (scaled)"), ylab="Cluster", legend_position="bottom") + 
                           theme(axis.text.x = element_text(angle=90, hjust=1, vjust=.5)) + 
                           guides(size=guide_legend(order=1)))
    return(p)
  })
  
  p = patchwork::wrap_plots(p_list, ncol=2) 
  p
}
```

### Dot plot (non-scaled)

```{r markers_plot_dot_nonscaled, eval=markers_found, fig.height=fig_height_dp_2cols}
if (markers_found) {
  # Visualises how feature expression changes across different clusters
  # Plot dotplots per cluster, and combine it all at the end
  p_list = lapply(markers_top$cluster %>% sort() %>% unique(), function(cl) {
    genes = markers_top %>% dplyr::filter(cluster==cl) %>% dplyr::pull(gene)
    genes = genes[length(genes):1]
    p = suppressMessages(DotPlotUpdated(sc, features=genes, scale=FALSE, cols=c("lightgrey", param$col)) + 
                           AddStyle(title=paste0("Top marker genes for cluster ", cl, " (not scaled)"), ylab="Cluster", legend_position="bottom") + 
                           theme(axis.text.x = element_text(angle=90, hjust=1, vjust=.5)) + 
                           guides(size=guide_legend(order=1)))
    return(p)
  })
      
  p = patchwork::wrap_plots(p_list, ncol=2)
  p
}
```

## Expression per cluster per sample {.tabset}
If the dataset contains multiple samples, we can visualise the expression of a gene that is up-regulated in a cluster separately for each sample. For each cluster, we extract up-regulated genes, and visualise expression of these genes in all cells in that cluster, split by their sample of origin. 

```{r markers_plot_dotplotpercl_height}
fig_height_degs_per_cl = max(5, 
                             max(2, 0.3 * (sc$orig.ident %>% unique() %>% length())) * length(levels(sc$seurat_clusters)) * 2) # We multiply by 2, as the legend requires quite some space
```

### Scaled dotplots
First, we plot scaled expression as explained above (see section Known marker genes). This plot allows us to judge whether the expression of a gene is increased in one sample as compared to the other samples.

```{r markers_plot_dotplotpercl_scaled, fig.height=fig_height_degs_per_cl, eval=markers_found}
if (markers_found) {
  p_list = list()
  markers_filt_up_top = DegsUpDisplayTop(degs=markers_filt$up, n=50)
  for (cl in levels(sc$seurat_clusters)) {  
    markers_filt_up_cl_top = markers_filt_up_top %>% 
      dplyr::filter(cluster==cl) %>% 
      dplyr::pull(gene)

    if (length(markers_filt_up_cl_top) > 0) {
      p_list[[cl]] = suppressMessages(Seurat::DotPlot(sc, features=markers_filt_up_cl_top, idents=cl, group.by="orig.ident") +
        scale_colour_gradient2(low="steelblue", mid="lightgrey", high="darkgoldenrod1") + 
        AddStyle(title=paste0("Up to 50 markers (up-regulated genes) for cluster ", cl), ylab="Cluster", legend_position="bottom") + 
        theme(axis.text.x=element_text(angle=90, hjust=1, vjust=.5)) + 
        guides(size=guide_legend(order=1)))
    }
  }
  p = patchwork::wrap_plots(p_list, ncol=1) + patchwork::plot_annotation("Dotplot per cluster") 
  p
}
```

### Non-scaled dotplots
Second, we plot normalised expression with no further scaling. This plot helps to get an impression of the total expression of a gene. 

```{r markers_plot_dotplotpercl_unscaled, fig.height=fig_height_degs_per_cl, eval=markers_found}
if (markers_found) {
  n_genes_max_dotplot = 50
  p_list = list()
  for (cl in levels(sc$seurat_clusters)) {            
    markers_filt_up_cl_top = markers_filt$up %>% 
      dplyr::filter(cluster==cl) %>% 
      dplyr::top_n(n=n_genes_max_dotplot, wt=p_val_adj_score) %>% 
      dplyr::pull(gene)
    if (length(markers_filt_up_cl_top) > 0) {
      p_list[[cl]] = DotPlotUpdated(sc, features=markers_filt_up_cl_top, idents=cl, group.by="orig.ident", scale=FALSE, cols=c("lightgrey", param$col)) +
        AddStyle(title=paste0("Up to ", n_genes_max_dotplot, " markers (up-regulated genes) for cluster ", cl, " (not scaled)"), ylab="Cluster", legend_position="bottom") + 
        theme(axis.text.x=element_text(angle=90, hjust=1, vjust=.5)) + 
        guides(size=guide_legend(order=1))
    }
  }
  
  p = patchwork::wrap_plots(p_list, ncol=1) + patchwork::plot_annotation("Dotplot per cluster (not scaled)") 
  p
}
```

## Heatmaps {.tabset}
### All up- and down-regulated genes

```{r markers_heatmap_all, eval=markers_found, fig.height=20}
if (markers_found) {
  # This will sample 500 cells; the number of cells per seurat_cluster will be proportional
  cells_subset = ScSampleCells(sc, n=500, group="seurat_clusters", group_proportional=TRUE, seed=1)
    
  # Heatmap of all differentially expressed genes
  p = Seurat::DoHeatmap(sc, features=markers_filt$all$gene, group.colors=param$col_clusters, label=FALSE, cells=cells_subset) + 
    NoLegend() + 
    theme(axis.text.y=element_blank()) +
    ggtitle("Heatmap of scaled gene expression data, all genes differentially expressed between a cluster and the rest")
  p
}
```

### Top 300 up-regulated genes

```{r markers_heatmap_top_up, eval=markers_found, fig.height=20}
if (markers_found) {
  # This will sample 500 cells; the number of cells per seurat_cluster will be proportional
  cells_subset = ScSampleCells(sc, n=500, group="seurat_clusters", group_proportional=TRUE, seed=1)
  # With fig.height = 20, 300 features can be shown; distribute among clusters
  features_per_group = 300/length(levels(markers_filt$up$cluster))
  features_subset = markers_filt$up %>% 
    dplyr::group_by(cluster) %>% 
    dplyr::top_n(n=features_per_group, wt=avg_log2FC) %>% 
    dplyr::arrange(cluster, -avg_log2FC) %>%
    dplyr::pull(gene) %>%
    unique()
  
  # Heatmap of top up-regulated genes
  p = Seurat::DoHeatmap(sc, features=features_subset, group.colors=param$col_clusters, label=FALSE, cells=cells_subset) + 
    NoLegend() + 
    theme(axis.text.y=element_text(size=8)) +
    ggtitle("Heatmap of scaled gene expression data, top genes up-regulated in a cluster compared to the rest")
  p
}
```

### Top 300 down-regulated genes

```{r markers_heatmap_top_down, eval=markers_found, fig.height=20}
if (markers_found) {
  # This will sample 500 cells; the number of cells per seurat_cluster will be proportional
  cells_subset = ScSampleCells(sc, n=500, group="seurat_clusters", group_proportional=TRUE, seed=1)
  # With fig.height = 20, 300 features can be shown; distribute among clusters
  features_per_group = 300/length(levels(markers_filt$down$cluster))
  features_subset = markers_filt$down %>% 
    dplyr::group_by(cluster) %>% 
    dplyr::top_n(n=features_per_group, wt=-avg_log2FC) %>% 
    dplyr::arrange(cluster, avg_log2FC) %>%
    dplyr::pull(gene) %>%
    unique()
  
  # Heatmap of top down-regulated genes
  p = Seurat::DoHeatmap(sc, features=features_subset, group.colors=param$col_clusters, label=FALSE, cells=cells_subset) + 
    NoLegend() + 
    theme(axis.text.y=element_text(size=8)) +
    ggtitle("Heatmap of scaled gene expression data, top genes up-regulated in a cluster compared to the rest")
  p
}
```

## Functional enrichment analysis
To gain first insights into potential functions of cells in a cluster, we test for over-representation of functional terms amongst up- and down-regulated genes of each cluster. Over-represented terms are written to file.  

We first translate gene symbols of up- and down-regulated genes per cluster into Entrez gene symbols, and then use the "enrichR" R-package to access the "Enrichr" website `r Cite("https://amp.pharm.mssm.edu/Enrichr/", "citep")`. You can choose to test functional enrichment from a wide range of databases:

```{r enrichr_databases}
# Set Enrichr database
enrichR::setEnrichrSite(param$enrichr_site)

# List databases
dbs_all = enrichR::listEnrichrDbs()
knitr::kable(dbs_all, align="l", caption="Enrichr databases") %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover")) %>% 
  kableExtra::scroll_box(width="100%", height="300px")

markers_enriched=list()
```

```{r markers_functional_enrichment, results="hide", eval=markers_found}
if (markers_found) {
  # Upregulated markers
  
  # Convert Seurat names of upregulated marker per cluster to Entrez; use named lists for translation
  # Is that still neccessary?
  marker_genesets_up = sapply(levels(sc$seurat_clusters), function(x) {
    tmp = markers_filt$up %>% dplyr::filter(cluster==x) %>% dplyr::pull(gene)
    tmp = sapply(tmp, function(n) seurat_rowname_to_entrez[[n]][1], USE.NAMES=TRUE, simplify=TRUE) %>% unlist() %>% as.character()
    return(tmp[!is.na(tmp)])
  }, USE.NAMES=TRUE, simplify=TRUE)
  
  # Tests done by Enrichr
  marker_genesets_up_enriched = purrr::map(marker_genesets_up, EnrichrTest, databases=param$enrichr_dbs, padj=param$enrichr_padj)
  marker_genesets_up_enriched = purrr::map(list_names(marker_genesets_up_enriched), function(n) {
    return(purrr::map(marker_genesets_up_enriched[[n]], function(d){
      return(cbind(d, Cluster=rep(n, nrow(d)), Direction=rep("up", nrow(d))))
    }))
  })

  # Write to files
  invisible(purrr::map(names(marker_genesets_up_enriched), function(n) {
    EnrichrWriteResults(enrichr_results=marker_genesets_up_enriched[[n]],
                        file=file.path(param$path_out, "marker_degs", paste0("functions_marker_up_cluster_", n, "_vs_rest.xlsx")))
  }))
  
  
  # Downregulated markers
  
  # Convert Seurat names of downregulated marker per cluster to Entrez; use named lists for translation
  # Is that still neccessary?
  marker_genesets_down = sapply(levels(sc$seurat_clusters), function(x) {
    tmp = markers_filt$down %>% dplyr::filter(cluster==x) %>% dplyr::pull(gene)
    tmp = sapply(tmp, function(x) seurat_rowname_to_entrez[[x]][1], USE.NAMES=TRUE, simplify=TRUE) %>% unlist() %>% as.character()
    return(tmp[!is.na(tmp)])
  }, USE.NAMES=TRUE, simplify=TRUE)
  
  #  Tests done by Enrichr
  marker_genesets_down_enriched = purrr::map(marker_genesets_down, EnrichrTest, databases=param$enrichr_dbs, padj=param$enrichr_padj)
  marker_genesets_down_enriched = purrr::map(list_names(marker_genesets_down_enriched), function(n) {
    return(purrr::map(marker_genesets_down_enriched[[n]], function(d){
      return(cbind(d, Cluster=rep(n, nrow(d)), Direction=rep("down", nrow(d))))
    }))
  })
  
  # Write to files
  invisible(purrr::map(names(marker_genesets_down_enriched), function(n) {
    EnrichrWriteResults(enrichr_results=marker_genesets_down_enriched[[n]],
                        file=file.path(param$path_out, "marker_degs", paste0("functions_marker_down_cluster_", n, "_vs_rest.xlsx")))
  }))
  
  # Combine, flatten into data.frame and add to sc misc slot
  marker_genesets_enriched = c(marker_genesets_up_enriched, marker_genesets_down_enriched)
  marker_genesets_enriched = unname(marker_genesets_enriched)
  marker_genesets_enriched = purrr::map(marker_genesets_enriched, FlattenEnrichr) %>% dplyr::bind_rows()
  marker_genesets_enriched$Cluster = factor(marker_genesets_enriched$Cluster, levels=levels(sc$seurat_clusters))
  marker_genesets_enriched$Direction = factor(marker_genesets_enriched$Direction, levels=c("up", "down"))
  
  misc_content = Misc(sc, "markers")
  misc_content[["enrichr"]] = marker_genesets_enriched
  suppressWarnings({Misc(sc, "markers") = misc_content})
}
```

The following table contains the top enriched terms per cluster.

```{r functional_enrichment_results, eval=markers_found, results="asis"}
# Top enriched terms (TODO: better plots, functions)
if (markers_found) {
  cat("#### {.tabset} \n \n")
  
  # Get top ten up and down over all databases per cluster
  marker_genesets_top_enriched = marker_genesets_enriched %>% dplyr::group_by(Cluster, Direction) %>%
    dplyr::top_n(n=10, wt=Combined.Score)
  
  # Print as tabs
  for(n in levels(marker_genesets_top_enriched$Cluster)){
    cat("##### ", n, " \n")
    
    print(knitr::kable(marker_genesets_top_enriched %>% dplyr::ungroup() %>% dplyr::filter(Cluster==n) %>% dplyr::select(Database, Term, Direction, Adjusted.P.value, Odds.Ratio, Combined.Score), 
                     align="l", caption="Top ten enriched terms per geneset", format="html") %>% 
    kableExtra::kable_styling(bootstrap_options=c("striped", "hover")) %>% 
    kableExtra::scroll_box(width="100%", height="700px"))

    cat(" \n \n")
  }
  cat(" \n \n")
}
```

# Differentially expressed genes
If requested, we identify genes that are differentially expressed between two groups of cells. Groups can be defined by columns in the cell metadata. Different types of tests can be used and input data for testing can be the different assays as well as the computed dimensionality reductions. Resulting _p_-values are adjusted using the Bonferroni method. The names of differentially expressed genes per cluster, alongside statistical measures and additional gene annotation are written to file.

```{r degs_test_contrasts}
# We first compute the DEGs for all requested contrasts

# Prepare a list with contrasts (input can be R data.frame table or Excel file)
degs_contrasts_list = DegsSetupContrastsList(sc, param$deg_contrasts, param$latent_vars)

# Add the actual data to the list
degs_contrasts_list = purrr::map(degs_contrasts_list, function(contrast){
  # If there were already errors, just return
  if (length(contrast[["error_messages"]]) > 0) return(c(contrast, list(object=NULL, cells_group1_idx_subset=as.integer(), cells_group2_idx_subset=as.integer())))
  
  # Get cells indices
  cells_group1_idx = contrast[["cells_group1_idx"]]
  cells_group2_idx = contrast[["cells_group2_idx"]]

  # Create object
  if (contrast[["use_reduction"]]) {
    # Use dimensionality reduction
    contrast[["object"]] = Seurat::Reductions(sc, slot=contrast[["assay"]])
  } else {
    # Use assay
    contrast[["object"]] = Seurat::GetAssay(sc[,unique(c(cells_group1_idx, cells_group2_idx))], assay=contrast[["assay"]])
    
    # This saves a lot of memory for parallelisation
    if (contrast[["slot"]]!="scale.data") contrast[["object"]]@scale.data = new(Class="matrix")
  }
  
  # Variable latent vars must be passed as data.frame
  if (!is.null(contrast[["latent_vars"]]) && length(contrast[["latent_vars"]]) > 0) {
    contrast[["latent_vars"]] = sc[[unique(c(cells_group1_idx, cells_group2_idx)), contrast[["latent_vars"]], drop=FALSE]]
  }

  # Now update cell indices so that they match to subset
  contrast[["cells_group1_idx_subset"]] = match(colnames(sc)[cells_group1_idx], colnames(contrast[["object"]]))
  contrast[["cells_group2_idx_subset"]] = match(colnames(sc)[cells_group2_idx], colnames(contrast[["object"]]))
  
  return(contrast)
})

# Compute the tests
# TODO: this chunk may be done in parallel in future
degs_contrasts_results = purrr::map(degs_contrasts_list, function(contrast) {
  if (length(contrast$error_messages)==0) {
    # No errors, do contrast
    test_results = suppressWarnings(
      DegsTestCellSets(object=contrast[["object"]],
                       slot=contrast[["slot"]],
                       cells_1=colnames(contrast[["object"]])[contrast[["cells_group1_idx_subset"]]],
                       cells_2=colnames(contrast[["object"]])[contrast[["cells_group2_idx_subset"]]],
                       is_reduction=contrast[["use_reduction"]],
                       logfc.threshold=contrast[["log2FC"]],
                       test.use=contrast[["test"]],
                       min.pct=contrast[["min_pct"]],
                       latent.vars=contrast[["latent_vars"]])
    )
  } else {
    # Errors, return empty data.frame
    test_results = DegsEmptyResultsTable()
  }
  
  # Sort and filter table
  test_results = test_results %>% DegsSort() %>% DegsFilter(contrast[["log2FC"]], contrast[["padj"]], split_by_dir=FALSE)

  # Add mean gene expression data (counts or data, dep on slot)
  avg.1 = DegsAvgData(contrast[["object"]], cells=contrast[["cells_group1_idx_subset"]], genes=test_results$gene, slot=contrast[["slot"]])[,1]
  avg.2 = DegsAvgData(contrast[["object"]], cells=contrast[["cells_group2_idx_subset"]], genes=test_results$gene, slot=contrast[["slot"]])[,1]
  test_results = cbind(test_results, avg.1, avg.2)
  
  # Add test results and drop unneccessary data
  contrast = c(contrast, list(results=test_results))
  contrast[["object"]] = NULL
  contrast[["cells_group1_idx_subset"]] = NULL
  contrast[["cells_group2_idx_subset"]] = NULL
  
  return(contrast)
})

# Also remove objects from deg_contrasts_list (save memory)
degs_contrasts_list = purrr::map(degs_contrasts_list, function(contrast){ contrast[["object"]] = NULL; return(contrast)})
```

```{r degs_enrichr, warning=FALSE, results="hide"}
# Use the existing variable and add Enrichr results
# Not in parallel due to server load
degs_contrasts_results = purrr::map(degs_contrasts_results, function(contrast) {
  # Get results table
  results_table = contrast$results
  
  # Drop existing results
  if ("enrichr" %in% names(contrast)) contrast[["enrichr"]] = NULL
  
  # Split into up- and downregulated DEGs, then translate to Entrez gene, runEnrichr
  degs_up = dplyr::filter(results_table, avg_log2FC > 0) %>% dplyr::pull(gene) %>% unique()
  degs_up = sapply(degs_up, function(n) seurat_rowname_to_entrez[[n]][1], USE.NAMES=TRUE, simplify=TRUE) %>% unlist() %>% as.character()
  degs_up = degs_up[!is.na(degs_up)]
  enrichr_results_up = EnrichrTest(genes=degs_up, databases=param$enrichr_dbs, padj=param$enrichr_padj)
  
  degs_down = dplyr::filter(results_table, avg_log2FC < 0) %>% dplyr::pull(gene) %>% unique()
  degs_down = sapply(degs_down, function(n) seurat_rowname_to_entrez[[n]][1], USE.NAMES=TRUE, simplify=TRUE) %>% unlist() %>% as.character()
  degs_down = degs_down[!is.na(degs_down)]
  enrichr_results_down = EnrichrTest(genes=degs_down, databases=param$enrichr_dbs, padj=param$enrichr_padj)
  
  # Flatten both enrichr results into tables
  enrichr_results_up = purrr::map_dfr(names(enrichr_results_up), function(n) {
    return(cbind(enrichr_results_up[[n]], 
          list(Database=factor(rep(n, nrow(enrichr_results_up[[n]])), levels=names(enrichr_results_up)), 
               Direction=factor(rep("up", nrow(enrichr_results_up[[n]])), levels=c("up", "down"))
               )
          ))
  })
  
  enrichr_results_down = purrr::map_dfr(names(enrichr_results_down), function(n) {
    return(cbind(enrichr_results_down[[n]], 
          list(Database=factor(rep(n, nrow(enrichr_results_down[[n]])), levels=names(enrichr_results_down)), 
               Direction=factor(rep("up", nrow(enrichr_results_down[[n]])), levels=c("up", "down"))
               )
          ))
  })
  
  # Rbind and add factor levels
  enrichr_results = rbind(enrichr_results_up, enrichr_results_down)
  return(c(contrast, list(enrichr=enrichr_results)))
})
```

```{r degs_write_results}
# Now regroup list so that subsets are together again
original_contrast_rows = purrr::map_int(degs_contrasts_results, function(contrast){ return(contrast[["contrast_row"]]) })
degs = split(degs_contrasts_results, original_contrast_rows)

# Write degs to files
invisible(purrr::map_chr(degs, function(degs_subsets) {
  # The output file
  file = file.path(param$path_out, "marker_degs", paste0("degs_contrast_row_", degs_subsets[[1]][["contrast_row"]], "_results.xlsx"))
  
  # Write degs
  degs_subsets_results = purrr::map(degs_subsets, function(contrast) {return(contrast[["results"]])})
  names(degs_subsets_results) = purrr::map_chr(degs_subsets, function(contrast) {return(ifelse(!is.na(contrast[["subset_group"]]), contrast[["subset_group"]], "All"))})
  file = DegsWriteToFile(degs_subsets_results, 
                         annot_ensembl=annot_ensembl,
                         gene_to_ensembl=seurat_rowname_to_ensembl,
                         file=file,
                         additional_readme=NULL)
  
  return(file)
}))


invisible(purrr::map_chr(degs, function(degs_subsets) {
  # The output file
  file = file.path(param$path_out, "marker_degs", paste0("degs_contrast_row_", degs_subsets[[1]][["contrast_row"]],  "_functions.xlsx"))
  
  # Write Enrichr results
  degs_subsets_enrichr = purrr::map(degs_subsets, function(contrast) {return(contrast[["enrichr"]])})
  names(degs_subsets_enrichr) = purrr::map_chr(degs_subsets, function(contrast) {return(ifelse(!is.na(contrast[["subset_group"]]), contrast[["subset_group"]], "All"))})
  file = EnrichrWriteResults(degs_subsets_enrichr, file=file)
  
  return(file)
}))

# Add to sc object
Misc(sc, "degs") = degs
```

```{r degs_plots}
for (i in seq(degs)) { 
  for (j in seq(degs[[i]])) {
    # If there are errors, skip
    if (length(degs[[i]][[j]]$error_messages) > 0) {
      next
    }

    # Average expression of all genes
    x = subset(sc, cells=degs[[i]][[j]]$cells_group2_idx) %>% GetAssayData(slot="data")
    x = log2(Matrix::rowMeans(expm1(x)) + 1)
    y = subset(sc, cells=degs[[i]][[j]]$cells_group1_idx) %>% GetAssayData(slot="data") 
    y = log2(Matrix::rowMeans(expm1(y)) + 1)
    sc_avg_log2FC = data.frame(x, y, col="none", gene=rownames(sc))
    lims = c(min(c(x, y)), max(x, y))
    
    ## Color DEGs
    up = degs[[i]][[j]]$results %>% dplyr::filter(avg_log2FC > 0) %>% dplyr::pull(gene)
    if (length(up) > 0) sc_avg_log2FC[up, "col"] = "up"
    down = degs[[i]][[j]]$results %>% dplyr::filter(avg_log2FC < 0) %>% dplyr::pull(gene)
    if (length(down) > 0) sc_avg_log2FC[down, "col"] = "down"

    ## Plots
    degs[[i]][[j]]$plot_scatter = ggplot(sc_avg_log2FC %>% dplyr::arrange(col, gene), aes(x=x, y=y, col=col)) + 
      geom_abline(slope=1, intercept=0, col="lightgrey") + 
      geom_abline(slope=1, intercept=c(-degs[[i]][[j]]$log2FC, degs[[i]][[j]]$log2FC), col="lightgrey", lty=2) + 
      geom_point() + 
      xlim(lims) + ylim(lims) +
      AddStyle(ylab=degs[[i]][[j]]$condition_group1, xlab=degs[[i]][[j]]$condition_group2, 
               col=c(none="grey", up="darkgoldenrod1", down="steelblue"), 
               legend_position="bottom", legend_title="Filtered genes")

    # Feature plot of top 4 genes, sorted by the p-value
    degs_top = degs[[i]][[j]]$results %>% dplyr::top_n(n=-4, wt=p_val) %>% dplyr::top_n(n=-4, wt=avg_log2FC) %>% dplyr::pull(gene)
    if (length(degs_top) > 0) {
      p_list = Seurat::FeaturePlot(sc, features=degs_top, cols=c("lightgrey", param$col), combine=FALSE, label=FALSE)
      for (p in seq(p_list)) p_list[[p]] = p_list[[p]] + AddStyle(legend_position="bottom", xlab="", ylab="")
      degs[[i]][[j]]$plot_feature = patchwork::wrap_plots(p_list, ncol=ifelse(length(degs_top) > 1, 2, 1))
    } else {
      degs[[i]][[j]]$plot_feature = NULL
    }
  }
}
```

```{r degs_print_summary_to_html, fig.show="asis", results="asis"}
knitr_header_string = "

## {{condition_column}}: {{condition_group1}} vs {{condition_group2}}

General configuration:

* assay: {{assay}}
* slot: {{slot}}
* test: {{test}}
* maximum adjusted p-value: {{padj}}
* minimum absolute log2 foldchange: {{log2FC}}
* minimum percentage of cells: {{min_pct}}
* latent vars: {{latent_vars}}
* output files: degs_contrast_row_{{row}}_results.xlsx, degs_contrast_row_{{row}}_functions.xlsx

Subset on column: \'{{subset_column}}\'"

if (length(degs)==0) message("No DEG contrasts specified.")

for (i in seq(degs)) {
  # Get subsets
  degs_subsets = degs[[i]]
  first_contrast = degs_subsets[[1]]
  
  # Create header
  cat(
    knitr::knit_expand(text=knitr_header_string,
                      row=i,
                     condition_column=first_contrast[["condition_column"]],
                     condition_group1=first_contrast[["condition_group1"]],
                     condition_group2=first_contrast[["condition_group2"]],
                     assay=first_contrast[["assay"]],
                     slot=first_contrast[["slot"]],
                     test=first_contrast[["test"]],
                     padj=first_contrast[["padj"]],
                     log2FC=first_contrast[["log2FC"]],
                     min_pct=first_contrast[["min_pct"]],
                     latent_vars=ifelse(!is.null(first_contrast[["latent_vars"]]), paste(colnames(first_contrast[["latent_vars"]]), collapse=","), "-"),
                     subset_column=ifelse(is.na(first_contrast[["subset_column"]]), "-", first_contrast[["subset_column"]]))
  , "\n")
  
  # Get error messages
  error_messages = unique(purrr::flatten_chr(purrr::map(degs_subsets, function(contrast){return(contrast[["error_messages"]])})))

   # Create combined results table
  degs_subsets_results = purrr::map_dfr(degs_subsets, function(contrast) {
    subset_group_value = ifelse(!is.na(contrast[["subset_group"]]), contrast[["subset_group"]], "All")
    return(contrast[["results"]] %>% 
      dplyr::summarise(subset_group=subset_group_value,
                       Cells1=length(contrast[["cells_group1_idx"]]),
                       Cells2=length(contrast[["cells_group2_idx"]]),
                       DEGs=length(gene),
                       DEGs_up=sum(avg_log2FC > 0),
                       DEGs_down=sum(avg_log2FC < 0)))
  }) %>% tibble::as_tibble()
  
  # Print warnings/errors
  if (length(error_messages) > 0) {
    warning(error_messages)
  }
  
  # Print summary table
  print(
      knitr::kable(degs_subsets_results,
                   align="l", caption="DEG summary", 
                   col.names=c("Subset", "Cells in group 1", "Cells in group 2", "# DEGs", "# DEGs upregulated", "# DEGs downregulated"), 
                   format="html") %>%
        kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))
    )
  
  # Print plots per contrast
  for (contrast in seq(degs_subsets)) {
    if (!"plot_scatter" %in% names(degs_subsets[[contrast]]) & !"plot_feature" %in% names(degs_subsets[[contrast]])) next
      
    p = degs_subsets[[contrast]]$plot_scatter | degs_subsets[[contrast]]$plot_feature
    title = "Scatterplot and feature plots"
    if (!is.na(degs_subsets[[contrast]]$subset_column)) {
      title = paste0(title, " (subset ", degs_subsets[[contrast]]$subset_column, 
                     ": ", degs_subsets[[contrast]]$subset_group, ")")
    }
    
    p = p + patchwork::plot_annotation(title=title)
    print(p)
  }
  
  cat("\n \n")
} 
```

# Output

```{r postprocess_sc, warning=FALSE, results="hide"}
# Add colour lists for orig.dataset
col = GenerateColours(num_colours=length(levels(sc$orig.dataset)), names=levels(sc$orig.dataset), palette=param$col_palette_samples, alphas=1)
sc = ScAddLists(sc, lists=list(orig.dataset=col), lists_slot="colour_lists")

# Add experiment details
Seurat::Misc(sc, "experiment") = list(project_id=param$project_id, date=Sys.Date(), species=gsub("_gene_ensembl", "", param$mart_dataset))

# Add parameter
Seurat::Misc(sc, "parameters") = param

# Add technical output (note: cannot use Misc function here)
sc@misc$technical = data.frame(ScrnaseqSessionInfo(param$path_to_git))
```

## Export to Loupe Cell Browser
If all provided datasets are of type "10x", we export the UMAP 2D visualisation, metadata such as the cell clusters, and lists of differentially expressed genes, so you can open and work with these in the Loupe Cell Browser `r Cite("https://support.10xgenomics.com/single-cell-gene-expression/software/visualization/latest/what-is-loupe-cell-browser", "citep")`.  

```{r loupe_export, warning=FALSE, results="hide"}
if (all(param$path_data$type == "10x")) { 
  
  # Export reductions (umap, pca, others)
  for(r in Seurat::Reductions(sc)) {
    write.table(Seurat::Embeddings(sc, reduction=r)[,1:2] %>% as.data.frame() %>% tibble::rownames_to_column(var="Barcode"),
                file=file.path(param$path_out, "export", paste0("Loupe_projection_", r, ".csv")), col.names=TRUE, row.names=FALSE, quote=FALSE, sep=",")
  }
  
  # Export categorical metadata
  loupe_meta = sc@meta.data
  idx_keep = sapply(1:ncol(loupe_meta), function(x) !is.numeric(loupe_meta[,x]))
  write.table(x=loupe_meta[, idx_keep] %>% tibble::rownames_to_column(var="barcode"), 
              file=file.path(param$path_out, "export", "Loupe_metadata.csv"), col.names=TRUE, row.names=FALSE, quote=FALSE, sep=",")

  # Export gene sets (CC genes, known markers, per-cluster markers up- and downregulated, ...)
  gene_lists = Misc(sc, "gene_lists")
  
  # Remove empty gene sets
  gene_lists = gene_lists[purrr::map_int(gene_lists, length) > 0]
  loupe_genesets = purrr::map_dfr(names(gene_lists), function(n) {return(data.frame(List=n, Name=gene_lists[[n]]))})
  loupe_genesets$Ensembl = seurat_rowname_to_ensembl[loupe_genesets$Name]
  write.table(loupe_genesets, file=file.path(param$path_out, "export", "Loupe_genesets.csv"), col.names=TRUE, row.names=FALSE, quote=FALSE, sep=",")
}
```

Result files are:

  * export/
    * Loupe_projection_(umap|pca|...).csv: Seurat UMAP/PCA/... projections for visualization
    * Loupe_metadata.csv: Seurat cell meta data including clusters and cell cycle phases
    * Loupe_genesets.csv: Gene sets such as markers, DEGs, cell cycles 

Projections can be imported in Loupe via "Import Projection", cell meta data via "Import Categories" and gene sets via "Import Lists" 

## Export to cellxgene browser
We export the assay data, cell metadata, clustering and visualisation in a format that can be read by the cellxgene browser `r Cite("https://github.com/chanzuckerberg/cellxgene", "citep")`.

```{r cellxgene_export, message=FALSE, warning=FALSE, results="hide"}
# Convert Seurat single cell object to python anndata object which will be accessible via reticulate here
adata = sceasy::convertFormat(sc, from="seurat", to="anndata", outFile=NULL, assay=DefaultAssay(sc))

# Set up correct colours (see https://chanzuckerberg.github.io/cellxgene/posts/prepare) so that colours match
adata$uns = dict(
  seurat_clusters_colors=np_array(unname(Misc(sc, "colour_lists")$seurat_clusters), dtype="<U7"), 
  orig.ident_colors=np_array(unname(Misc(sc, "colour_lists")$orig.ident), dtype="<U7"),
  orig.dataset_colors=np_array(unname(Misc(sc, "colour_lists")$orig.dataset), dtype="<U7"),
  Phase_colors=np_array(unname(Misc(sc, "colour_lists")$Phase), dtype="<U7")
)

# Write to h5ad file
adata$write(file.path(param$path_out, "export", "sc.h5ad"), compression="gzip")
```

Result files are:

  * export/
    * sc.h5ad: H5AD object for cellxgene browser   

Copy/upload to data  directory of your cellxgene browser

## Export to Cerebro browser
We export the assay data, clustering, visualisation, marker genes, enriched pathways and degs in a format that can be read by the Cerebro Browser `r Cite("https://github.com/romanhaa/cerebroApp/", "citep")`.

```{r cerebro_export, message=FALSE, warning=FALSE}
# Export to cerebro
res = ExportToCerebro(sc=sc, 
                      path=file.path(param$path_out, "export", "sc.crb"), 
                      assay=DefaultAssay(sc),
                      assay_raw=param$assay_raw,
                      delayed_array=FALSE)
```

Result files are:

  * export/
    * sc.crb: Object for Cerebro browser  

Load into Cerebro browser.

## Other output files

```{r output_files}
# Seurat object
saveRDS(sc, file=file.path(param$path_out, "data", "sc.rds"))

# Counts (RNA)
invisible(ExportSeuratAssayData(sc, 
                      dir=file.path(param$path_out, "data", "counts"), 
                      assays=param$assay_raw, 
                      slot="counts",
                      include_cell_metadata_cols=colnames(sc[[]]),
                      metadata_prefix=paste0(param$project_id, ".")))

# Metadata
openxlsx::write.xlsx(x=sc[[]] %>% tibble::rownames_to_column(var="Barcode"), file=file.path(param$path_out, "data", "cell_metadata.xlsx"), rowNames=FALSE, colNames=TRUE)

# Annotation as excel file
openxlsx::write.xlsx(x=data.frame(seurat_id=rownames(sc), ensembl_gene_id=seurat_rowname_to_ensembl[rownames(sc)], row.names=rownames(sc)) %>%
                       dplyr::inner_join(annot_ensembl, by="ensembl_gene_id"),
                     file=file.path(param$path_out, "annotation", "gene_annotation.xlsx"), 
                     rowNames=FALSE, colNames=TRUE)

# Data and annotation for a subset of 500 cells for Morpheus
# ERROR: This gives an error with the newest packages, might be related to this: 
# https://issueexplorer.com/issue/r-lib/cpp11/244
#  For now, we outcomment this section, since it isn't really needed
#cells_subset = ScSampleCells(sc, n=500, seed=1)
#openxlsx::write.xlsx(Seurat::GetAssayData(sc[, cells_subset], slot="data") %>% as.data.frame() %>% tibble::rownames_to_column(var="gene"), 
#                     file=file.path(param$path_out, "data", paste0("subset_", 500, "_cells_normalised_data.xlsx")),
#                     rowNames=FALSE, colNames=TRUE)
#openxlsx::write.xlsx(Seurat::GetAssayData(sc[, cells_subset], slot="scale.data") %>% as.data.frame() %>% #tibble::rownames_to_column(var="gene"), 
#                     file=file.path(param$path_out, "data", paste0("subset_", 500, "_cells_scaled_data.xlsx")),
#                     rowNames=FALSE, colNames=TRUE)
#openxlsx::write.xlsx(sc[[]][cells_subset, ] %>% as.data.frame() %>% tibble::rownames_to_column(var="cell"), 
#           file=file.path(param$path_out, "data",paste0("subset_", 500, "_cells_column_annotations.xlsx")),
#           rowNames=FALSE, colNames=TRUE)
```

Result files are:

  * annotation/
    * gene_annotation.xlsx: Ensembl annotation of the genes (Excel format)
    * cell_cycle_markers.xlsx: Markers for cell cycle phases (Excel format)
    * species_gene_ensembl.vEnsembl.annot.txt: Raw annotation downloaded from Ensembl (tab-separated file)
  * data/
    * sc.rds: Seurat object for import into R
    * cell_metadata.xlsx: Cell metadata (Excel format)
    * counts: Raw counts of the entire dataset (sparse matrix)
    * subset_500_cells_normalised_data.xlsx: Normalised subset of 500 cells for heatmap plotting with morpheus (https://software.broadinstitute.org/morpheus/) (Excel format)
    * subset_500_cells_scaled_data.xlsx: Normalised and scaled subset of 500 cells for heatmap plotting with morpheus (Excel format)
    * subset_500_cells_column_annotations.xlsx: Cell annotations for the 500 cells subset (Excel format)
  * figures/
    * all plots of the HTML report (PNG and PDF format)
  * marker_degs/
    * markers_cluster_vs_rest.xslx: Marker genes for each cluster (Excel format)
    * functions_marker_up_cluster_[1,2,3,...]_vs_rest.xslx: Biological functions and pathways that were found enriched in the up-regulated markers for cluster 1, 2, 3, ... (Excel format)
    * functions_marker_down_cluster_[1,2,3,...]_vs_rest.xslx: Biological functions and pathways that were found enriched in the down-regulated markers for cluster 1, 2, 3, ... (Excel format)
    * degs_contrast_row_[1,2,3,...]_results.xlsx: Results (genes) of the DEG analysis specified in the first, second, third, ... row of the configuration parameter (Excel format)
    * degs_contrast_row_[1,2,3,...]_functions.xlsx: Results (enriched functions and pathways) of the DEG analysis specified in the first, second, third, ... row of the configuration parameter (Excel format)

# Parameter table
The following parameters were used to run the workflow.  

```{r parameters_table}
out = ScrnaseqParamsInfo(params=param)

knitr::kable(out, align="l") %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover"), full_width=FALSE, position="left")
```

# Software versions
This report was created with generated using the [scrnaseq](https://github.com/ktrns/scrnaseq) GitHub repository. Software versions were collected at run time. 

```{r versions, message=FALSE}
out = ScrnaseqSessionInfo(param$path_to_git)

knitr::kable(out, align="l") %>% 
  kableExtra::kable_styling(bootstrap_options=c("striped", "hover"))
```

# Credits and References
This Workflow was developed as part of the [scrnaseq](https://github.com/ktrns/scrnaseq) GitHub repository by Katrin Sameith and Andreas Petzold at the [Dresden-concept Genome Center, TU Dresden](https://genomecenter.tu-dresden.de/) (Dresden, Germany), in collaboration with Torsten Glomb, Maike Kosanke and Oliver Dittrich at the [Research Core Unit Genomics, Hannover Medical School](https://www.mhh.de/genomics) (Hannover, Germany). Seurat Vignettes were initially used as templates. 

```{r bib, message=FALSE}
# Writes knitcitations references to references.bib file.
knitcitations::write.bibtex(file=file.path(param$path_out, "references.bib"))
```
