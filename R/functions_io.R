#- Smartseq2: ReadCounts_csv
#- 10x:
#  - RNA ok
#  - ATAC ok
#  - ADT ok
#  - TCR/BCR: no
#  - Spatial: no
#
# - Parse:
#  - RNA: ok
#  - TCR: no
#
# - Scale:
#  - RNA: ok
#
# - MissionBio:
#  - DNA: no
#  - Protein: no

#' Reads metadata from an anndata object in hdf5 format (generated by scanpy).
#' 
#' Largely copied and adapted from Azimuth::LoadH5ADobs!
#' 
#' @param h5ad_file Path to an anndata object in hdf5 format
#' @param type Can be 'obs' (for barcodes) or 'var' (for features).
#' @return Metadata (data.frame format)
ReadMetadata_h5ad = function(h5ad_file, type) {
  # Checks
  assertthat::is.readable(h5ad_file)
  
  # Open hdf5 file with anndata object
  hdf5_fh = hdf5r::H5File$new(h5ad_file, mode = "r+")
  hd5_data = hdf5_fh[[paste0("/", type)]]
  
  # Create metadata matrix
  index.var = hdf5r::h5attr(hd5_data, "_index")
  index = hd5_data[[index.var]][]
  groups = names(hd5_data)
  matrix = as.data.frame(x = matrix(
    data = NA,
    nrow = length(index),
    ncol = length(groups)
  ))
  colnames(matrix) = groups
  rownames(matrix) = index
  
  # Get columns and values
  if ("__categories" %in% names(x = hd5_data)) {
    hd5_data_cate = hd5_data[["__categories"]]
    for (i in seq_along(groups)) {
      g.i = groups[i]
      value_i = hd5_data[[g.i]][]
      if (g.i %in% names(x = hd5_data_cate)) {
        value_i = factor(x = value_i, labels = hd5_data[[g.i]][])
      }
      matrix[, i] = value_i
    }
  } else {
    for (i in seq_along(groups)) {
      g.i = groups[i]
      if (all(names(hd5_data[[g.i]]) == c("categories", "codes"))) {
        if (length(unique(hd5_data[[g.i]][["codes"]][])) == length(hd5_data[[g.i]][["categories"]][])) {
          value_i = factor(x = hd5_data[[g.i]][["codes"]][], labels = hd5_data[[g.i]][["categories"]][])
        }
        else {
          value_i = hd5_data[[g.i]][["codes"]][]
        }
      }
      else {
        value_i = tryCatch(
          expr = hd5_data[[g.i]][],
          error = function(e) {
            return("unknown")
          }
        )
      }
      matrix[, i] = value_i
    }
  }
  
  hdf5_fh$close_all()
  return(as.data.frame(matrix))
}

#' Reads metadata from a character-separated file.
#' 
#' @param h5ad_file Path to a character-separated file. First column must contain the respective barcode or feature id.
#' @return Metadata (data.frame format)
ReadMetadata_csv = function(csv_file) {
  # Checks
  assertthat::is.readable(csv_file)
  
  # Read table
  meta_data = readr::read_delim(csv_file, col_names=TRUE, comment="#", progress=FALSE, show_col_types=FALSE, col_types=readr::cols())
  meta_data = as.data.frame(meta_data)
  rownames(meta_data) = meta_data[, 1, drop=TRUE]
  return(meta_data)
}

#' Reads metadata from an Excel file.
#' 
#' @param excel_file Path to an Excel file. First column must contain the respective barcode or feature id. Reads only sheet 1.
#' @return Metadata (data.frame format)
ReadMetadata_excel = function(excel_file) {
  # Checks
  assertthat::is.readable(excel_file)
  
  # Read table
  meta_data = readxl::read_excel(excel_file, sheet=1, col_names=TRUE)
  meta_data = as.data.frame(meta_data)
  rownames(meta_data) = meta_data[, 1, drop=TRUE]
  return(meta_data)
}

#' Reads metadata from a metadata table saved as R rds file.
#' 
#' This method preserves factor levels.
#' 
#' @param rds_file Path to an R rds file. First column must contain the respective barcode or feature id.
#' @return Metadata (data.frame format)
ReadMetadata_rds = function(rds_file) {
  # Checks
  assertthat::is.readable(rds_file)
  
  # Read table
  meta_data = readRDS(rds_file)
  meta_data = as.data.frame(meta_data)
  rownames(meta_data) = meta_data[, 1, drop=TRUE]
  return(meta_data)
}

#' Reads metadata.
#' 
#' @param file Path to a character-separated file (csv, tsv, csv.gz, tsv.gz), an Excel file (xls, xslx) or an R rds file containing a table (preserves factor levels). First column must contain the respective barcode or feature id. For Excel files, only the first sheet is read.
#' @return Metadata (data.frame format)
ReadMetadata = function(file, ids=NULL) {
  # Checks
  extension = tools::file_ext(gsub("\\.gz$", "", file))
  valid_extensions = c("csv", "tsv", "xls", "xlsx", "rds")
  assertthat::assert_that(extension %in% valid_extensions,
                          msg=FormatMessage("Metadata file type must be: {valid_extensions*} (file can be gzipped)."))
  
  # Read metadata
  if (extension %in% c("csv", "tsv")) {
    meta_data = ReadMetadata_csv(file)
  } else if(extension %in% c("xls", "xlsx")) {
    meta_data = ReadMetadata_excel(file)
  } else if(extension %in% c("rds")) {
    meta_data = ReadMetadata_rds(file)
  }
  assertthat::not_empty(meta_data)
  
  return(meta_data)
}

#' Reads counts from a character-separated file.
#' 
#' @param csv_file Path to a character-separated counts file. First column contains the gene id (cell id if transpose is set), all other columns contain the counts.
#' @param transpose If TRUE then rows are cells and columns are genes (default: FALSE)
#' @return Sparse counts matrix (dgCMatrix format).
ReadCounts_csv = function(csv_file, transpose=FALSE) {
  library(magrittr)
  
  # Checks
  assertthat::is.readable(csv_file)
  
  # Read character-separated counts table with gene id in the first column and counts in the other columns 
  counts_data = readr::read_delim(csv_file, col_names=TRUE, comment="#", progress=FALSE, show_col_types=FALSE, col_types=readr::cols())
  row_ids = counts_data[, 1, drop=TRUE]
  col_ids = colnames(counts_data)
  col_ids = col_ids[-1]
  
  # Create sparse matrix
  if (transpose) {
    counts_data = Matrix::Matrix(data=counts_data[, -1, drop=FALSE] %>% as.matrix() %>% t(), 
                                 sparse=TRUE,
                                 dimnames = list(col_ids, row_ids))
  } else {
    counts_data = Matrix::Matrix(data=counts_data[, -1, drop=FALSE] %>% as.matrix(), 
                                 sparse=TRUE,
                                 dimnames = list(row_ids, col_ids))
  }
  return(list(All=counts_data))
}
  
#' Reads counts that are in market exchange format.
#' 
#' @param mtx_directory Path to counts directory in market exchange format.
#' @param mtx_file_name Name of the matrix mtx file (default: matrix.mtx.gz)
#' @param transpose If TRUE then rows are cells and columns are genes (default: FALSE)
#' @param barcodes_file_name Name of the barcodes character-separated file (default: barcodes.tsv.gz)
#' @param barcodes_column_names How to name the columns in the barcodes file. When TRUE, use the first line as header. When FALSE, use generic names. Alternatively, a character vector with column names can be provided (default: FALSE).
#' @param features_file_name Name of the features character-separated file (default: features.tsv.gz)
#' @param features_column_names How to name the columns in the features file. When TRUE, use the first line as header. When FALSE, use generic names. Alternatively, a character vector with column names can be provided (default: FALSE).
#' @param feature_type_column If there is data for multiple feature types, which column (number) in the features file is used to identify the type. If there is no column, set to NULL and type will be "Gene Expression" (default: NULL)
#' @param delim Delimiter used in barcodes and feature files (default: \t)
#' @param strip_suffix String that needs to be removed from the end of the barcodes (default: NULL) 
#' @return One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_mtx = function(mtx_directory, mtx_file_name="matrix.mtx.gz", transpose=FALSE, barcodes_file_name="barcodes.tsv.gz", barcodes_column_names=FALSE, features_file_name="features.tsv.gz", features_column_names=FALSE, feature_type_column=NULL, delim="\t", strip_suffix=NULL) {
  # Checks
  for(f in file.path(mtx_directory, c(mtx_file_name, barcodes_file_name, features_file_name))) assertthat::is.readable(f)
  
  # Read market exchange format file
  counts_data = Matrix::readMM(file=file.path(mtx_directory, mtx_file_name))
  if (transpose) {
    counts_data = Matrix::t(counts_data)
  }
  counts_data = as(counts_data, "CsparseMatrix")
  
  # Read barcodes file
  barcodes_data = readr::read_delim(file=file.path(mtx_directory, barcodes_file_name), col_names=barcodes_column_names, delim=delim, progress=FALSE, show_col_types=FALSE)
  barcodes_col_nms = colnames(barcodes_data)
  if (is.logical(barcodes_column_names) && barcodes_column_names==FALSE) {
    barcodes_col_nms = make.unique(rep("barcode_info", length(barcodes_col_nms)), sep="_")

  }
  barcodes_col_nms[1] = "barcode"
  colnames(barcodes_data) = barcodes_col_nms
  if (!is.null(strip_suffix)) {
    barcodes_data$barcode = trimws(barcodes_data$barcode, which="right", whitespace=strip_suffix)
  }
  barcodes_data = as.data.frame(barcodes_data)
  rownames(barcodes_data) = barcodes_data$barcode
  
  # Read features file
  features_data = readr::read_delim(file=file.path(mtx_directory, features_file_name), col_names=features_column_names, delim=delim, progress=FALSE, show_col_types=FALSE)
  feature_col_nms = colnames(features_data)
  if (is.logical(features_column_names) && features_column_names==FALSE)  {
    feature_col_nms = make.unique(rep("feature_info", length(feature_col_nms)), sep="_")
    
  }
  feature_col_nms[1] = "feature_id"
  colnames(features_data) = feature_col_nms
  features_data = as.data.frame(features_data)
  rownames(features_data) = features_data$feature_id
  
  # Split by feature type column
  feature_sets = list("All" = rep(TRUE, nrow(features_data)))
  if (!is.null(feature_type_column)) {
    feature_types = unique(features_data[, feature_type_column, drop=TRUE])
    
    if (length(feature_types) > 1) {
      feature_sets = purrr::map(feature_types, function(f) {
        return(features_data[, feature_type_column, drop=TRUE] == f)
      })
      names(feature_sets) = feature_types
    }
  }
  
  # Generate list of matrix (matrices)
  counts_lst = purrr::map(feature_sets, function(f) {
    cts = counts_data[f, ]
    col_ids = rownames(barcodes_data[, 1, drop=FALSE])
    row_ids = rownames(features_data[f, 1, drop=FALSE])
    dimnames(cts) = list(row_ids, col_ids)
    
    attr(cts, "barcode_metadata") = barcodes_data
    attr(cts, "feature_metadata") = features_data[f,, drop=FALSE]
    return(cts)
  })
  names(counts_lst) = names(counts_lst)
  
  return(counts_lst)
}

#' Reads counts from an anndata object in hdf5 format (generated by scanpy and co).
#' 
#' Note: This function does not read the entire counts data into memory. Instead it returns an iterator object that can be used to
#' retrieve values directly from file (random access). It is recommend to convert this object into a BPcells on-disk storage object.
#' 
#' Does not discriminate between feature types.
#' 
#' @param h5ad_file Path to an anndata object in hdf5 format.
#' @return Sparse counts matrix (AnnDataMatrixH5 format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_h5ad = function(h5ad_file) {
  library(magrittr)
  
  # Checks
  assertthat::is.readable(h5ad_file)
  
  # Read barcodes and features data separately
  barcodes_data = ReadMetadata_h5ad(h5ad_file=h5ad_file, type='obs')
  barcodes_col_nms = colnames(barcodes_data)
  barcodes_col_nms[1] = "barcode"
  colnames(barcodes_data) = barcodes_col_nms
  rownames(barcodes_data) = barcodes_data$barcode
  
  features_data = ReadMetadata_h5ad(h5ad_file=h5ad_file, type='var')
  features_data = features_data %>% dplyr::select(feature_id=gene_id,
                                  feature_name=gene_name,
                                  feature_type=gene_id,
                                  setdiff(colnames(features_data), c("gene_id", "gene_name")))
  features_data$feature_type = NA
  rownames(features_data) = features_data$feature_id
  
  # Read counts and attach barcodes/features data
  counts_data=BPCells::open_matrix_anndata_hdf5(h5ad_file)
  rownames(counts_data) = rownames(features_data)
  attr(counts_data, "barcode_metadata") = barcodes_data
  attr(counts_data, "feature_metadata") = features_data
  
  return(list(All=counts_data))
}


#' Reads counts data produced by plate-based methods like SmartSeq.
#' 
#' @param path Path to counts data. Can be a character-separated file or a matrix exchange format directory (with files matrix.mtx.gz, barcodes.tsv.gz and features.tsv.gz).
#' @param type Counts assay type. Can be: 'RNA' (gene expression), 'ATAC' (chromatin accessibility), 'ADT' (protein antibody capture), 'CRISPR' (CRISPR) or 'Custom'. Multiple types can be specified.
#' @param transpose  If TRUE then rows are cells and columns are genes (default: FALSE)
#' @return A sparse counts matrix (dgCMatrix format)
ReadCounts_SmartSeq = function(path, type="RNA", transpose=FALSE) {.
  # Checks
  assertthat::is.readable(path)
  
  valid_types = c("RNA", "ATAC", "ADT", "CRISPR", "Custom")
  assertthat::assert_that(all(type %in% valid_types),
                          msg=FormatMessage("'{type} must be: {valid_types*}."))
  
  if (dir.exists(path)) {
    # market exchange format
    counts_lst = ReadCounts_mtx(mtx_directory=path,
                   transpose=transpose,
                   barcodes_file_name="barcodes.tsv.gz",
                   barcodes_column_names=FALSE,
                   features_file_name="features.tsv.gz",
                   features_column_names=FALSE,
                   feature_type_column=NULL,
                   delim="\t",
                   strip_suffix=NULL)
    attr(counts_lst[[1]], "barcode_metadata") = NULL
    attr(counts_lst[[1]], "feature_metadata") = NULL
  } else {
    # character-separated file
    counts_lst = ReadCounts_csv(csv_file=path, transpose=transpose)
  }
  names(counts_lst) = type
  
  return(counts_lst)
}

#' Reads 10x counts that are in market exchange format.
#' 
#' @param mtx_directory Path to 10x counts directory in market exchange format.
#' @return One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_10x_mtx = function(mtx_directory) {
  # Determine the name of the matrix file
  mtx_file_name = dplyr::case_when(file.exists(file.path(mtx_directory, "matrix.mtx.gz")) ~ "matrix.mtx.gz",
                                   file.exists(file.path(mtx_directory, "matrix.mtx")) ~ "matrix.mtx")
  
  # Determine the name of the barcodes file
  barcodes_file_name = dplyr::case_when(
    file.exists(file.path(mtx_directory, "barcodes.tsv.gz")) ~ "barcodes.tsv.gz",
    file.exists(file.path(mtx_directory, "barcodes.tsv")) ~ "barcodes.tsv"
  )
  
  # Determine the name of the features file
  features_file_name = dplyr::case_when(
    file.exists(file.path(mtx_directory, "features.tsv.gz")) ~ "features.tsv.gz",
    file.exists(file.path(mtx_directory, "features.tsv")) ~ "features.tsv",
    file.exists(file.path(mtx_directory, "genes.tsv")) ~ "genes.tsv",
    file.exists(file.path(mtx_directory, "peaks.bed")) ~ "peaks.bed",
    file.exists(file.path(mtx_directory, "motifs.tsv")) ~ "motifs.tsv"
  )
  
  # Determine the column name of the features file
  if (features_file_name == "peaks.bed") {
    # 10x atac
    features_column_names = c("chr", "start", "end")
  } else if (features_file_name == "motifs.tsv") {
    # 10x atac
    features_column_names = c("tf_full_name", "tf_name")
  } else {
    feature_metadata = readr::read_delim(file.path(mtx_directory, features_file_name), delim="\t", col_names=FALSE, n_max=3, progress=FALSE, show_col_types=FALSE)
    
    if (ncol(feature_metadata)) {
      # 10x multiome
      features_column_names = c("feature_id",
                                "feature_name",
                                "feature_type",
                                "chr",
                                "start",
                                "end")
    } else {
      # 10x other
      features_column_names = c("feature_id", "feature_name", "feature_type")
    }
  }
  
  # Use more generic function to data in market exchange format
  counts_lst = ReadCounts_mtx(
    mtx_directory=mtx_directory,
    mtx_file_name=mtx_file_name,
    barcodes_file_name=barcodes_file_name,
    barcodes_column_names=FALSE,
    features_file_name=features_file_name,
    features_column_names=features_column_names,
    feature_type_column=3,
    delim = "\t",
    strip_suffix = "-1"
  )
  
  return(counts_lst)
}

#' Reads 10x counts that are in hdf5 format.
#' 
#' Note: This function does not read the entire counts data into memory. Instead it returns an iterator object that can be used to
#' retrieve values directly from file (random access). It is recommend to convert this object into a BPcells on-disk storage object.
#' 
#' @param hdf5_file Path to a 10x hdf5 counts file.
#' @return One sparse counts matrix per feature type (MatrixSubset format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_10x_hdf5 = function(hdf5_file) {
  # Checks
  assertthat::is.readable(hdf5_file)
  
  # Read barcodes and features data separately
  hdf5_fh = hdf5r::H5File$new(hdf5_file, mode = "r+")
  
  # No barcodes data, just a vector of the barcodes
  barcodes = hdf5_fh[["matrix/barcodes"]][]
  barcodes = trimws(barcodes, which="right", whitespace="-1")
  barcodes_data = data.frame(row.names=barcodes, barcode=barcodes)
  
  # Read feature data
  hdf5_features = hdf5_fh[["matrix/features"]]
  non_standard_features = hdf5_features[["_all_tag_keys"]][]
  features_data = data.frame(
    feature_id=hdf5_features[["id"]][],
    feature_name=hdf5_features[["name"]][],
    feature_type=hdf5_features[["feature_type"]][]
  )
  
  if (length(non_standard_features) > 0) {
    non_standard_features_data = purrr::map(non_standard_features, function(f) {
      return(hdf5_features[[f]][])
    })
    names(non_standard_features_data) = non_standard_features
    
    if ("interval" %in% names(non_standard_features_data)) {
      interval_data = list(
        chr = gsub(
          "^([^:]+):(\\d+)-(\\d+)$",
          "\\1",
          non_standard_features_data[["interval"]]
        ),
        start = gsub(
          "^([^:]+):(\\d+)-(\\d+)$",
          "\\2",
          non_standard_features_data[["interval"]]
        ),
        end = gsub(
          "^([^:]+):(\\d+)-(\\d+)$",
          "\\3",
          non_standard_features_data[["interval"]]
        )
      )
      
      idx = which(names(non_standard_features_data) == "interval")
      if (idx == 1) {
        pre_idx = c()
      } else {
        pre_idx = 1:(idx - 1)
      }
      if (idx == length(non_standard_features_data)) {
        post_idx = c()
      } else {
        post_idx = (idx + 1):length(non_standard_features_data)
      }
      non_standard_features_data = c(non_standard_features_data[pre_idx],
                                     interval_data,
                                     non_standard_features_data[post_idx])
    }
    features_data = cbind(features_data, non_standard_features_data)
  }
  rownames(features_data) = features_data$feature_id
  hdf5_fh$close_all()
  
  feature_types = unique(features_data$feature_type)
  counts_lst = purrr::map(feature_types, function(f) {
    cts = BPCells::open_matrix_10x_hdf5(hdf5_file, feature_type=f)
    colnames(cts) = trimws(colnames(cts), which="right", whitespace="-1")
    
    attr(cts, "barcode_metadata") = barcodes_data
    attr(cts, "feature_metadata") = features_data[features_data$feature_type == f, , drop=FALSE]
    
    return(cts)
  })
  names(counts_lst) = feature_types
  
  return(counts_lst)
}

#' Reads counts data produced by 10x.
#' 
#' @param path Path to 10x counts data. Can be a 10x hdf5 file (recommended for big datasets) or a 10x matrix exchange format directory.
#' @param type If there are multiple counts types in the dataset, which type to read. Can be: 'RNA' (gene expression), 'ATAC' (chromatin accessibility), 'ADT' (protein antibody capture), 'CRISPR' (CRISPR) or 'Custom'. Multiple types can be specified. If there is only one counts type, this simply sets the counts assay type.
#' @return One sparse counts matrix per feature type. Format is either MatrixSubset (when reading hdf5) or dgCMatrix (when reading from a matrix exchange format directory). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_10x = function(path, type, transpose=FALSE) {
  # Checks
  assertthat::is.readable(path)
  
  valid_types = c("RNA", "ATAC", "ADT", "CRISPR", "Custom")
  assertthat::assert_that(all(type %in% valid_types),
                          msg=FormatMessage("'{type} must be: {valid_types*}."))
  
  # Convert to type name in dataset
  converted_type = dplyr::case_when(
    type=="RNA" ~ "Gene Expression",
    type=="ATAC" ~ "Chromatin Accessibility",
    type=="ADT" ~ "Antibody Capture",
    type=="CRISPR" ~ "CRISPR Guide Capture",
    type=="Custom" ~ "CUSTOM"
  )
  names(type) = converted_type
  
  # Read counts
  if (dir.exists(path)) {
    # 10x market exchange format
    counts_lst = ReadCounts_10x_mtx(mtx_directory=path)
  } else {
    # 10x hdf5 file
    counts_lst = ReadCounts_10x_hdf5(hdf5_file=path)
  }
  
  # Rename/prepare
  if (length(counts_lst) == 1) {
    # Only one type
    names(counts_lst) = type
  } else {
    # Multiple types
    f = converted_type %in% names(counts_lst)
    assertthat::assert_that(all(f),
                            msg=FormatMessage("Dataset {path} does not contain the following types of data: {type[f]*} (named {converted_type[f]*} in the dataset)."))
    counts_lst = counts_lst[converted_type]
    names(counts_lst) = type
  }
  
  return(counts_lst)
}

#' Reads Parse Biosciences counts that are in market exchange format.
#' 
#' @param mtx_directory Path to Parse Biosciences counts directory in market exchange format. Typically contains the files count_matrix.mtx, cell_metadata.csv and all_genes.csv.
#' @return One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_ParseBio_mtx = function(mtx_directory) {
  # Determine the name of the matrix file
  mtx_file_name = "count_matrix.mtx"
  
  # Determine the name of the barcodes file
  barcodes_file_name = "cell_metadata.csv"
  
  # Determine the name of the features file
  features_file_name = "all_genes.csv"
  
  # Use more generic function to data in market exchange format
  counts_lst = ReadCounts_mtx(
    mtx_directory=mtx_directory,
    transpose=TRUE,
    mtx_file_name=mtx_file_name,
    barcodes_file_name=barcodes_file_name,
    barcodes_column_names=TRUE,
    features_file_name=features_file_name,
    features_column_names=TRUE,
    feature_type_column=NULL,
    delim = ","
  )
  
  return(counts_lst)
}

#' Reads Parse Biosciences counts that are in h5ad anndata format.
#' 
#' Note: This function does not read the entire counts data into memory. Instead it returns an iterator object that can be used to
#' retrieve values directly from file (random access). It is recommend to convert this object into a BPcells on-disk storage object.
#' 
#' Does not discriminate between feature types.
#' 
#' @param h5ad_file Path to an anndata object in hdf5 format.
#' @return Sparse counts matrix (AnnDataMatrixH5 format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_ParseBio_h5ad = function(h5ad_file) {
  return(ReadCounts_h5ad(h5ad_file))
}

#' Reads counts data produced by Parse Biosciences.
#' 
#' @param path Path to Parse Biosciences counts data. Can be a Parse Biosciences anndata.h5ad file (recommended for big datasets) or a Parse Biosciences matrix exchange format directory.
#' @param type If there are multiple counts types in the dataset, which type to read. Can be: 'RNA' (gene expression), 'ATAC' (chromatin accessibility), 'ADT' (protein antibody capture), 'CRISPR' (CRISPR) or 'Custom'. Multiple types can be specified. If there is only one counts type, this simply sets the counts assay type.
#' @return One sparse counts matrix. Format is either AnnDataMatrixH5 (when reading anndata.h5ad) or dgCMatrix (when reading from a matrix exchange format directory). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_ParseBio = function(path, type, transpose=FALSE) {
  # Checks
  assertthat::is.readable(path)
  
  valid_types = c("RNA", "ATAC", "ADT", "CRISPR", "Custom")
  assertthat::assert_that(all(type %in% valid_types),
                          msg=FormatMessage("'{type} must be: {valid_types*}."))
  
  # Convert to type name in dataset
  converted_type = dplyr::case_when(
    type=="RNA" ~ "Gene Expression",
    type=="ATAC" ~ "Chromatin Accessibility",
    type=="ADT" ~ "Antibody Capture",
    type=="CRISPR" ~ "CRISPR Guide Capture",
    type=="Custom" ~ "CUSTOM"
  )
  names(type) = converted_type
  
  # Read counts
  if (dir.exists(path)) {
    # 10x market exchange format
    counts_lst = ReadCounts_ParseBio_mtx(mtx_directory=path)
  } else {
    # 10x hdf5 file
    counts_lst = ReadCounts_ParseBio_h5ad(h5ad_file=path)
  }
  
  # Rename/prepare
  if (length(counts_lst) == 1) {
    # Only one type
    names(counts_lst) = type
  } else {
    # Multiple types
    f = converted_type %in% names(counts_lst)
    assertthat::assert_that(all(f),
                            msg=FormatMessage("Dataset {path} does not contain the following types of data: {type[f]*} (named {converted_type[f]*} in the dataset)."))
    counts_lst = counts_lst[converted_type]
    names(counts_lst) = type
  }
  
  return(counts_lst)
}

#' Reads Scale Bio counts that are in market exchange format.
#' 
#' @param mtx_directory Path to Scale Bio counts directory in market exchange format. Typically contains the files matrix.mtx.gz, barcodes.tsv.gz and features.tsv.gz.
#' @return One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_ScaleBio_mtx = function(mtx_directory) {
  # Determine the name of the matrix file
  mtx_file_name = "matrix.mtx"
  
  # Determine the name of the barcodes file
  barcodes_file_name = "barcodes.tsv"
  
  # Determine the name of the features file
  features_file_name = "features.tsv"
  
  # Use more generic function to data in market exchange format
  counts_lst = ReadCounts_mtx(
    mtx_directory=mtx_directory,
    transpose=FALSE,
    mtx_file_name=mtx_file_name,
    barcodes_file_name=barcodes_file_name,
    barcodes_column_names=FALSE,
    features_file_name=features_file_name,
    features_column_names=c("feature_id", "feature_name", "feature_type"),
    feature_type_column=3,
    delim = "\t"
  )
  
  return(counts_lst)
}

#' Reads counts data produced by Scale Bio
#' 
#' @param path Path to Scale Bio counts data. Must be a Scale Bio matrix exchange format directory.
#' @param type If there are multiple counts types in the dataset, which type to read. Can be: 'RNA' (gene expression), 'ATAC' (chromatin accessibility), 'ADT' (protein antibody capture), 'CRISPR' (CRISPR) or 'Custom'. Multiple types can be specified. If there is only one counts type, this simply sets the counts assay type.
#' @return  One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata
ReadCounts_ScaleBio = function(path, type, transpose=FALSE) {
  # Checks
  assertthat::is.readable(path)

  valid_types = c("RNA", "ATAC", "ADT", "CRISPR", "Custom")
  assertthat::assert_that(all(type %in% valid_types),
                          msg=FormatMessage("'{type} must be: {valid_types*}."))
  
  
  # Convert to type name in dataset
  converted_type = dplyr::case_when(
    type=="RNA" ~ "Gene Expression",
    type=="ATAC" ~ "Chromatin Accessibility",
    type=="ADT" ~ "Antibody Capture",
    type=="CRISPR" ~ "CRISPR Guide Capture",
    type=="Custom" ~ "CUSTOM"
  )
  names(type) = converted_type
  
  # Read counts
  counts_lst = ReadCounts_ScaleBio_mtx(mtx_directory=path)
  
  # Rename/prepare
  if (length(counts_lst) == 1) {
    # Only one type
    names(counts_lst) = type
  } else {
    # Multiple types
    f = converted_type %in% names(counts_lst)
    assertthat::assert_that(all(f),
                            msg=FormatMessage("Dataset {path} does not contain the following types of data: {type[f]*} (named {converted_type[f]*} in the dataset)."))
    counts_lst = counts_lst[converted_type]
    names(counts_lst) = type
  }
  
  return(counts_lst)
}

#' Reads counts data produced by Smartseq, 10x, Parse Biosciences, Scale Bio.
#' 
#' @param path Path to counts data. Can be: character-separated file (Smartseq), matrix exchange format directory (SmartSeq, 10x, Parse Biosciences, ScaleBio), hdf5 file (10x), h5ad file (Parse Biosciences).
#' @param technology Technology. Can be: 'smartseq', '10x', 'parse' or 'scale'.
#' @param type If there are multiple counts types in the dataset, which type to read. Can be: 'RNA' (gene expression), 'ATAC' (chromatin accessibility), 'ADT' (protein antibody capture), 'CRISPR' (CRISPR) or 'Custom'. Multiple types can be specified. If there is only one counts type, this simply sets the counts assay type.
#' @param barcode_metadata_file Optional path to additional barcode metadata. Can be: character-separated file, Excel file or a table saved R rds file. First column must contain the barcode. Missing barcodes will be filled with NA.
#' @param feature_metadata_file Optional path to additional feature metadata. Can be: character-separated file, Excel file or a table saved R rds file. First column must contain the feature id. Missing features will be filled with NA.
#' @param rename_barcodes If not NULL, controls how to rename the barcodes. Can be a character vector of length 1 with the name of a barcode metadata column or a named character vector with names being the old barcode names and values being the new barcode names. The named character vector can also contain just a subset of barcodes for renaming and all other barcodes stay untouched.
#' @param rename_features If not NULL, controls how to rename the features. Can be a character vector of length 1 with the name of a feature metadata column or a named character vector with names being the old feature names and values being the new feature names. The named character vector can also contain just a subset of features for renaming and all other features stay untouched.
#' @param barcode_suffix Suffix to add to the barcodes (default: NULL). When barcodes are renamed, will be applied afterwards.
#' @param on_disk_path If not NULL, do not store counts in memory but on disk in a matrix directory at this path. Together with the BPcells package, this allows the analysis of very large datasets since at all times just a small part but never the entire counts matrix is kept in memory. 
#' @param on_disk_overwrite If TRUE, overwrite existing matrix directories. If FALSE, read and return existing matrix directories.
#' @return  One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata

ReadCounts = function(path, technology, type, barcode_metadata_file=NULL, feature_metadata_file=NULL, rename_barcodes=NULL, rename_features=NULL, barcode_suffix=NULL, on_disk_path=NULL, on_disk_overwrite=FALSE) {
  library(magrittr)
  
  path = "datasets/10x_pbmc_5k_protein/counts/"
  technology = "10x"
  type = c("RNA", "ADT")
  on_disk_path = "this"
  on_disk_overwrite = FALSE
  barcode_metadata_file = NULL
  feature_metadata_file = NULL
  rename_barcodes = NULL
  rename_features = "feature_name"
  barcode_suffix = NULL
  
  # Checks
  valid_technologies = c("smartseq", "10x", "parse", "scale")
  assertthat::assert_that(technology %in% valid_technologies,
                          msg=FormatMessage("Technology is {technology} but must be one of: {valid_technologies*}."))
  
  # Read counts
  if (technology == "smartseq") {
    counts_lst = ReadCounts_SmartSeq(path=path, type=type)
  } else if(technology == "10x") {
    counts_lst = ReadCounts_10x(path=path, type=type)
  } else if(technology == "parse") {
    counts_lst = ReadCounts_ParseBio(path=path, type=type)
  } else if(technology == "scale") {
    counts_lst = ReadCounts_ScaleBio(path=path, type=type)
  }
  assertthat::not_empty(counts_lst)
  
  # Read metadata and add to counts objects
  if (!is.null(barcode_metadata_file)) {
    barcode_metadata = ReadMetadata(barcode_metadata_file)

    for(i in seq_along(counts_lst)) {
      # Do we have already other barcode metadata
      if ("barcode_metadata" %in% names(attributes(counts_lst[[i]]))) {
        metadata = attr(counts_lst[[i]], "barcode_metadata")
      } else {
        metadata = data.frame(id=colnames(counts_lst[[i]]))
      }
      
      x_id = colnames(metadata)[1]
      y_id = colnames(barcode_metadata)[1]
      metadata = dplyr::left_join(x=metadata,
                                   y=barcode_metadata,
                                   by=setNames(y_id, x_id))
      attr(counts_lst[[i]], "barcode_metadata") = metadata
    }
  }
  
  if (!is.null(feature_metadata_file)) {
    feature_metadata = ReadMetadata(feature_metadata_file)

    for(i in seq_along(counts_lst)) {
      # Do we have already other feature metadata
      if ("feature_metadata" %in% names(attributes(counts_lst[[i]]))) {
        metadata = attr(counts_lst[[i]], "feature_metadata")
      } else {
        metadata = data.frame(id=rownames(counts_lst[[i]]))
      }
      
      x_id = colnames(metadata)[1]
      y_id = colnames(feature_metadata)[1]
      metadata = dplyr::left_join(x=metadata,
                                  y=feature_metadata,
                                  by=setNames(y_id, x_id))
      attr(counts_lst[[i]], "feature_metadata") = metadata
    }
  }
  
  # Update barcode and feature names
  if (!is.null(rename_barcodes)) {
    if (length(names(rename_barcodes))==0) {
      barcode_name_column = rename_barcodes[1]
      for(i in seq_along(counts_lst)) {
        metadata = attr(counts_lst[[i]], "barcode_metadata")
        assertthat::assert_that(barcode_name_column %in% colnames(metadata),
                                msg=FormatMessage("Column {barcode_name_column} cannot be found in the barcode metadata available for dataset {path}."))
        new_barcode_names = metadata[, barcode_name_column, drop=TRUE]
        if (any(duplicated(new_barcode_names))) {
          warning(FormatMessage("Metadata column {barcode_name_column} contains duplicate values for dataset {path}. Barcode names will be made unique."))
          new_barcode_names = make.unique(new_barcode_names)
        }
        colnames(counts_lst[[i]]) = new_barcode_names
      }
    } else if (length(names(rename_barcodes))>0) {
      barcode_names = rename_barcodes
      new_barcode_names = ifelse(colnames(counts_lst[[i]]) %in% names(barcode_names),
                                 barcode_names[colnames(counts_lst[[i]])],
                                 colnames(counts_lst[[i]]))
      if (any(duplicated(new_barcode_names))) {
        warning(FormatMessage("Provided barcode names contain duplicate values for dataset {path}. Barcode names will be made unique."))
        new_barcode_names = make.unique(new_barcode_names)
      }
      colnames(counts_lst[[i]]) = unname(new_barcode_names)
    }
  }
  
  if (!is.null(rename_features)) {
    if (length(names(rename_features))==0) {
      feature_name_column = rename_features[1]
      for(i in seq_along(counts_lst)) {
        metadata = attr(counts_lst[[i]], "feature_metadata")
        assertthat::assert_that(feature_name_column %in% colnames(metadata),
                                msg=FormatMessage("Column {feature_name_column} cannot be found in the feature metadata available for dataset {path}."))
        new_feature_names = metadata[, feature_name_column, drop=TRUE]
        if (any(duplicated(new_feature_names))) {
          warning(FormatMessage("Metadata column {feature_name_column} contains duplicate values for dataset {path}. Feature names will be made unique."))
          new_feature_names = make.unique(new_feature_names)
        }
        rownames(counts_lst[[i]]) = new_feature_names
      }
    } else if (length(names(rename_features))>0) {
      feature_names = rename_features
      new_feature_names = ifelse(rownames(counts_lst[[i]]) %in% names(feature_names),
                                 feature_names[colnames(counts_lst[[i]])],
                                 rownames(counts_lst[[i]]))
      if (any(duplicated(new_feature_names))) {
        warning(FormatMessage("Provided feature names contain duplicate values for dataset {path}. Feature names will be made unique."))
        new_feature_names = make.unique(new_feature_names)
      }
      rownames(counts_lst[[i]]) = unname(new_feature_names)
    }
  }
  
  # Add barcode suffix
  if (!is.null(barcode_suffix)) {
    for(i in seq_along(counts_lst)) {
      colnames(counts_lst[[i]]) = paste0(colnames(counts_lst[[i]]), barcode_suffix)
    }
  }
  
  # Store counts in memory or write counts into matrix directory
  for(n in names(counts_lst)) {
    if (!is.null(on_disk_path)) {
      # in matrix directory
      if (is(counts_lst[[n]], 'dgCMatrix')) {
        # test if we have non-negative integers, then convert matrix save disk space (default is double)
        vals = sample(counts_lst[[n]]@x, min(length(counts_lst[[n]]@x), 100000))
        
        counts_lst[[n]] = as(counts_lst[[n]], "IterableMatrix")
        if (all(vals >= 0) & all(vals == round(vals))) {
          counts_lst[[n]] = BPCells::convert_matrix_type(counts_lst[[n]], type="uint32_t")
        }
      }
      
      if (dir.exists(file.path(on_disk_path, n)) & on_disk_overwrite==FALSE) {
        counts_lst[[n]] = BPCells::open_matrix_dir(file.path(on_disk_path, n))
      } else {
        counts_lst[[n]] = BPCells::write_matrix_dir(mat=counts_lst[[n]], dir=file.path(on_disk_path, n), overwrite=on_disk_overwrite)
      }
    } else {
      # in memory: make sure it is sparse
      if (!is(counts_lst[[n]], 'dgCMatrix')) {
        counts_lst[[n]] = counts_lst[[n]] %>% as("sparseMatrix")
      }
    }
  }
}

#1. Then got list of assays for all samples and types
#2. Group by type
#3. CreateSeuratObject for all RNA
#4. Then add others as assays
#5. Add metadata
#6. Set column SAMPLE and column dataset