# 10x feature types and assay names
Assays_10x = list("Gene Expression" = "RNA",
                  "Multiplexing Capture" = "MPLX",
                  "VDJ T" = "VDJT",
                  "VDJ B" = "VDJB",
                  "Antibody Capture" = "ADT",
                  "Peaks" = "ATAC",
                  "CRISPR Guide Capture" = "CRISPR",
                  "Antigen Capture" = "BEAM",
                  "Custom" = "CUSTOM",
                  "Negative Control Codeword" = "ControlCodeword",
                  "Negative Control Probe" = "ControlProbe",
                  "Unassigned Codeword" = "BlankCodeword")

Assays_Scale = list("Gene Expression" = "RNA",
                  "Antibody Capture" = "ADT",
                  "Chromatin Accessibility" = "ATAC",
                  "CRISPR Guide Capture" = "CRISPR")

Assays_Parse = list("Gene Expression" = "RNA",
                    "Antibody Capture" = "ADT",
                    "Chromatin Accessibility" = "ATAC",
                    "CRISPR Guide Capture" = "CRISPR")

Assays_Smartseq = list("Gene Expression" = "RNA",
                    "Antibody Capture" = "ADT",
                    "Chromatin Accessibility" = "ATAC")

#' Reads metadata from an anndata object in hdf5 format (generated by scanpy).
#' 
#' Largely copied and adapted from Azimuth::LoadH5ADobs!
#' 
#' @param h5ad_file Path to an anndata object in hdf5 format
#' @param type Can be 'obs' (for barcodes) or 'var' (for features).
#' @return Metadata (data.frame format)
ReadMetadata_h5ad = function(h5ad_file, type) {
  # Checks
  assertthat::is.readable(h5ad_file)
  
  # Open hdf5 file with anndata object
  hdf5_fh = hdf5r::H5File$new(h5ad_file, mode = "r+")
  hd5_data = hdf5_fh[[paste0("/", type)]]
  
  # Create metadata matrix
  index.var = hdf5r::h5attr(hd5_data, "_index")
  index = hd5_data[[index.var]][]
  groups = names(hd5_data)
  matrix = as.data.frame(x = matrix(
    data = NA,
    nrow = length(index),
    ncol = length(groups)
  ))
  colnames(matrix) = groups
  rownames(matrix) = index
  
  # Get columns and values
  if ("__categories" %in% names(x = hd5_data)) {
    hd5_data_cate = hd5_data[["__categories"]]
    for (i in seq_along(groups)) {
      g.i = groups[i]
      value_i = hd5_data[[g.i]][]
      if (g.i %in% names(x = hd5_data_cate)) {
        value_i = factor(x = value_i, labels = hd5_data[[g.i]][])
      }
      matrix[, i] = value_i
    }
  } else {
    for (i in seq_along(groups)) {
      g.i = groups[i]
      if (all(names(hd5_data[[g.i]]) == c("categories", "codes"))) {
        if (length(unique(hd5_data[[g.i]][["codes"]][])) == length(hd5_data[[g.i]][["categories"]][])) {
          value_i = factor(x = hd5_data[[g.i]][["codes"]][], labels = hd5_data[[g.i]][["categories"]][])
        }
        else {
          value_i = hd5_data[[g.i]][["codes"]][]
        }
      }
      else {
        value_i = tryCatch(expr = hd5_data[[g.i]][],
                           error=function(e) return("unknown")
        )
      }
      matrix[, i] = value_i
    }
  }
  
  hdf5_fh$close_all()
  return(as.data.frame(matrix))
}

#' Reads metadata from a character-separated file.
#' 
#' @param h5ad_file Path to a character-separated file. First column must contain the respective barcode or feature id.
#' @return Metadata (data.frame format)
ReadMetadata_csv = function(csv_file) {
  # Checks
  assertthat::is.readable(csv_file)
  
  # Read table
  meta_data = readr::read_delim(csv_file, col_names=TRUE, comment="#", progress=FALSE, show_col_types=FALSE, col_types=readr::cols())
  meta_data = as.data.frame(meta_data)
  
  # Assert that first column is unique
  assertthat::assert_that(all(not(duplicated(meta_data[, 1, drop=TRUE]))),
                          msg=FormatMessage("Metadata file {file} contains duplicate values in first column."))
  
  # Create table
  rownames(meta_data) = meta_data[, 1, drop=TRUE]
  return(meta_data)
}

#' Reads metadata from an Excel file.
#' 
#' @param excel_file Path to an Excel file. First column must contain the respective barcode or feature id.
#' @param sheet Sheet number. description
#' @return Metadata (data.frame format)
ReadMetadata_excel = function(excel_file, sheet=1) {
  # Checks
  assertthat::is.readable(excel_file)
  
  # Read table
  meta_data = readxl::read_excel(excel_file, sheet=sheet, col_names=TRUE)
  meta_data = as.data.frame(meta_data)
  
  # Assert that first column is unique
  assertthat::assert_that(all(not(duplicated(meta_data[, 1, drop=TRUE]))),
                          msg=FormatMessage("Metadata file {file} contains duplicate values in first column."))
  
  # Create table
  rownames(meta_data) = meta_data[, 1, drop=TRUE]
  return(meta_data)
}

#' Reads metadata from a metadata table saved as R rds file.
#' 
#' This method preserves factor levels.
#' 
#' @param rds_file Path to an R rds file. First column must contain the respective barcode or feature id.
#' @return Metadata (data.frame format)
ReadMetadata_rds = function(rds_file) {
  # Checks
  assertthat::is.readable(rds_file)
  
  # Read table
  meta_data = readRDS(rds_file)
  meta_data = as.data.frame(meta_data)
  
  # Assert that first column is unique
  assertthat::assert_that(all(not(duplicated(meta_data[, 1, drop=TRUE]))),
                          msg=FormatMessage("Metadata file {file} contains duplicate values in first column."))
  
  # Create table
  rownames(meta_data) = meta_data[, 1, drop=TRUE]
  return(meta_data)
}

#' Reads metadata.
#' 
#' @param file Path to a character-separated file (csv, tsv, csv.gz, tsv.gz), an Excel file (xls, xslx) or an R rds file containing a table (preserves factor levels). First column must contain the respective barcode or feature id. For Excel files, a sheet can be specified by appending ':<sheet_number>'.
#' @return Metadata (data.frame format)
ReadMetadata = function(file) {
  # Sheet number appended?
  sheet = 1
  if (grepl(":\\d+$", file)) {
    sheet = gsub(pattern=".+:(\\d+)$", replacement="\\1", x=file)
    file = gsub(pattern=":\\d+$", replacement="", x=file)
  }
  
  # Checks
  extension = tools::file_ext(gsub(pattern="\\.gz$", replacement="", x=file))
  valid_extensions = c("csv", "tsv", "xls", "xlsx", "rds")
  assertthat::assert_that(extension %in% valid_extensions,
                          msg=FormatMessage("Metadata file type must be: {valid_extensions*} (file can be gzipped)."))
  
  # Read metadata
  if (extension %in% c("csv", "tsv")) {
    meta_data = ReadMetadata_csv(file)
  } else if(extension %in% c("xls", "xlsx")) {
    meta_data = ReadMetadata_excel(file, sheet=sheet)
  } else if(extension %in% c("rds")) {
    meta_data = ReadMetadata_rds(file)
  }
  
  # Assert that it is not empty
  assertthat::assert_that(assertthat::not_empty(meta_data),
                          msg=FormatMessage("Metadata file {file} is empty."))

  return(meta_data)
}

#' Reads the datasets table.
#' 
#' TODO: Code may be a bit redundant with ReadMetadata. On the other hand, it does some specific checks.
#' 
#' @param file Path to a character-separated file (csv, tsv, csv.gz, tsv.gz) or an Excel file (xls, xslx). For Excel files, a sheet can be specified by appending ':<sheet_number>'. Needs to contain the following columns:
#' @return Metadata (data.frame format)
ReadDatasetsTable = function(file) {
  #file ="datasets/pbmc_datasets.xlsx"
  
  # Sheet number appended?
  sheet = 1
  if (grepl(":\\d+$", file)) {
    sheet = gsub(pattern=".+:(\\d+)$", replacement="\\1", x=file)
    file = gsub(pattern=":\\d+$", replacement="", x=file)
  }
  
  # Checks
  extension = tools::file_ext(gsub(pattern="\\.gz$", replacement="", x=file))
  valid_extensions = c("csv", "tsv", "xls", "xlsx", "rds")
  assertthat::assert_that(extension %in% valid_extensions,
                          msg=FormatMessage("Datasets file type must be: {valid_extensions*} (file can be gzipped)."))
  
  # Read datasets table
  if (extension %in% c("csv", "tsv")) {
    datasets_table = readr::read_delim(file, col_names=TRUE, comment="#", progress=FALSE, show_col_types=FALSE, col_types="text")
  } else if(extension %in% c("xls", "xlsx")) {
    datasets_table = readxl::read_excel(file, sheet=sheet, col_names=TRUE)
  }
  assertthat::assert_that(assertthat::not_empty(datasets_table),
                          msg=FormatMessage("Datasets file {file} is empty."))
  
  # Check that all columns are present
  
  
  return(datasets_table)
}

#' Reads counts from a character-separated file.
#' 
#' @param csv_file Path to a character-separated counts file. First column contains the feature id (barcode id if transpose is set), all other columns contain the barcode (feature) counts.
#' @param transpose If TRUE then rows are barcodes and columns are features (default: FALSE)
#' @return Sparse counts matrix (dgCMatrix format).
ReadCounts_csv = function(csv_file, transpose=FALSE) {
  library(magrittr)
  
  # Checks
  assertthat::is.readable(csv_file)
  
  # Read character-separated counts table with gene id in the first column and counts in the other columns 
  counts_data = readr::read_delim(csv_file, col_names=TRUE, comment="#", progress=FALSE, show_col_types=FALSE, col_types=readr::cols())
  row_ids = counts_data[, 1, drop=TRUE]
  col_ids = colnames(counts_data)
  col_ids = col_ids[-1]
  
  # Check that barcodes and features are unique
  assertthat::assert_that(sum(duplicated(col_ids)) == 0,
                          msg=FormatMessage("Dataset {csv_file} contains at least two barcodes with the same name."))
  
  assertthat::assert_that(sum(duplicated(row_ids)) == 0,
                          msg=FormatMessage("Dataset {csv_file} contains at least two features with the same name.")) 
  
  # Create sparse matrix
  if (transpose) {
    counts_data = Matrix::Matrix(data=counts_data[, -1, drop=FALSE] %>% as.matrix() %>% t(), 
                                 sparse=TRUE,
                                 dimnames = list(col_ids, row_ids))
  } else {
    counts_data = Matrix::Matrix(data=counts_data[, -1, drop=FALSE] %>% as.matrix(), 
                                 sparse=TRUE,
                                 dimnames = list(row_ids, col_ids))
  }
  return(list(All=counts_data))
}
  
#' Reads counts that are in market exchange format.
#' 
#' @param mtx_directory Path to counts directory in market exchange format.
#' @param mtx_file_name Name of the matrix mtx file (default: matrix.mtx.gz)
#' @param transpose If TRUE then rows are cells and columns are genes (default: FALSE)
#' @param barcodes_file_name Name of the barcodes character-separated file (default: barcodes.tsv.gz)
#' @param barcodes_column_names How to name the columns in the barcodes file. When TRUE, use the first line as header. When FALSE, use generic names. Alternatively, a character vector with column names can be provided (default: FALSE).
#' @param features_file_name Name of the features character-separated file (default: features.tsv.gz)
#' @param features_column_names How to name the columns in the features file. When TRUE, use the first line as header. When FALSE, use generic names. Alternatively, a character vector with column names can be provided (default: FALSE).
#' @param feature_type_column If there is data for multiple feature types, which column (number) in the features file is used to identify the type. If there is no column, set to NULL and type will be "Gene Expression" (default: NULL)
#' @param delim Delimiter used in barcodes and feature files (default: \t)
#' @param strip_suffix String that needs to be removed from the end of the barcodes (default: NULL) 
#' @return One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_mtx = function(mtx_directory, mtx_file_name="matrix.mtx.gz", transpose=FALSE, barcodes_file_name="barcodes.tsv.gz", barcodes_column_names=FALSE, features_file_name="features.tsv.gz", features_column_names=FALSE, feature_type_column=NULL, delim="\t", strip_suffix=NULL) {
  # Checks
  for(f in file.path(mtx_directory, c(mtx_file_name, barcodes_file_name, features_file_name))) assertthat::is.readable(f)
  
  # Read market exchange format file
  counts_data = Matrix::readMM(file=file.path(mtx_directory, mtx_file_name))
  if (transpose) {
    counts_data = Matrix::t(counts_data)
  }
  counts_data = as(counts_data, "CsparseMatrix")
  
  # Read barcodes file
  barcodes_data = readr::read_delim(file=file.path(mtx_directory, barcodes_file_name), col_names=barcodes_column_names, delim=delim, progress=FALSE, show_col_types=FALSE)
  barcodes_col_nms = colnames(barcodes_data)
  if (is.logical(barcodes_column_names) && barcodes_column_names==FALSE) {
    barcodes_col_nms = rep("barcode_info", length(barcodes_col_nms)) %>% make.unique(sep="_")

  }
  barcodes_col_nms[1] = "orig_barcode"
  colnames(barcodes_data) = barcodes_col_nms
  barcodes_data = as.data.frame(barcodes_data)
  
  if (!is.null(strip_suffix)) {
    rownames(barcodes_data) = trimws(barcodes_data[, 1, drop=TRUE], which="right", whitespace=strip_suffix)
  } else {
    rownames(barcodes_data) = barcodes_data[, 1, drop=TRUE]
  }
  
  # Read features file
  features_data = readr::read_delim(file=file.path(mtx_directory, features_file_name), col_names=features_column_names, delim=delim, progress=FALSE, show_col_types=FALSE)
  feature_col_nms = colnames(features_data)
  if (is.logical(features_column_names) && features_column_names==FALSE)  {
    feature_col_nms = make.unique(rep("feature_info", length(feature_col_nms)), sep="_")
    
  }
  feature_col_nms[1] = "feature_id"
  colnames(features_data) = feature_col_nms
  features_data = as.data.frame(features_data)
  rownames(features_data) = features_data[, 1, drop=TRUE]
  
  # Split by feature type column
  feature_sets = list("All" = rep(TRUE, nrow(features_data)))
  if (!is.null(feature_type_column)) {
    feature_types = unique(features_data[, feature_type_column, drop=TRUE])
    
    if (length(feature_types) > 1) {
      feature_sets = purrr::map(feature_types, function(f) {
        return(features_data[, feature_type_column, drop=TRUE] == f)
      })
      names(feature_sets) = feature_types
    }
  }
  
  # Generate list of matrix (matrices)
  counts_lst = purrr::map(feature_sets, function(f) {
    cts = counts_data[f, ]
    col_ids = rownames(barcodes_data[, 1, drop=FALSE])
    row_ids = rownames(features_data[f, 1, drop=FALSE])
    dimnames(cts) = list(row_ids, col_ids)
    
    attr(cts, "barcode_metadata") = barcodes_data
    attr(cts, "feature_metadata") = features_data[f,, drop=FALSE]
    return(cts)
  })
  names(counts_lst) = names(counts_lst)
  
  return(counts_lst)
}

#' Reads counts from an anndata object in hdf5 format (generated by scanpy and co).
#' 
#' Note: This function does not read the entire counts data into memory. Instead it returns an iterator object that can be used to
#' retrieve values directly from file (random access). It is recommend to convert this object into a BPcells on-disk storage object.
#' 
#' Does not discriminate between feature types.
#' 
#' @param h5ad_file Path to an anndata object in hdf5 format.
#' @return Sparse counts matrix (IterableMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_h5ad = function(h5ad_file) {
  library(magrittr)
  
  # Checks
  assertthat::is.readable(h5ad_file)
  
  # Read barcodes and features data separately
  barcodes_data = ReadMetadata_h5ad(h5ad_file=h5ad_file, type='obs')
  barcodes_col_nms = colnames(barcodes_data)
  barcodes_col_nms[1] = "orig_barcode"
  colnames(barcodes_data) = barcodes_col_nms
  rownames(barcodes_data) = barcodes_data[, 1, drop=TRUE]
  
  features_data = ReadMetadata_h5ad(h5ad_file=h5ad_file, type='var')
  features_data = features_data %>% dplyr::select(feature_id=gene_id,
                                  feature_name=gene_name,
                                  feature_type=gene_id,
                                  setdiff(colnames(features_data), c("gene_id", "gene_name")))
  features_data$feature_type = NA
  rownames(features_data) = features_data$feature_id
  
  # Read counts and attach barcodes/features data
  counts_data=BPCells::open_matrix_anndata_hdf5(h5ad_file)
  rownames(counts_data) = rownames(features_data)
  attr(counts_data, "barcode_metadata") = barcodes_data
  attr(counts_data, "feature_metadata") = features_data
  
  return(list(All=counts_data))
}


#' Reads counts data produced by plate-based methods like SmartSeq.
#' 
#' @param path Path to counts data. Can be a character-separated file or a matrix exchange format directory (with files matrix.mtx.gz, barcodes.tsv.gz and features.tsv.gz).
#' @param assay This simply sets the assay type.
#' @param version Set to '2' for Smartseq2 or '3' for Smartseq3.
#' @param transpose  If TRUE then rows are cells and columns are genes (default: FALSE)
#' @return A sparse counts matrix (dgCMatrix format)
ReadCounts_SmartSeq = function(path, assay, version, transpose=FALSE) {
  #path = "./test.csv.gz"
  #assay = "RNA"
  #version = "2"
  
  # Checks
  assertthat::is.readable(path)
  assertthat::assert_that(version %in% c("2", "3"),
                          msg=FormatMessage("Smartseq version must be '2' or '3'."))
  
  
  # Convert to feature type in dataset
  assay_to_feature_type = setNames(names(Assays_Smartseq), Assays_Smartseq)
  valid_assays = names(assay_to_feature_type)
  assertthat::assert_that(assay %in% valid_assays,
                          msg=FormatMessage("'{assay} must be: {valid_assays*}."))

  if (dir.exists(path)) {
    # market exchange format
    counts_lst = ReadCounts_mtx(mtx_directory=path,
                   transpose=transpose,
                   mtx_directory="matrix.mtx.gz",
                   barcodes_file_name="barcodes.tsv.gz",
                   barcodes_column_names=FALSE,
                   features_file_name="features.tsv.gz",
                   features_column_names=FALSE,
                   feature_type_column=NULL,
                   delim="\t",
                   strip_suffix=NULL)
    counts_lst = counts_lst[1]
  } else {
    # character-separated file
    counts_lst = ReadCounts_csv(csv_file=path, transpose=transpose)
    barcode_metadata = data.frame(orig_barcode=colnames(counts_lst[[1]]),
                                  row.names=colnames(counts_lst[[1]]))
    feature_metadata = data.frame(feature_id=rownames(counts_lst[[1]]),
                                  row.names=rownames(counts_lst[[1]]))
    attr(counts_lst[[1]], "barcode_metadata") = barcode_metadata
    attr(counts_lst[[1]], "feature_metadata") = feature_metadata
  }
  
  # Assay
  names(counts_lst) = assays[1]
  
  # Add attributes technology and assay
  attr(counts_lst[[1]], "technology") = paste0("Smartseq", version)
  attr(counts_lst[[1]], "assay") = assays[1]
  
  return(counts_lst)
}

#' Reads 10x counts that are in market exchange format.
#' 
#' @param mtx_directory Path to 10x counts directory in market exchange format.
#' @return One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_10x_mtx = function(mtx_directory) {
  # Determine the name of the matrix file
  mtx_file_name = dplyr::case_when(file.exists(file.path(mtx_directory, "matrix.mtx.gz")) ~ "matrix.mtx.gz",
                                   file.exists(file.path(mtx_directory, "matrix.mtx")) ~ "matrix.mtx")
  
  # Determine the name of the barcodes file
  barcodes_file_name = dplyr::case_when(
    file.exists(file.path(mtx_directory, "barcodes.tsv.gz")) ~ "barcodes.tsv.gz",
    file.exists(file.path(mtx_directory, "barcodes.tsv")) ~ "barcodes.tsv"
  )
  
  # Determine the name of the features file
  features_file_name = dplyr::case_when(
    file.exists(file.path(mtx_directory, "features.tsv.gz")) ~ "features.tsv.gz",
    file.exists(file.path(mtx_directory, "features.tsv")) ~ "features.tsv",
    file.exists(file.path(mtx_directory, "genes.tsv")) ~ "genes.tsv",
    file.exists(file.path(mtx_directory, "peaks.bed")) ~ "peaks.bed",
    file.exists(file.path(mtx_directory, "motifs.tsv")) ~ "motifs.tsv"
  )
  
  # Determine the column name of the features file
  if (features_file_name == "peaks.bed") {
    # 10x atac
    features_column_names = c("chr", "start", "end")
  } else if (features_file_name == "motifs.tsv") {
    # 10x atac
    features_column_names = c("tf_full_name", "tf_name")
  } else {
    feature_metadata = readr::read_delim(file.path(mtx_directory, features_file_name), delim="\t", col_names=FALSE, n_max=3, progress=FALSE, show_col_types=FALSE)
    
    if (ncol(feature_metadata) == 6) {
      # 10x multiome
      features_column_names = c("feature_id",
                                "feature_name",
                                "feature_type",
                                "chr",
                                "start",
                                "end")
    } else {
      # 10x other
      features_column_names = c("feature_id", "feature_name", "feature_type")
    }
  }
  
  # Use more generic function to data in market exchange format
  counts_lst = ReadCounts_mtx(
    mtx_directory=mtx_directory,
    mtx_file_name=mtx_file_name,
    barcodes_file_name=barcodes_file_name,
    barcodes_column_names=FALSE,
    features_file_name=features_file_name,
    features_column_names=features_column_names,
    feature_type_column=3,
    delim = "\t",
    strip_suffix = "-1"
  )
  
  return(counts_lst)
}

#' Reads 10x counts that are in hdf5 format.
#' 
#' Note: This function does not read the entire counts data into memory. Instead it returns an iterator object that can be used to
#' retrieve values directly from file (random access). It is recommend to convert this object into a BPcells on-disk storage object.
#' 
#' @param h5_file Path to a 10x h5 counts file.
#' @return One sparse counts matrix per feature type (IterableMatrix format). Additional information on barcodes and features is attached as attributes. barcode_metadata and feature_metadata.
ReadCounts_10x_h5 = function(h5_file) {
  # Checks
  assertthat::is.readable(h5_file)
  
  # Read barcodes and features data separately
  hdf5_fh = hdf5r::H5File$new(h5_file, mode = "r+")
  
  # No barcodes data, just a vector of the barcodes
  barcodes = hdf5_fh[["matrix/barcodes"]][]
  barcodes_data = data.frame(row.names=trimws(barcodes, which="right", whitespace="-1"), orig_barcode=barcodes)
  
  # Read feature data
  hdf5_features = hdf5_fh[["matrix/features"]]
  non_standard_features = hdf5_features[["_all_tag_keys"]][]
  features_data = data.frame(
    feature_id=hdf5_features[["id"]][],
    feature_name=hdf5_features[["name"]][],
    feature_type=hdf5_features[["feature_type"]][]
  )
  
  if (length(non_standard_features) > 0) {
    non_standard_features_data = purrr::map(non_standard_features, function(f) {
      return(hdf5_features[[f]][])
    })
    names(non_standard_features_data) = non_standard_features
    
    if ("interval" %in% names(non_standard_features_data)) {
      interval_data = list(
        chr = gsub(
          "^([^:]+):(\\d+)-(\\d+)$",
          "\\1",
          non_standard_features_data[["interval"]]
        ),
        start = gsub(
          "^([^:]+):(\\d+)-(\\d+)$",
          "\\2",
          non_standard_features_data[["interval"]]
        ),
        end = gsub(
          "^([^:]+):(\\d+)-(\\d+)$",
          "\\3",
          non_standard_features_data[["interval"]]
        )
      )
      
      idx = which(names(non_standard_features_data) == "interval")
      if (idx == 1) {
        pre_idx = c()
      } else {
        pre_idx = 1:(idx - 1)
      }
      if (idx == length(non_standard_features_data)) {
        post_idx = c()
      } else {
        post_idx = (idx + 1):length(non_standard_features_data)
      }
      non_standard_features_data = c(non_standard_features_data[pre_idx],
                                     interval_data,
                                     non_standard_features_data[post_idx])
    }
    features_data = cbind(features_data, non_standard_features_data)
  }
  rownames(features_data) = features_data$feature_id
  hdf5_fh$close_all()
  
  feature_types = unique(features_data$feature_type)
  counts_lst = purrr::map(feature_types, function(f) {
    cts = BPCells::open_matrix_10x_hdf5(h5_file, feature_type=f)
    colnames(cts) = trimws(colnames(cts), which="right", whitespace="-1")
    
    attr(cts, "barcode_metadata") = barcodes_data
    attr(cts, "feature_metadata") = features_data[features_data$feature_type == f, , drop=FALSE]
    
    return(cts)
  })
  names(counts_lst) = feature_types
  
  return(counts_lst)
}

#' Reads counts data produced by 10x (non-spatial datasets).
#' 
#' @param path Path to 10x counts data. Can be a 10x hdf5 file (recommended for big datasets) or a 10x matrix exchange format directory.
#' @param assays If there are multiple assays in the dataset, which assay to read. Multiple assays can be specified. If there is only one assay, this simply sets the assay type.
#' @return One sparse counts matrix per assay. Format is either IterableMatrix (when reading a h5 file) or dgCMatrix (when reading from a matrix exchange format directory). Additional information on barcodes and features is attached as attributes.
ReadCounts_10x = function(path, assays, transpose=FALSE) {
  #path = "/projects/seq-work/analysis/SCdev/bfx2327/XETG00051/20230727__145230__LAB4872_RebekkaW/output-XETG00051__0003507__S146470__20230727__145352/cell_feature_matrix.h5"
  #assays = c("RNA")
  
  # Checks
  assertthat::is.readable(path)
  
  # Convert to feature type in dataset
  assay_to_feature_type = setNames(names(Assays_10x), Assays_10x)
  valid_assays = names(assay_to_feature_type)
  assertthat::assert_that(all(assays %in% valid_assays),
                          msg=FormatMessage("'{assays} must be: {valid_assays*}."))
  feature_types = assay_to_feature_type[assays]
  
  # Read counts
  if (dir.exists(path)) {
    # 10x market exchange format
    counts_lst = ReadCounts_10x_mtx(mtx_directory=path)
  } else {
    # 10x h5 file
    counts_lst = ReadCounts_10x_h5(h5_file=path)
  }
  
  # Rename/prepare
  if (length(counts_lst) == 1) {
    assertthat::assert_that(length(assays) == 1,
                            msg=FormatMessage("Dataset {path} contains only one assay but at least two assays ({assays*}) were requested."))
    
    # Only one type
    names(counts_lst) = assays[1]
  } else {
    # Multiple types
    f = feature_types %in% names(counts_lst)
    assertthat::assert_that(all(f),
                            msg=FormatMessage("Dataset {path} does not contain the following types of data: {assays[!f]*} (named {feature_types[!f]*} in the dataset)."))
    counts_lst = counts_lst[feature_types]
    names(counts_lst) = assays
  }
  
  # Add attributes technology and assay
  for(n in names(counts_lst)) {
    attr(counts_lst[[n]], "technology") = "10x"
    attr(counts_lst[[n]], "assay") = n
  }
  
  return(counts_lst)
}

#' Reads counts data produced by 10x Visium.
#' 
#' @param path Path to 10x counts data for 10x Visium. Can be a 10x hdf5 file (recommended for big datasets) or a 10x matrix exchange format directory.
#' @param assays If there are multiple assays in the dataset, which assay to read. Multiple assays can be specified. If there is only one assay, this simply sets the assay type.
#' @return One sparse counts matrix per assay. Format is either IterableMatrix (when reading a h5 file) or dgCMatrix (when reading from a matrix exchange format directory). Additional information on barcodes and features is attached as attributes. Path to a directory with image information is attached as attribute.
ReadCounts_10xVisium = function(path, assays, transpose=FALSE) {
  # Checks
  assertthat::is.readable(path)
  image_dir = file.path(dirname(path), "spatial")
  assertthat::assert_that(dir.exists(image_dir),
                          msg=FormatMessage("Visium dataset {path} needs a 'spatial' directory at the same location."))
  
  # Read counts
  counts_lst = ReadCounts_10x(path, assays=assays)
  
  # Attach spatial information
  for (i in seq_along(counts_lst)) {
    attr(counts_lst[[i]], "image_dir") = image_dir
  }
  
  return(counts_lst)
}

#' Reads counts data produced by 10x Xenium.
#' 
#' @param path Path to 10x counts data for 10x Xenium. Can be a 10x hdf5 file (recommended for big datasets) or a 10x matrix exchange format directory.
#' @param assays If there are multiple assays in the dataset, which assay to read. Multiple assays can be specified. If there is only one assay, this simply sets the assay type.
#' @return One sparse counts matrix per assay. Format is either IterableMatrix (when reading a h5 file) or dgCMatrix (when reading from a matrix exchange format directory). Additional information on barcodes and features is attached as attributes.
ReadCounts_10xXenium = function(path, assays, transpose=FALSE) {
  return(ReadCounts_10x(path, assays=assays))
}

#' Reads Parse Biosciences counts that are in market exchange format.
#' 
#' @param mtx_directory Path to Parse Biosciences counts directory in market exchange format. Typically contains the files count_matrix.mtx, cell_metadata.csv and all_genes.csv.
#' @return One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_ParseBio_mtx = function(mtx_directory) {
  # Determine the name of the matrix file
  mtx_file_name = "count_matrix.mtx"
  
  # Determine the name of the barcodes file
  barcodes_file_name = "cell_metadata.csv"
  
  # Determine the name of the features file
  features_file_name = "all_genes.csv"
  
  # Use more generic function to data in market exchange format
  counts_lst = ReadCounts_mtx(
    mtx_directory=mtx_directory,
    transpose=TRUE,
    mtx_file_name=mtx_file_name,
    barcodes_file_name=barcodes_file_name,
    barcodes_column_names=TRUE,
    features_file_name=features_file_name,
    features_column_names=TRUE,
    feature_type_column=NULL,
    delim = ","
  )
  
  return(counts_lst)
}

#' Reads Parse Biosciences counts that are in h5ad anndata format.
#' 
#' Note: This function does not read the entire counts data into memory. Instead it returns an iterator object that can be used to
#' retrieve values directly from file (random access). It is recommend to convert this object into a BPcells on-disk storage object.
#' 
#' Does not discriminate between feature types.
#' 
#' @param h5ad_file Path to an anndata object in hdf5 format.
#' @return Sparse counts matrix (IterableMatrix format). Additional information on barcodes and features is attached as attributes barcode_metadata and feature_metadata.
ReadCounts_ParseBio_h5ad = function(h5ad_file) {
  return(ReadCounts_h5ad(h5ad_file))
}

#' Reads counts data produced by Parse Biosciences.
#' 
#' @param path Path to Parse Biosciences counts data. Can be a Parse Biosciences anndata.h5ad file (recommended for big datasets) or a Parse Biosciences matrix exchange format directory.
#' @param assays If there are multiple assays in the dataset, which assay to read. Multiple assays can be specified. If there is only one assay, this simply sets the assay type.
#' @return One sparse counts matrix. Format is either IterableMatrix (when reading an anndata.h5ad file) or dgCMatrix (when reading from a matrix exchange format directory). Additional information on barcodes, features, technology and assays is attached as attributes.
ReadCounts_ParseBio = function(path, assays, transpose=FALSE) {
  #path = "/projects/seq-work/analysis/annee/bfx2302/splitpipe/gex_combined/BC001/DGE_filtered"
  #assays = "RNA"
  
  # Checks
  assertthat::is.readable(path)
  
  # Convert to feature type in dataset
  assay_to_feature_type = setNames(names(Assays_Parse), Assays_Parse)
  valid_assays = names(assay_to_feature_type)
  assertthat::assert_that(all(assays %in% valid_assays),
                          msg=FormatMessage("'{assays} must be: {valid_assays*}."))
  feature_types = assay_to_feature_type[assays]
  
  # Read counts
  if (dir.exists(path)) {
    # 10x market exchange format
    counts_lst = ReadCounts_ParseBio_mtx(mtx_directory=path)
  } else {
    # 10x hdf5 file
    counts_lst = ReadCounts_ParseBio_h5ad(h5ad_file=path)
  }
  
  # Rename/prepare
  if (length(counts_lst) == 1) {
    assertthat::assert_that(length(assays) == 1,
                            msg=FormatMessage("Dataset {path} contains only one assay but at least two assays ({assays*}) were requested."))
    
    # Only one type
    names(counts_lst) = assays[1]
  } else {
    # Multiple types
    f = feature_types %in% names(counts_lst)
    assertthat::assert_that(all(f),
                            msg=FormatMessage("Dataset {path} does not contain the following types of data: {assays[!f]*} (named {feature_types[!f]*} in the dataset)."))
    counts_lst = counts_lst[feature_types]
    names(counts_lst) = assays
  }
  
  # Add attributes technology and assay
  for(n in names(counts_lst)) {
    attr(counts_lst[[n]], "technology") = "Parse Biosciences"
    attr(counts_lst[[n]], "assay") = n
  }
  
  return(counts_lst)
}

#' Reads Scale Bio counts that are in market exchange format.
#' 
#' @param mtx_directory Path to Scale Bio counts directory in market exchange format. Typically contains the files matrix.mtx.gz, barcodes.tsv.gz and features.tsv.gz.
#' @return One sparse counts matrix per feature type (dgCMatrix format). Additional information on barcodes and features is attached as attributes.
ReadCounts_ScaleBio_mtx = function(mtx_directory) {
  # Determine the name of the matrix file
  mtx_file_name = "matrix.mtx"
  
  # Determine the name of the barcodes file
  barcodes_file_name = "barcodes.tsv"
  
  # Determine the name of the features file
  features_file_name = "features.tsv"
  
  # Use more generic function to data in market exchange format
  counts_lst = ReadCounts_mtx(
    mtx_directory=mtx_directory,
    transpose=FALSE,
    mtx_file_name=mtx_file_name,
    barcodes_file_name=barcodes_file_name,
    barcodes_column_names=FALSE,
    features_file_name=features_file_name,
    features_column_names=c("feature_id", "feature_name", "feature_type"),
    feature_type_column=3,
    delim = "\t"
  )
  
  return(counts_lst)
}

#' Reads counts data produced by Scale Bio
#' 
#' @param path Path to Scale Bio counts data. Must be a Scale Bio matrix exchange format directory.
#' @param assays If there are multiple assays in the dataset, which assay to read. Multiple assays can be specified. If there is only one assay, this simply sets the assay type.
#' @return  One sparse counts matrix per assay (dgCMatrix format). Additional information on barcodes, features, technology and assay is attached as attributes.
ReadCounts_ScaleBio = function(path, assays, transpose=FALSE) {
  #path = "/projects/seq-work/analysis/SCdev/bfx2279/scalerna/output/samples/BC238.filtered/"
  #assays = "RNA"

  # Checks
  assertthat::is.readable(path)
  
  # Convert to feature type in dataset
  assay_to_feature_type = setNames(names(Assays_Scale), Assays_Scale)
  valid_assays = names(assay_to_feature_type)
  assertthat::assert_that(all(assays %in% valid_assays),
                          msg=FormatMessage("'{assays} must be: {valid_assays*}."))
  feature_types = assay_to_feature_type[assays]

  # Read counts
  counts_lst = ReadCounts_ScaleBio_mtx(mtx_directory=path)
  
  # Rename/prepare
  if (length(counts_lst) == 1) {
    assertthat::assert_that(length(assays) == 1,
                            msg=FormatMessage("Dataset {path} contains only one assay but at least two assays ({assays*}) were requested."))
    
    # Only one type
    names(counts_lst) = assays[1]
  } else {
    # Multiple types
    f = feature_types %in% names(counts_lst)
    assertthat::assert_that(all(f),
                            msg=FormatMessage("Dataset {path} does not contain the following types of data: {assays[!f]*} (named {feature_types[!f]*} in the dataset)."))
    counts_lst = counts_lst[feature_types]
    names(counts_lst) = assays
  }
  
  # Add attributes technology and assay
  for(n in names(counts_lst)) {
    attr(counts_lst[[n]], "technology") = "ScaleBio"
    attr(counts_lst[[n]], "assay") = n
  }
  
  return(counts_lst)
}

#' Reads counts data produced by Smartseq, 10x, 10x Visium, 10x Xenium, Parse Biosciences, Scale Bio.
#' 
#' @param path Path to counts data. Can be: character-separated file (Smartseq), matrix exchange format directory (SmartSeq, 10x, Parse Biosciences, ScaleBio), hdf5 file (10x), h5ad file (Parse Biosciences).
#' @param technology Technology. Can be: 'smartseq2', 'smartseq3', '10x', '10x_visium', '10x_xenium', 'parse' or 'scale'.
#' @param assays If there are multiple assays in the dataset, which assay to read. Multiple assays can be specified. If there is only one assay, this simply sets the assay type.
#' @param barcode_metadata Table with additional barcode metadata. Can also be a list specifying metadata for each assay. First column must contain the barcode. Missing barcodes will be filled with NA.
#' @param feature_metadata Table with additional feature metadata. Can also be a list specifying metadata for each assay. First column must contain the feature id. Missing features will be filled with NA.
#' @param barcode_suffix Suffix to add to the barcodes (default: NULL). When barcodes are renamed, will be applied afterwards.
#' @return  One sparse counts matrix per assay. Format can be dgCMatrix (general) or IterableMatrix (when reading an anndata.h5ad or h5 file). Additional information on barcodes and features is attached as attributes.
ReadCounts = function(path, technology, assays, barcode_metadata_file=NULL, feature_metadata_file=NULL, barcode_suffix=NULL) {
  library(magrittr)
  
  #path = "datasets/10x_pbmc_5k_protein/filtered_feature_bc_matrix/"
  #technology = "10x"
  #assays=c("RNA", "ADT")
  #rename_features_metadata=c(2,2)
  #rename_features = NULL
  #on_disk_path="modules/read_data/10x_pbmc_5k_protein"
  #barcode_metadata_file=NULL
  #feature_metadata_file=NULL
  #barcode_suffix=NULL
  #on_disk_overwrite=TRUE
  
  
  # Checks
  valid_technologies = c("smartseq2", "smartseq3", "10x", "10x_visium", "10x_xenium", "parse", "scale")
  assertthat::assert_that(technology %in% valid_technologies,
                          msg=FormatMessage("Technology is {technology} but must be one of: {valid_technologies*}."))
  
  # Read counts
  if (technology == "smartseq2") {
    counts_lst = ReadCounts_SmartSeq(path=path, assays=assays[1], version="2")
  } else if (technology == "smartseq3") {
    counts_lst = ReadCounts_SmartSeq(path=path, assays=assays[1], version="3")
  } else if(technology == "10x") {
    counts_lst = ReadCounts_10x(path=path, assays=assays)
  } else if(technology == "10x_visium") {
    counts_lst = ReadCounts_10xVisium(path=path, assays=assays)
  } else if(technology == "10x_xenium") {
    counts_lst = ReadCounts_10xXenium(path=path, assays=assays)
  } else if(technology == "parse") {
    counts_lst = ReadCounts_ParseBio(path=path, assays=assays)
  } else if(technology == "scale") {
    counts_lst = ReadCounts_ScaleBio(path=path, assays=assays)
  }
  
  assertthat::assert_that(assertthat::not_empty(counts_lst),
                          msg=FormatMessage("Count not read counts for dataset {path}, assay {assay}."))
  
  # Add barcode metadata to counts objects
  if (!is.null(barcode_metadata)) {
    assertthat::assert_that(!is(barcode_metadata, "list") | length(barcode_metadata) == length(counts_lst),
                            msg=FormatMessage("Barcode metadata must either be one table or a list of tables for each assay (dataset {path})."))
    
    for(i in seq_along(counts_lst)) {
      # Do we have already other barcode metadata
      if ("barcode_metadata" %in% names(attributes(counts_lst[[i]]))) {
        metadata = attr(counts_lst[[i]], "barcode_metadata")
      } else {
        metadata = data.frame(id=colnames(counts_lst[[i]]))
      }
      
      if (is(barcode_metadata, "list")) {
        barcode_metadata_assay = barcode_metadata[[i]]
      } else {
        barcode_metadata_assay = barcode_metadata
      }
      
      x_id = colnames(metadata)[1]
      x_rownames = rownames(metadata)
      y_id = colnames(barcode_metadata_assay)[1]
      metadata = dplyr::left_join(x=metadata,
                                   y=barcode_metadata_assay,
                                   by=setNames(y_id, x_id))
      rownames(metadata) = x_rownames
      attr(counts_lst[[i]], "barcode_metadata") = metadata
    }
  }

  # Add feature metadata to counts objects
  if (!is.null(feature_metadata)) {
    assertthat::assert_that(!is(feature_metadata, "list") | length(feature_metadata) == length(counts_lst),
                            msg=FormatMessage("Feature metadata must either be one table or a list of tables for each assay (dataset {path})."))
    
    for(i in seq_along(counts_lst)) {
      # Do we have already other feature metadata
      if ("feature_metadata" %in% names(attributes(counts_lst[[i]]))) {
        metadata = attr(counts_lst[[i]], "feature_metadata")
      } else {
        metadata = data.frame(id=rownames(counts_lst[[i]]))
      }
      
      if (is(feature_metadata, "list")) {
        feature_metadata_assay = feature_metadata[[i]]
      } else {
        feature_metadata_assay = feature_metadata
      }
      
      x_id = colnames(metadata)[1]
      x_rownames = rownames(metadata)
      y_id = colnames(feature_metadata_assay)[1]
      metadata = dplyr::left_join(x=metadata,
                                  y=feature_metadata_assay,
                                  by=setNames(y_id, x_id))
      rownames(metadata) = x_rownames
      attr(counts_lst[[i]], "feature_metadata") = metadata
    }
  }
  
  # Make feature names Seurat-compatible (replace '_' with '-') and unique
  for(i in seq_along(counts_lst)) {
    assay = names(counts_lst)[i]
    metadata = attr(counts_lst[[i]], "feature_metadata")
    
    feature_names = rownames(counts_lst[[i]])
    if (any(grepl(pattern="_", x=feature_names, fixed=TRUE))) {
      warning(FormatMessage("Feature names contain '_' for dataset {path}, assay {assay}. All occurences will be replaced with '-'."))
      feature_names = gsub(pattern="_", replacement="-", x=feature_names, fixed=TRUE)
    }
    if (any(duplicated(feature_names))) {
      warning(FormatMessage("Features contains duplicate values for dataset {path}, assay {assay}. Feature names will be made unique."))
      feature_names = make.unique(feature_names)
    }
    
    rownames(counts_lst[[i]]) = feature_names
    rownames(metadata) = feature_names
    attr(counts_lst[[i]], "feature_metadata") = metadata
  }

  # Add barcode suffix
  if (!is.null(barcode_suffix)) {
    for(i in seq_along(counts_lst)) {
      # Counts
      colnames(counts_lst[[i]]) = paste0(colnames(counts_lst[[i]]), barcode_suffix)
      
      # Metadata
      barcode_metadata = attr(counts_lst[[i]], "barcode_metadata")
      rownames(barcode_metadata) = paste0(rownames(barcode_metadata), barcode_suffix)
      attr(counts_lst[[i]], "barcode_metadata") = barcode_metadata
    }
  }
  
  return(counts_lst)
}

#' Write counts data to disk.
#' 
#' @param counts A counts matrix. Format can be a standard matrix, a sparse matrix, AnnDataMatrixH5 (when reading anndata.h5ad) or MatrixSubset (when reading hdf5).
#' @param path Where to write counts on disk. Depending on the format this will be a single file or a directory.
#' @param format Output format. Can be: 'matrix_market'  (directory with barcodes.tsv.gz, features.tsv.gz and matrix.txt.gz) or 'matrix_directory' format (directory for on-disk operations using the BPCells package)
#' @param overwrite Overwrite existing output paths. Default is FALSE.
#' @param metadata If TRUE write barcode and feature metadata. Default is FALSE.
WriteCounts = function(counts, path, format, overwrite=FALSE, metadata=FALSE) {
  #counts = counts_lst[[i]][[j]]
  #path=file.path(module_dir, sample, assay) 
  #format="matrix_directory"
  #overwrite=TRUE
  
  # Checks
  valid_formats = c("matrix_market", "matrix_directory")
  assertthat::assert_that(format %in% valid_formats,
                          msg=FormatMessage("Format is {format} but must be one of: {valid_formats*}."))
  
  # Check that the counts object has the correct format
  if (is(counts, "IterableMatrix")) {
    # Produced by BPCells::open_matrix_10x_hdf5 or BPCells::open_matrix_anndata_hdf5
    # Nothing to do
  } else if (is.matrix(counts)) {
    # Standard matrix - convert to sparse matrix
    counts = as(counts, "dgCMatrix")
  } else if(is(counts, "sparseMatrix")) {
    # Sparse matrix - convert to dgCMatrix
    if (!is(counts, "dgCMatrix")) {
      counts = as(counts, "dgCMatrix")
    }
  }else {
    # No matrix - try to convert to sparse matrix
    counts = as(as.matrix(counts), "dgCMatrix")
  }
  
  # Now write to disk
  if (format == "matrix_directory") {
    # Save in matrix directory
    library(BPCells)
    
    # Sparse matrices in dgCMatrix format must be converted to BPCells internal format for better efficiency
    # AnnDataMatrixH5 and MatrixSubset can be processed directly
    if (is(counts, "dgCMatrix")) {
      
      # Test if we have non-negative integers, then convert matrix from double to integer to save disk space (default is double)
      vals = sample(counts@x, min(length(counts@x), 100000))
      counts = as(counts, "IterableMatrix")
      if (all(vals >= 0) & all(vals == round(vals))) {
        counts = BPCells::convert_matrix_type(counts, type="uint32_t")
      }
    }
    
    if (!dir.exists(path) | overwrite==TRUE) {
      # If path does not exists or overwrite set to TRUE: write data to matrix dir
      counts = BPCells::write_matrix_dir(mat=counts, dir=path, overwrite=overwrite)
    }
  } else {
    # Save in matrix market format
    if (overwrite) {
      d = file.path(path)
      dir.create(d, showWarnings=FALSE)
      
      mh = file.path(d, "matrix.mtx")
      Matrix::writeMM(counts, file=mh)
      R.utils::gzip(mh, overwrite=TRUE)
      
      bh = gzfile(file.path(d, "barcodes.tsv.gz"), open="wb")
      write(colnames(counts), file=bh)
      close(bh)
      
      fh = gzfile(file.path(d, "features.tsv.gz"), open="wb")
      write.table(assay_feature_meta_data_df, file=fh, row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t")
      close(fh)
    }
  }
  
}

#' Reads image data produced by 10x Visium.
#' 
#' @param path Path to the 'spatial' directory produced by 10x Visium.
#' @return A Seurat VisiumV1 object.
ReadImage_10xVisium = function(image_dir) {
  #image_dir = "/group/sequencing/Bfx/scripts/andreasp/scrnaseq/datasets/10x_visium_human_brain_cancer/spatial/"
  
  # Checks
  assertthat::is.readable(image_dir)
  for (f in c("tissue_lowres_image.png", "scalefactors_json.json")) {
    assertthat::assert_that(file.exists(file.path(image_dir, f)),
                            msg=FormatMessage("10x Visium image directory {image_dir} misses the file {f}."))
  }
  
  # Read image
  image = Seurat::Read10X_Image(image_dir, filter.matrix=FALSE)
  
  return(image)
}

#' Reads image data produced by 10x Visium and 10x Xenium.
#' 
#' @param image_dir Path to the 'spatial' directory produced by 10x Visium.
#' @param technology Technology. Can be: 10x_visium', '10x_xenium'.
#' @param barcodes Named vector with barcodes to keep. Names are original barcodes and values are barcodes after renaming.
#' @return A Seurat VisiumV1 object.
ReadImage = function(image_dir, technology, barcodes) {
  #image_dir = "/group/sequencing/Bfx/scripts/andreasp/scrnaseq/datasets/10x_visium_human_brain_cancer/spatial/"
  #technology = "10x_visium"
  #barcodes = colnames(counts_lst[[1]][[1]])
  
  # Checks
  valid_technologies = c("10x_visium", "10x_xenium")
  assertthat::assert_that(technology %in% valid_technologies,
                          msg=FormatMessage("Technology is {technology} but must be one of: {valid_technologies*}."))
  
  # Read image
  if(technology == "10x_visium") {
    image = ReadImage_10xVisium(image_dir=image_dir)
  } else if(technology == "10x_xenium") {
    image = ReadImage_10xXenium(image_dir=image_dir)
  }
  
  # Keep only spots that are also present in the assay data (under tissue)
  spots_to_keep = image@coordinates %>% dplyr::filter(tissue==1) %>% row.names()
  image = image[spots_to_keep]
  
  return(image)
}

ReadMetrics_10x = function(metrics_file) {
  metrics_file = "/projects/seq-work/analysis/annac/bfx2337/cellranger_rnaseq/Newt_control/outs/metrics_summary.csv"
  metrics_file = "/projects/seq-work/analysis/joseg/bfx2306/cellranger_multi/bfx2306.LAB4821_Pre-amp-cDNA.s4-CEL105008.cellranger_multi_metrics_summary.csv"
  
  # Checks
  assertthat::is.readable(metrics_file)
  
  # Read file
  metrics_table = readr::read_delim(metrics_file, col_names=TRUE, show_col_types=FALSE)
  metrics_table_colnms = colnames(metrics_table)
  
  if (metrics_table_colnms[1] == "Category") {
    # Produced by cellranger multi
    # https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/metrics-summary-csv
    
    # Subset per-sample metrics (get rid of per-library metrics)
    # Also only keep overall metrics but not the ones calculated for various groups
    metrics_table = metrics_table %>% 
      dplyr::filter(Category=="Cells", is.na(`Grouped By`)) %>%
      dplyr::select(library_type=`Library Type`, metric_name=`Metric Name`, metric_value=`Metric Value`)
    
    # Split by library type and convert into wide table
    metrics_table = split(metrics_table, metrics_table$library_type)
    metrics_table = purrr::map(metrics_table, function(tbl) {
      tbl = tbl %>% dplyr::select(-library_type)
      tbl = tidyr::pivot_wider(tbl, names_from="metric_name", values_from="metric_value")
      return(tbl)
    })
    
    # Map types to assay names
    #
  } else {
    # Produced by other cellranger pipelines (standard, multiome, atac, visium, xenium)
    metrics_table = list(Overall=metrics_table)
  }
  
  return(metrics_table)
}
  